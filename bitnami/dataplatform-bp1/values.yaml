## @section Global parameters
## Global Docker image parameters
## Please, note that this will override the image parameters, including dependencies, configured to use the global value
## Current available global Docker image parameters: imageRegistry, imagePullSecrets and storageClass

## @param global.imageRegistry Global Docker image registry
## @param global.imagePullSecrets Global Docker registry secret names as an array
## @param global.storageClass Global StorageClass for Persistent Volume(s)
##
global:
  imageRegistry: ""
  ## E.g.
  ## imagePullSecrets:
  ##   - myRegistryKeySecretName
  ##
  imagePullSecrets: []
  storageClass: ""

## @section Zookeeper chart parameters

zookeeper:
  ## @param zookeeper.enabled Switch to enable or disable the Zookeeper helm chart
  ##
  enabled: true
  ## @param zookeeper.replicaCount Number of Zookeeper replicas
  ##
  replicaCount: 3
  ## @param zookeeper.heapSize Size in MB for the Java Heap options (Xmx and XMs).
  ## This env var is ignored if Xmx an Xms are configured via JVMFLAGS
  ##
  heapSize: 4096
  ## Recommended values for cpu and memory requests
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  ## @param zookeeper.resources.limits The resources limits for Zookeeper containers
  ## @param zookeeper.resources.requests [object] The requested resources for Zookeeper containers
  ##
  resources:
    limits: {}
    requests:
      cpu: 250m
      memory: 5120Mi
  ## Anti Affinity rules set for resiliency
  ## @param zookeeper.affinity.podAntiAffinity [object] Zookeeper pods Anti Affinity rules for best possible resiliency (evaluated as a template)
  ## @skip zookeeper.affinity.podAntiAffinity.requiredDuringSchedulingIgnoredDuringExecution
  ##
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/name
                operator: In
                values:
                  - zookeeper
              - key: app.kubernetes.io/instance
                operator: In
                values:
                  - '{{ .Release.Name }}'
          topologyKey: "kubernetes.io/hostname"

## @section Kafka chart parameters

## Kafka Subchart parameters
##
kafka:
  ## @param kafka.enabled Switch to enable or disable the Kafka helm chart
  ##
  enabled: true
  ## @param kafka.replicaCount Number of Kafka replicas
  ##
  replicaCount: 3
  ## @param kafka.heapOpts Kafka's Java Heap size
  ##
  heapOpts: -Xmx4096m -Xms4096m
  ## Recommended values for cpu and memory requests
  ## @param kafka.resources.limits The resources limits for Kafka containers
  ## @param kafka.resources.requests [object] The requested resources for Kafka containers
  ##
  resources:
    limits: {}
    requests:
      cpu: 250m
      memory: 5120Mi
  ## Anti Affinity rules set for resiliency and Affinity rules set for optimal performance
  ## @param kafka.affinity.podAntiAffinity [object] Zookeeper pods Anti Affinity rules for best possible resiliency (evaluated as a template)
  ## @skip kafka.affinity.podAntiAffinity.requiredDuringSchedulingIgnoredDuringExecution
  ## @param kafka.affinity.podAffinity [object] Zookeeper pods Affinity rules for best possible resiliency (evaluated as a template)
  ## @skip kafka.affinity.podAffinity.preferredDuringSchedulingIgnoredDuringExecution
  ##
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/component
                operator: In
                values:
                  - kafka
              - key: app.kubernetes.io/instance
                operator: In
                values:
                  - '{{ .Release.Name }}'
          topologyKey: "kubernetes.io/hostname"
    podAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 50
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: app.kubernetes.io/name
                  operator: In
                  values:
                    - zookeeper
                - key: app.kubernetes.io/instance
                  operator: In
                  values:
                    - '{{ .Release.Name }}'
            topologyKey: "kubernetes.io/hostname"
  ## Prometheus Exporters / Metrics
  ##
  metrics:
    ## Prometheus Kafka Exporter: exposes complimentary metrics to JMX Exporter
    ##
    kafka:
      ## @param kafka.metrics.kafka.enabled Whether or not to create a standalone Kafka exporter to expose Kafka metrics
      ##
      enabled: false
      ## Prometheus Kafka Exporter' resource requests and limits
      ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
      ## @param kafka.metrics.kafka.resources.limits The resources limits for the container
      ## @param kafka.metrics.kafka.resources.requests [object] Kafka Exporter container resource requests
      ##
      resources:
        limits: {}
        requests:
          cpu: 100m
          memory: 128Mi
      ## Service configuration
      ##
      service:
        ## @param kafka.metrics.kafka.service.port Kafka Exporter Prometheus port to be used in Wavefront configuration
        ##
        port: 9308
    ## Prometheus JMX Exporter: exposes the majority of Kafka's metrics
    ##
    jmx:
      ## @param kafka.metrics.jmx.enabled Whether or not to expose JMX metrics to Prometheus
      ##
      enabled: false
      ## Prometheus JMX Exporter' resource requests and limits
      ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
      ## @param kafka.metrics.jmx.resources.limits The resources limits for the container
      ## @param kafka.metrics.jmx.resources.requests [object] JMX Exporter container resource requests
      ##
      resources:
        limits: {}
        requests:
          cpu: 100m
          memory: 128Mi
      ## Service configuration
      ##
      service:
        ## @param kafka.metrics.jmx.service.port JMX Exporter Prometheus port
        ##
        port: 5556
  ## @param kafka.zookeeper.enabled Switch to enable or disable the Zookeeper helm chart
  ##
  zookeeper:
    enabled: false
  ## External Zookeeper. This value is only used when zookeeper.enabled is set to false.
  ## @param kafka.externalZookeeper.servers Server or list of external Zookeeper servers to use
  ##
  externalZookeeper:
    ## This is set to the zookeeper deployed as part of this chart
    ##
    servers:
      - '{{ .Release.Name }}-zookeeper'

## @section Solr chart parameters

## Solr Subchart parameters
##
solr:
  ## @param solr.enabled Switch to enable or disable the Solr helm chart
  ##
  enabled: true
  ## @param solr.replicaCount Number of Solr replicas
  ##
  replicaCount: 2
  ## @param solr.authentication.enabled Enable Solr authentication. BUG: Exporter deployment does not work with authentication enabled
  ##
  authentication:
    enabled: false
  ## @param solr.javaMem Java recommended memory options to pass to the Solr container
  ##
  javaMem: -Xmx4096m -Xms4096m
  ## Anti affinity rules set for resiliency
  ## @param solr.affinity.podAntiAffinity [object] Zookeeper pods Anti Affinity rules for best possible resiliency (evaluated as a template)
  ## @skip solr.affinity.podAntiAffinity.requiredDuringSchedulingIgnoredDuringExecution
  ##
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
              - key: app.kubernetes.io/component
                operator: In
                values:
                  - solr
              - key: app.kubernetes.io/instance
                operator: In
                values:
                  - '{{ .Release.Name }}'
          topologyKey: "kubernetes.io/hostname"
  resources:
    ## Recommended values for cpu and memory requests
    ## @param solr.resources.limits The resources limits for Solr containers
    ## @param solr.resources.requests [object] The requested resources for Solr containers
    ##
    limits: {}
    requests:
      cpu: 250m
      memory: 5120Mi
  ## Configuration for the solr prometheus exporter
  ##
  exporter:
    ## @param solr.exporter.enabled Start a prometheus exporter
    ##
    enabled: false
    ## @param solr.exporter.port Solr exporter port
    ##
    port: 9983
    ## @param solr.exporter.affinity.podAffinity [object] Zookeeper pods Affinity rules for best possible resiliency (evaluated as a template)
    ## @skip solr.exporter.affinity.podAffinity.preferredDuringSchedulingIgnoredDuringExecution
    ##
    affinity:
      podAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 50
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                  - key: app.kubernetes.io/name
                    operator: In
                    values:
                      - solr
                  - key: app.kubernetes.io/instance
                    operator: In
                    values:
                      - '{{ .Release.Name }}'
              topologyKey: "kubernetes.io/hostname"
    ## Solr Prometheus exporter container resource requests and limits
    ## @param solr.exporter.resources.limits The resources limits for the container
    ## @param solr.exporter.resources.requests [object] The requested resources for the container
    ##
    resources:
      limits: {}
      requests:
        cpu: 100m
        memory: 128Mi
  ## @param solr.zookeeper.enabled Enable Zookeeper deployment. Needed for Solr cloud.
  ##
  zookeeper:
    enabled: false
  ## External Zookeeper. This value is only used when zookeeper.enabled is set to false.
  ## @param solr.externalZookeeper.servers Servers for an already existing Zookeeper.
  ##
  externalZookeeper:
    ## In this case, it is set to the zookeeper deployed as part of this chart.
    ##
    servers:
      - '{{ .Release.Name }}-zookeeper'

## @section Spark chart parameters

## Spark Subchart parameters
##
spark:
  ## @param spark.enabled Switch to enable or disable the Spark helm chart
  ##
  enabled: true
  ## Spark master specific configuration
  ##
  master:
    ## @param spark.master.webPort Specify the port where the web interface will listen on the master
    ##
    webPort: 8080
    ## @param spark.master.resources.limits The resources limits for the container
    ## @param spark.master.resources.requests [object] The resources limits for the container
    ##
    resources:
      ## Recommended values for cpu and memory requests
      ##
      limits: {}
      requests:
        cpu: 250m
        memory: 5120Mi
    ## Anti affinity rules set for resiliency
    ## @param spark.master.affinity.podAntiAffinity [object] Zookeeper pods Anti Affinity rules for best possible resiliency (evaluated as a template)
    ## @skip spark.master.affinity.podAntiAffinity.requiredDuringSchedulingIgnoredDuringExecution
    ##
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
                - key: app.kubernetes.io/component
                  operator: In
                  values:
                    - worker
                - key: app.kubernetes.io/instance
                  operator: In
                  values:
                    - '{{ .Release.Name }}'
            topologyKey: "kubernetes.io/hostname"
  ## Spark worker specific configuration
  ##
  worker:
    ## @param spark.worker.replicaCount Set the number of workers
    ##
    replicaCount: 2
    ## @param spark.worker.webPort Specify the port where the web interface will listen on the worker
    ##
    webPort: 8081
    ## Anti affinity rules set for resiliency
    ## @param spark.worker.affinity.podAntiAffinity [object] Zookeeper pods Anti Affinity rules for best possible resiliency (evaluated as a template)
    ## @skip spark.worker.affinity.podAntiAffinity.requiredDuringSchedulingIgnoredDuringExecution
    ##
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
                - key: app.kubernetes.io/component
                  operator: In
                  values:
                    - worker
                    - master
                - key: app.kubernetes.io/instance
                  operator: In
                  values:
                    - '{{ .Release.Name }}'
            topologyKey: "kubernetes.io/hostname"
    ## @param spark.worker.resources.limits The resources limits for the container
    ## @param spark.worker.resources.requests [object] The resources limits for the container
    ##
    resources:
      limits: {}
      requests:
        cpu: 250m
        memory: 5120Mi
  ## Metrics configuration
  ##
  metrics:
    ## @param spark.metrics.enabled Start a side-car Prometheus exporter
    ##
    enabled: false
    ## @param spark.metrics.masterAnnotations [object] Annotations for enabling prometheus to access the metrics endpoint of the master nodes
    ##
    masterAnnotations:
      prometheus.io/scrape: 'true'
      prometheus.io/path: '/metrics/'
      prometheus.io/port: '8080'
    ## @param spark.metrics.workerAnnotations [object] Annotations for enabling prometheus to access the metrics endpoint of the worker nodes
    ##
    workerAnnotations:
      prometheus.io/scrape: 'true'
      prometheus.io/path: '/metrics/'
      prometheus.io/port: '8081'

## @section Tanzu Observability (Wavefront) chart parameters

## Wavefront Subchart parameters
##
wavefront:
  ## @param wavefront.enabled Switch to enable or disable the Wavefront helm chart
  ##
  enabled: false
  ## @param wavefront.clusterName Unique name for the Kubernetes cluster (required)
  ## All metrics will receive a `cluster` tag with this value
  ##
  clusterName: KUBERNETES_CLUSTER_NAME
  ## @param wavefront.wavefront.url Wavefront URL for your cluster (required)
  ## @param wavefront.wavefront.token Wavefront API Token (required)
  ## @param wavefront.wavefront.existingSecret Name of an existing secret containing the token
  ##
  wavefront:
    url: https://YOUR_CLUSTER.wavefront.com
    token: YOUR_API_TOKEN
    existingSecret: ""
  ## Wavefront Collector is responsible to get all Kubernetes metrics from your cluster.
  ## It will capture Kubernetes resources metrics available from the kubelets, as well as auto-discovery capabilities.
  ##
  collector:
    ## Rules based discovery configuration
    ## Ref: https://github.com/wavefrontHQ/wavefront-kubernetes-collector/blob/master/docs/discovery.md
    ## @param wavefront.collector.resources.limits The resources limits for the collector container
    ## @param wavefront.collector.resources.requests [object] The requested resources for the collector container
    ##
    resources:
      limits: {}
      requests:
        cpu: 200m
        memory: 10Mi
    discovery:
      ## @param wavefront.collector.discovery.enabled Rules based and Prometheus endpoints auto-discovery
      ##
      enabled: true
      ## @param wavefront.collector.discovery.enableRuntimeConfigs Enable runtime discovery rules
      ## Ref: https://github.com/wavefrontHQ/wavefront-collector-for-kubernetes/blob/master/docs/discovery.md#runtime-configurations
      ##
      enableRuntimeConfigs: true
      ## @param wavefront.collector.discovery.config [array] Configuration for rules based auto-discovery
      ##
      config:
        ## auto-discover kafka-exporter
        ##
        - name: kafka-discovery
          type: prometheus
          selectors:
            images:
              - '*bitnami/kafka-exporter*'
          port: 9308
          path: /metrics
          scheme: http
          prefix: kafka.
        ## auto-discover jmx exporter
        ##
        - name: kafka-jmx-discovery
          type: prometheus
          selectors:
            images:
              - '*bitnami/jmx-exporter*'
          port: 5556
          path: /metrics
          scheme: http
          prefix: kafkajmx.
        ## auto-discover solr
        ##
        - name: solr-discovery
          type: prometheus
          selectors:
            images:
              - '*bitnami/solr*'
          port: 9983
          path: /metrics
          scheme: http
        ## auto-discover spark
        ##
        - name: spark-worker-discovery
          type: prometheus
          selectors:
            images:
              - '*bitnami/spark*'
          port: 8081
          path: /metrics/
          scheme: http
          prefix: spark.
        ## auto-discover spark
        ##
        - name: spark-master-discovery
          type: prometheus
          selectors:
            images:
              - '*bitnami/spark*'
          port: 8080
          path: /metrics/
          scheme: http
          prefix: spark.
  proxy:
    ## Wavefront Proxy resource requests and limits
    ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
    ## @param wavefront.proxy.resources.limits The resources limits for the proxy container
    ## @param wavefront.proxy.resources.requests [object] The requested resources for the proxy container
    ##
    resources:
      limits: {}
      requests:
        cpu: 100m
        memory: 5Gi

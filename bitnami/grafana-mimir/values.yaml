# Copyright Broadcom, Inc. All Rights Reserved.
# SPDX-License-Identifier: APACHE-2.0

## @section Global parameters
## Global Docker image parameters
## Please, note that this will override the image parameters, including dependencies, configured to use the global value
## Current available global Docker image parameters: imageRegistry, imagePullSecrets and storageClass
##

## @param global.imageRegistry Global Docker image registry
## @param global.imagePullSecrets Global Docker registry secret names as an array
## @param global.storageClass Global StorageClass for Persistent Volume(s)
##
global:
  imageRegistry: ""
  ## E.g.
  ## imagePullSecrets:
  ##   - myRegistryKeySecretName
  ##
  imagePullSecrets: []
  storageClass: ""
  ## Compatibility adaptations for Kubernetes platforms
  ##
  compatibility:
    ## Compatibility adaptations for Openshift
    ##
    openshift:
      ## @param global.compatibility.openshift.adaptSecurityContext Adapt the securityContext sections of the deployment to make them compatible with Openshift restricted-v2 SCC: remove runAsUser, runAsGroup and fsGroup and let the platform use their allowed default IDs. Possible values: auto (apply if the detected running cluster is Openshift), force (perform the adaptation always), disabled (do not perform adaptation)
      ##
      adaptSecurityContext: auto
## @section Common parameters
##

## @param kubeVersion Override Kubernetes version
##
kubeVersion: ""
## @param nameOverride String to partially override common.names.name
##
nameOverride: ""
## @param fullnameOverride String to fully override common.names.fullname
##
fullnameOverride: ""
## @param namespaceOverride String to fully override common.names.namespace
##
namespaceOverride: ""
## @param commonLabels Labels to add to all deployed objects
##
commonLabels: {}
## @param commonAnnotations Annotations to add to all deployed objects
##
commonAnnotations: {}
## @param clusterDomain Kubernetes cluster domain name
##
clusterDomain: cluster.local
## @param extraDeploy Array of extra objects to deploy with the release
##
extraDeploy: []
## Enable diagnostic mode in the deployment
##
diagnosticMode:
  ## @param diagnosticMode.enabled Enable diagnostic mode (all probes will be disabled and the command will be overridden)
  ##
  enabled: false
  ## @param diagnosticMode.command Command to override all containers in the deployment
  ##
  command:
    - sleep
  ## @param diagnosticMode.args Args to override all containers in the deployment
  ##
  args:
    - infinity
## @section Common Grafana Mimir Parameters
##
mimir:
  ## Bitnami Grafana Mimir image
  ## ref: https://hub.docker.com/r/bitnami/grafana-mimir/tags/
  ## @param mimir.image.registry [default: REGISTRY_NAME] Grafana Mimir image registry
  ## @param mimir.image.repository [default: REPOSITORY_NAME/grafana-mimir] Grafana Mimir image repository
  ## @skip mimir.image.tag Grafana Mimir image tag (immutable tags are recommended)
  ## @param mimir.image.digest Grafana Mimir image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag image tag (immutable tags are recommended)
  ## @param mimir.image.pullPolicy Grafana Mimir image pull policy
  ## @param mimir.image.pullSecrets Grafana Mimir image pull secrets
  ##
  image:
    registry: docker.io
    repository: bitnami/grafana-mimir
    tag: 2.12.0-debian-12-r6
    digest: ""
    ## Specify a imagePullPolicy
    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
    ## ref: http://kubernetes.io/docs/concepts/containers/images/#pre-pulled-images
    ##
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ## e.g:
    ## pullSecrets:
    ##   - myRegistryKeySecretName
    ##
    pullSecrets: []
  ## @param mimir.dataDir path to the Mimir data directory
  ##
  dataDir: "/bitnami/grafana-mimir"
  ## @param mimir.configuration [string] Mimir components configuration
  ##
  configuration: |
    usage_stats:
      installation_mode: helm
    activity_tracker:
      filepath: {{ .Values.mimir.dataDir }}/activity.log
    alertmanager_storage:
      {{- if .Values.minio.enabled }}
      backend: s3
      s3:
        access_key_id: ${MIMIR_MINIO_ACCESS_KEY_ID}
        secret_access_key: ${MIMIR_MINIO_SECRET_ACCESS_KEY}
        bucket_name: alertmanager
        endpoint: "{{ include "grafana-mimir.minio.fullname" . }}:{{ .Values.minio.service.ports.api }}"
        insecure: {{ not .Values.minio.tls.enabled }}
      {{- else }}
      backend: {{ .Values.alertmanager.blockStorage.backend }}
      {{ .Values.alertmanager.blockStorage.backend }}:
        {{- include "common.tplvalues.render" (dict "value" .Values.alertmanager.blockStorage.config "context" $) | nindent 4 }}
      {{- end }}
    # This configures how the store-gateway synchronizes blocks stored in the bucket. It uses Minio by default for getting started (configured via flags) but this should be changed for production deployments.
    blocks_storage:
      bucket_store:
        sync_dir: {{ .Values.mimir.dataDir }}/tsdb-sync
        {{- if .Values.memcachedchunks.enabled }}
        chunks_cache:
          backend: memcached
          memcached:
            addresses: {{ include "grafana-mimir.memcached-chunks.host" . }}
            timeout: 450ms
        {{- end }}
        {{- if .Values.memcachedindex.enabled }}
        index_cache:
          backend: memcached
          memcached:
            addresses: {{ include "grafana-mimir.memcached-index.host" . }}
            timeout: 450ms
        {{- end }}
        {{- if .Values.memcachedmetadata.enabled }}
        metadata_cache:
          backend: memcached
          memcached:
            addresses: {{ include "grafana-mimir.memcached-metadata.host" . }}
            timeout: 450ms
        {{- end }}
      {{- if .Values.minio.enabled }}
      backend: s3
      s3:
        access_key_id: ${MIMIR_MINIO_ACCESS_KEY_ID}
        secret_access_key: ${MIMIR_MINIO_SECRET_ACCESS_KEY}
        bucket_name: mimir
        endpoint: "{{ include "grafana-mimir.minio.fullname" . }}:{{ .Values.minio.service.ports.api }}"
        insecure: {{ not .Values.minio.tls.enabled }}
      {{- else }}
      backend: {{ .Values.mimir.blockStorage.backend }}
      {{ .Values.mimir.blockStorage.backend }}:
        {{- include "common.tplvalues.render" (dict "value" .Values.mimir.blockStorage.config "context" $) | nindent 4 }}
      {{- end }}
      tsdb:
        dir: {{ .Values.mimir.dataDir }}/tsdb
    ingester:
      compaction_interval: 30m
      deletion_delay: 2h
      max_closing_blocks_concurrency: 2
      max_opening_blocks_concurrency: 4
      symbols_flushers_concurrency: 4
      data_dir: {{ .Values.mimir.dataDir }}/ingester
      sharding_ring:
        wait_stability_min_duration: 1m
    compactor:
      data_dir: {{ .Values.mimir.dataDir }}/compactor
    frontend:
      parallelize_shardable_queries: true
      {{- if .Values.memcachedfrontend.enabled }}
      results_cache:
        backend: memcached
        memcached:
          timeout: 500ms
          addresses: {{ include "grafana-mimir.memcached-frontend.host" . }}
      cache_results: true
      {{- end }}
      {{- if .Values.queryScheduler.enabled }}
      scheduler_address: {{ template "grafana-mimir.query-scheduler.fullname" . }}-headless.{{ .Release.Namespace }}.svc:{{ .Values.queryScheduler.service.ports.grpc }}
      {{- end }}
    frontend_worker:
      grpc_client_config:
        max_send_msg_size: 419430400 # 400MiB
      {{- if .Values.queryScheduler.enabled }}
      scheduler_address: {{ template "grafana-mimir.query-scheduler.fullname" . }}-headless.{{ .Release.Namespace }}.svc:{{ .Values.queryScheduler.service.ports.grpc }}
      {{- else }}
      frontend_address: {{ template "grafana-mimir.query-frontend.fullname" . }}-headless.{{ .Release.Namespace }}.svc:{{ .Values.queryFrontend.service.ports.grpc }}
      {{- end }}
    ingester:
      ring:
        final_sleep: 0s
        num_tokens: 512
        tokens_file_path: {{ .Values.mimir.dataDir }}/tokens
        unregister_on_shutdown: false
    ingester_client:
      grpc_client_config:
        max_recv_msg_size: 104857600
        max_send_msg_size: 104857600
    limits:
      # Limit queries to 500 days. You can override this on a per-tenant basis.
      max_total_query_length: 12000h
      # Adjust max query parallelism to 16x sharding, without sharding we can run 15d queries fully in parallel.
      # With sharding we can further shard each day another 16 times. 15 days * 16 shards = 240 subqueries.
      max_query_parallelism: 240
      # Avoid caching results newer than 10m because some samples can be delayed
      # This presents caching incomplete results
      max_cache_freshness: 10m
    memberlist:
      abort_if_cluster_join_fails: false
      compression_enabled: false
      advertise_port: {{ .Values.mimir.containerPorts.gossipRing }}
      bind_port: {{ .Values.mimir.containerPorts.gossipRing }}
      join_members:
      - dns+{{ include "grafana-mimir.gossip-ring.fullname" . }}.{{ .Release.Namespace }}.svc.{{ .Values.clusterDomain }}:{{ .Values.mimir.gossipRing.service.ports.http }}
    querier:
      # With query sharding we run more but smaller queries. We must strike a balance
      # which allows us to process more sharded queries in parallel when requested, but not overload
      # queriers during non-sharded queries.
      max_concurrent: 16
    query_scheduler:
      # Increase from default of 100 to account for queries created by query sharding
      max_outstanding_requests_per_tenant: 800
    server:
      grpc_server_max_concurrent_streams: 1000
      grpc_server_max_connection_age: 2m
      grpc_server_max_connection_age_grace: 5m
      grpc_server_max_connection_idle: 1m
      http_listen_port: {{ .Values.mimir.containerPorts.http }}
      grpc_listen_port: {{ .Values.mimir.containerPorts.grpc }}
    api:
      alertmanager_http_prefix: {{ .Values.mimir.httpPrefix.alertmanager }}
      prometheus_http_prefix: {{ .Values.mimir.httpPrefix.prometheus }}
    store_gateway:
      sharding_ring:
        wait_stability_min_duration: 1m
        tokens_file_path: {{ .Values.mimir.dataDir }}/tokens
    {{- if .Values.ruler.enabled }}
    ruler:
      alertmanager_url: dnssrvnoa+http://_http-metrics._tcp.{{ include "grafana-mimir.alertmanager.fullname" . }}-headless.{{ .Release.Namespace }}.svc.{{ .Values.clusterDomain }}/alertmanager
      enable_api: true
      rule_path: {{ .Values.mimir.dataDir }}/ruler
    ruler_storage:
      {{- if .Values.minio.enabled }}
      backend: s3
      s3:
        access_key_id: ${MIMIR_MINIO_ACCESS_KEY_ID}
        secret_access_key: ${MIMIR_MINIO_SECRET_ACCESS_KEY}
        bucket_name: ruler
        endpoint: "{{ include "grafana-mimir.minio.fullname" . }}:{{ .Values.minio.service.ports.api }}"
        insecure: {{ not .Values.minio.tls.enabled }}
      {{- else }}
      backend: {{ .Values.ruler.blockStorage.backend }}
      {{ .Values.ruler.blockStorage.backend }}:
        {{- include "common.tplvalues.render" (dict "value" .Values.ruler.blockStorage.config "context" $) | nindent 4 }}
      {{- end }}
    {{- end }}
    {{- if .Values.alertmanager.enabled }}
    alertmanager:
      data_dir: {{ .Values.mimir.dataDir }}/alert-manager
      enable_api: true
      external_url: {{ .Values.mimir.httpPrefix.alertmanager }}
    {{- if .Values.minio.enabled }}
    alertmanager_storage:
      backend: s3
      s3:
        access_key_id: ${MIMIR_MINIO_ACCESS_KEY_ID}
        secret_access_key: ${MIMIR_MINIO_SECRET_ACCESS_KEY}
        bucket_name: ruler
        endpoint: "{{ include "grafana-mimir.minio.fullname" . }}:{{ .Values.minio.service.ports.api }}"
        insecure: {{ not .Values.minio.tls.enabled }}
    {{- end }}
    {{- end }}
  ## @param mimir.overrideConfiguration [object] Mimir components configuration override. Values defined here takes precedence over mimir.configuration
  ## e.g:
  ## overrideConfiguration:
  ##   auth_enabled: true
  ##
  overrideConfiguration: {}
  ## @param mimir.existingConfigmap Name of a ConfigMap with the Mimir configuration
  ##
  existingConfigmap: ""
  ## @param mimir.httpPrefix.prometheus HTTP URL path under which the Prometheus api will be served.
  ## @param mimir.httpPrefix.alertmanager HTTP URL path under which the Alertmanager ui and api will be served.
  ##
  httpPrefix:
    prometheus: /prometheus
    alertmanager: /alertmanager
  ## @param mimir.containerPorts.http Grafana Mimir HTTP container port. This configuration is set mimir.yaml config file and is common for all Grafana Mimir components.
  ## @param mimir.containerPorts.grpc Grafana Mimir GRPC container port. This configuration is set mimir.yaml config file and is common for all Grafana Mimircomponents.
  ## @param mimir.containerPorts.gossipRing Grafana Mimir memberlist container port. This configuration is set mimir.yaml config file and is common for all Grafana Mimir components.
  ##
  containerPorts:
    http: 8080
    grpc: 9095
    gossipRing: 7946
  ## Gossip Ring parameters
  ##
  gossipRing:
    ## Gossip Ring service parameters
    ##
    service:
      ## @param mimir.gossipRing.service.ports.http Gossip Ring HTTP headless service port
      ##
      ports:
        http: 7946
      ## @param mimir.gossipRing.service.annotations Additional custom annotations for Gossip Ring headless service
      ##
      annotations: {}
  ## BlockStorage config for mimir pods
  ## ref: https://grafana.com/docs/mimir/latest/operators-guide/configure/reference-configuration-parameters/#alertmanager_storage
  ## @param mimir.blockStorage.backend Backend storage to use. NOTE: if minio.enable == true, this configuration will be ignored.
  ## @param mimir.blockStorage.config Configures connection to the backend store. NOTE: if minio.enable == true, this configuration will be ignored.
  ## e.g.:
  ## config:
  ##   access_key_id: AKIAMYACCESSKEY123456789
  ##   secret_access_key: MYSECRETACCESSKEY
  ##   region: us-east-1
  ##   bucket_name: mimir
  ##   endpoint: s3.us-east-1.amazonaws.com
  ##   insecure: false
  ##
  blockStorage:
    backend: s3
    config: {}
## @section Alertmanager Deployment Parameters
##
alertmanager:
  ## @param alertmanager.enabled Enable alertmanager deployment
  ##
  enabled: false
  ## @param alertmanager.extraEnvVars Array with extra environment variables to add to alertmanager nodes
  ## e.g:
  ## extraEnvVars:
  ##   - name: FOO
  ##     value: "bar"
  ##
  extraEnvVars: []
  ## @param alertmanager.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for alertmanager nodes
  ##
  extraEnvVarsCM: ""
  ## @param alertmanager.extraEnvVarsSecret Name of existing Secret containing extra env vars for alertmanager nodes
  ##
  extraEnvVarsSecret: ""
  ## @param alertmanager.command Override default container command (useful when using custom images)
  ##
  command: []
  ## @param alertmanager.args Override default container args (useful when using custom images)
  ##
  args: []
  ## @param alertmanager.extraArgs Add additional args to the default container args (useful to override configuration)
  ## e.g:
  ## extraArgs:
  ##   - "-log.level=debug"
  extraArgs: []
  ## @param alertmanager.replicaCount Number of Alertmanager replicas to deploy
  ##
  replicaCount: 1
  ## @param alertmanager.podManagementPolicy Statefulset Pod management policy, it needs to be Parallel to be able to complete the cluster join
  ## Ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  ##
  podManagementPolicy: OrderedReady
  ## Configure extra options for Alertmanager containers' liveness, readiness and startup probes
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  ## @param alertmanager.livenessProbe.enabled Enable livenessProbe on Alertmanager nodes
  ## @param alertmanager.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
  ## @param alertmanager.livenessProbe.periodSeconds Period seconds for livenessProbe
  ## @param alertmanager.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
  ## @param alertmanager.livenessProbe.failureThreshold Failure threshold for livenessProbe
  ## @param alertmanager.livenessProbe.successThreshold Success threshold for livenessProbe
  ##
  livenessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param alertmanager.readinessProbe.enabled Enable readinessProbe on Alertmanager nodes
  ## @param alertmanager.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
  ## @param alertmanager.readinessProbe.periodSeconds Period seconds for readinessProbe
  ## @param alertmanager.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
  ## @param alertmanager.readinessProbe.failureThreshold Failure threshold for readinessProbe
  ## @param alertmanager.readinessProbe.successThreshold Success threshold for readinessProbe
  ##
  readinessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param alertmanager.startupProbe.enabled Enable startupProbe on Alertmanager containers
  ## @param alertmanager.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe
  ## @param alertmanager.startupProbe.periodSeconds Period seconds for startupProbe
  ## @param alertmanager.startupProbe.timeoutSeconds Timeout seconds for startupProbe
  ## @param alertmanager.startupProbe.failureThreshold Failure threshold for startupProbe
  ## @param alertmanager.startupProbe.successThreshold Success threshold for startupProbe
  ##
  startupProbe:
    enabled: false
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 1
    failureThreshold: 15
    successThreshold: 1
  ## @param alertmanager.customLivenessProbe Custom livenessProbe that overrides the default one
  ##
  customLivenessProbe: {}
  ## @param alertmanager.customReadinessProbe Custom readinessProbe that overrides the default one
  ##
  customReadinessProbe: {}
  ## @param alertmanager.customStartupProbe Custom startupProbe that overrides the default one
  ##
  customStartupProbe: {}
  ## alertmanager resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param alertmanager.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if alertmanager.resources is set (alertmanager.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "nano"
  ## @param alertmanager.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
  ## Configure Pods Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param alertmanager.podSecurityContext.enabled Enabled Alertmanager pods' Security Context
  ## @param alertmanager.podSecurityContext.fsGroupChangePolicy Set filesystem group change policy
  ## @param alertmanager.podSecurityContext.sysctls Set kernel settings using the sysctl interface
  ## @param alertmanager.podSecurityContext.supplementalGroups Set filesystem extra groups
  ## @param alertmanager.podSecurityContext.fsGroup Set Alertmanager pod's Security Context fsGroup
  ##
  podSecurityContext:
    enabled: true
    fsGroupChangePolicy: Always
    sysctls: []
    supplementalGroups: []
    fsGroup: 1001
  ## Configure Container Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param alertmanager.containerSecurityContext.enabled Enabled containers' Security Context
  ## @param alertmanager.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in container
  ## @param alertmanager.containerSecurityContext.runAsUser Set containers' Security Context runAsUser
  ## @param alertmanager.containerSecurityContext.runAsGroup Set containers' Security Context runAsGroup
  ## @param alertmanager.containerSecurityContext.runAsNonRoot Set container's Security Context runAsNonRoot
  ## @param alertmanager.containerSecurityContext.privileged Set container's Security Context privileged
  ## @param alertmanager.containerSecurityContext.readOnlyRootFilesystem Set container's Security Context readOnlyRootFilesystem
  ## @param alertmanager.containerSecurityContext.allowPrivilegeEscalation Set container's Security Context allowPrivilegeEscalation
  ## @param alertmanager.containerSecurityContext.capabilities.drop List of capabilities to be dropped
  ## @param alertmanager.containerSecurityContext.seccompProfile.type Set container's Security Context seccomp profile
  ##
  containerSecurityContext:
    enabled: true
    seLinuxOptions: {}
    runAsUser: 1001
    runAsGroup: 1001
    runAsNonRoot: true
    privileged: false
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
    seccompProfile:
      type: "RuntimeDefault"
  ## @param alertmanager.lifecycleHooks for the ingester container(s) to automate configuration before or after startup
  ##
  lifecycleHooks: {}
  ## @param alertmanager.automountServiceAccountToken Mount Service Account token in pod
  ##
  automountServiceAccountToken: false
  ## @param alertmanager.hostAliases ingester pods host aliases
  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
  ##
  hostAliases: []
  ## @param alertmanager.podLabels Extra labels for ingester pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  ##
  podLabels: {}
  ## @param alertmanager.podAnnotations Annotations for ingester pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  ##
  podAnnotations: {}
  ## @param alertmanager.podAffinityPreset Pod affinity preset. Ignored if `alertmanager.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAffinityPreset: ""
  ## @param alertmanager.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `alertmanager.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAntiAffinityPreset: soft
  ## Node alertmanager.affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ##
  nodeAffinityPreset:
    ## @param alertmanager.nodeAffinityPreset.type Node affinity preset type. Ignored if `alertmanager.affinity` is set. Allowed values: `soft` or `hard`
    ##
    type: ""
    ## @param alertmanager.nodeAffinityPreset.key Node label key to match. Ignored if `alertmanager.affinity` is set
    ##
    key: ""
    ## @param alertmanager.nodeAffinityPreset.values Node label values to match. Ignored if `alertmanager.affinity` is set
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []
  ## @param alertmanager.affinity Affinity for Alertmanager pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## NOTE: `alertmanager.podAffinityPreset`, `alertmanager.podAntiAffinityPreset`, and `alertmanager.nodeAffinityPreset` will be ignored when it's set
  ##
  affinity: {}
  ## @param alertmanager.nodeSelector Node labels for Alertmanager pods assignment
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/
  ##
  nodeSelector: {}
  ## @param alertmanager.tolerations Tolerations for Alertmanager pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  ## @param alertmanager.topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains
  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
  ##
  topologySpreadConstraints: []
  ## @param alertmanager.priorityClassName Alertmanager pods' priorityClassName
  ##
  priorityClassName: ""
  ## @param alertmanager.schedulerName Kubernetes pod scheduler registry
  ## https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  schedulerName: ""
  ## @param alertmanager.terminationGracePeriodSeconds Seconds pod needs to terminate gracefully
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods
  ##
  terminationGracePeriodSeconds: ""
  ## @param alertmanager.updateStrategy.type Alertmanager statefulset strategy type
  ## @param alertmanager.updateStrategy.rollingUpdate Alertmanager statefulset rolling update configuration parameters
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  ##
  updateStrategy:
    type: RollingUpdate
    rollingUpdate: {}
  ## @param alertmanager.extraVolumes Optionally specify extra list of additional volumes for the Alertmanager pod(s)
  ##
  extraVolumes: []
  ## @param alertmanager.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the Alertmanager container(s)
  ##
  extraVolumeMounts: []
  ## @param alertmanager.sidecars Add additional sidecar containers to the Alertmanager pod(s)
  ## e.g:
  ## sidecars:
  ##   - name: your-image-name
  ##     image: your-image
  ##     imagePullPolicy: Always
  ##     ports:
  ##       - name: portname
  ##         containerPort: 1234
  ##
  sidecars: []
  ## @param alertmanager.initContainers Add additional init containers to the Alertmanager pod(s)
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  ## e.g:
  ## initContainers:
  ##  - name: your-image-name
  ##    image: your-image
  ##    imagePullPolicy: Always
  ##    command: ['sh', '-c', 'echo "hello world"']
  ##
  initContainers: []
  ## Enable persistence using Persistent Volume Claims
  ## ref: https://kubernetes.io/docs/concepts/storage/persistent-volumes/
  ##
  persistence:
    ## @param alertmanager.persistence.enabled Enable persistence in alertmanager instances
    ##
    enabled: true
    ## @param alertmanager.persistence.storageClass PVC Storage Class for alertmanager data volume
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    storageClass: ""
    ## @param alertmanager.persistence.accessModes PVC Access modes
    ##
    accessModes:
      - ReadWriteOnce
    ## @param alertmanager.persistence.size PVC Storage Request for alertmanager data volume
    ##
    size: 8Gi
    ## @param alertmanager.persistence.annotations Additional PVC annotations
    ##
    annotations: {}
    ## @param alertmanager.persistence.selector Selector to match an existing Persistent Volume for alertmanager's data PVC
    ## If set, the PVC can't have a PV dynamically provisioned for it
    ## E.g.
    ## selector:
    ##   matchLabels:
    ##     app: my-app
    ##
    selector: {}
    ## @param alertmanager.persistence.dataSource PVC data source
    ##
    dataSource: {}
  ## @section Alertmanager Traffic Exposure Parameters
  ##

  ## ingester service parameters
  ##
  service:
    ## @param alertmanager.service.type Alertmanager service type
    ##
    type: ClusterIP
    ## @param alertmanager.service.ports.http Alertmanager HTTP service port
    ## @param alertmanager.service.ports.grpc Alertmanager GRPC service port
    ##
    ports:
      http: 8080
      grpc: 9095
    ## Node ports to expose
    ## NOTE: choose port between <30000-32767>
    ## @param alertmanager.service.nodePorts.http Node port for HTTP
    ## @param alertmanager.service.nodePorts.grpc Node port for GRPC
    ##
    nodePorts:
      http: ""
      grpc: 9095
    ## @param alertmanager.service.sessionAffinityConfig Additional settings for the sessionAffinity
    ## sessionAffinityConfig:
    ##   clientIP:
    ##     timeoutSeconds: 300
    ##
    sessionAffinityConfig: {}
    ## @param alertmanager.service.sessionAffinity Control where client requests go, to the same pod or round-robin
    ## Values: ClientIP or None
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/
    ##
    sessionAffinity: None
    ## @param alertmanager.service.clusterIP Alertmanager service Cluster IP
    ## e.g.:
    ## clusterIP: None
    ##
    clusterIP: ""
    ## @param alertmanager.service.loadBalancerIP Alertmanager service Load Balancer IP
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer
    ##
    loadBalancerIP: ""
    ## @param alertmanager.service.loadBalancerSourceRanges Alertmanager service Load Balancer sources
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
    ## e.g:
    ## loadBalancerSourceRanges:
    ##   - 10.10.10.0/24
    ##
    loadBalancerSourceRanges: []
    ## @param alertmanager.service.externalTrafficPolicy Alertmanager service external traffic policy
    ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    externalTrafficPolicy: Cluster
    ## @param alertmanager.service.annotations Additional custom annotations for Alertmanager service
    ##
    annotations: {}
    ## @param alertmanager.service.extraPorts Extra ports to expose in the Alertmanager service
    ##
    extraPorts: []
    ## Headless service properties
    ##
    headless:
      ## @param alertmanager.service.headless.annotations Annotations for the headless service.
      ##
      annotations: {}
  ## Network Policies
  ## Ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/
  ##
  networkPolicy:
    ## @param alertmanager.networkPolicy.enabled Specifies whether a NetworkPolicy should be created
    ##
    enabled: true
    ## @param alertmanager.networkPolicy.allowExternal Don't require server label for connections
    ## The Policy model to apply. When set to false, only pods with the correct
    ## server label will have network access to the ports server is listening
    ## on. When true, server will accept connections from any source
    ## (with the correct destination port).
    ##
    allowExternal: true
    ## @param alertmanager.networkPolicy.allowExternalEgress Allow the pod to access any range of port and all destinations.
    ##
    allowExternalEgress: true
    ## @param alertmanager.networkPolicy.extraIngress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraIngress:
    ##   - ports:
    ##       - port: 1234
    ##     from:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    extraIngress: []
    ## @param alertmanager.networkPolicy.extraEgress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraEgress:
    ##   - ports:
    ##       - port: 1234
    ##     to:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    ##
    extraEgress: []
    ## @param alertmanager.networkPolicy.ingressNSMatchLabels [object] Labels to match to allow traffic from other namespaces
    ## @param alertmanager.networkPolicy.ingressNSPodMatchLabels [object] Pod labels to match to allow traffic from other namespaces
    ##
    ingressNSMatchLabels: {}
    ingressNSPodMatchLabels: {}
  ## Pod Disruption Budget configuration
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb
  ## @param alertmanager.pdb.create Enable/disable a Pod Disruption Budget creation
  ## @param alertmanager.pdb.minAvailable Minimum number/percentage of pods that should remain scheduled
  ## @param alertmanager.pdb.maxUnavailable Maximum number/percentage of pods that may be made unavailable
  ##
  pdb:
    create: false
    minAvailable: 1
    maxUnavailable: ""
  ## BlockStorage config for alertmanager pods
  ## ref: https://grafana.com/docs/mimir/latest/operators-guide/configure/reference-configuration-parameters/#alertmanager_storage
  ## @param alertmanager.blockStorage.backend Backend storage to use. NOTE: if minio.enable == true, this configuration will be ignored.
  ## @param alertmanager.blockStorage.config Configures connection to the backend store. NOTE: if minio.enable == true, this configuration will be ignored.
  ## e.g.:
  ## config:
  ##   access_key_id: AKIAMYACCESSKEY123456789
  ##   secret_access_key: MYSECRETACCESSKEY
  ##   region: us-east-1
  ##   bucket_name: alertmanager
  ##   endpoint: s3.us-east-1.amazonaws.com
  ##   insecure: false
  ##
  blockStorage:
    backend: s3
    config: {}
## @section Compactor Deployment Parameters
##
compactor:
  ## @param compactor.extraEnvVars Array with extra environment variables to add to compactor nodes
  ## e.g:
  ## extraEnvVars:
  ##   - name: FOO
  ##     value: "bar"
  ##
  extraEnvVars: []
  ## @param compactor.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for compactor nodes
  ##
  extraEnvVarsCM: ""
  ## @param compactor.extraEnvVarsSecret Name of existing Secret containing extra env vars for compactor nodes
  ##
  extraEnvVarsSecret: ""
  ## @param compactor.command Override default container command (useful when using custom images)
  ##
  command: []
  ## @param compactor.args Override default container args (useful when using custom images)
  ##
  args: []
  ## @param compactor.extraArgs Add additional args to the default container args (useful to override configuration)
  ## e.g:
  ## extraArgs:
  ##   - "-log.level=debug"
  extraArgs: []
  ## @param compactor.replicaCount Number of Compactor replicas to deploy
  ##
  replicaCount: 1
  ## @param compactor.podManagementPolicy Statefulset Pod management policy, it needs to be Parallel to be able to complete the cluster join
  ## Ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  ##
  podManagementPolicy: OrderedReady
  ## Configure extra options for Compactor containers' liveness, readiness and startup probes
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  ## @param compactor.livenessProbe.enabled Enable livenessProbe on Compactor nodes
  ## @param compactor.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
  ## @param compactor.livenessProbe.periodSeconds Period seconds for livenessProbe
  ## @param compactor.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
  ## @param compactor.livenessProbe.failureThreshold Failure threshold for livenessProbe
  ## @param compactor.livenessProbe.successThreshold Success threshold for livenessProbe
  ##
  livenessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param compactor.readinessProbe.enabled Enable readinessProbe on Compactor nodes
  ## @param compactor.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
  ## @param compactor.readinessProbe.periodSeconds Period seconds for readinessProbe
  ## @param compactor.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
  ## @param compactor.readinessProbe.failureThreshold Failure threshold for readinessProbe
  ## @param compactor.readinessProbe.successThreshold Success threshold for readinessProbe
  ##
  readinessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param compactor.startupProbe.enabled Enable startupProbe on Compactor containers
  ## @param compactor.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe
  ## @param compactor.startupProbe.periodSeconds Period seconds for startupProbe
  ## @param compactor.startupProbe.timeoutSeconds Timeout seconds for startupProbe
  ## @param compactor.startupProbe.failureThreshold Failure threshold for startupProbe
  ## @param compactor.startupProbe.successThreshold Success threshold for startupProbe
  ##
  startupProbe:
    enabled: false
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 1
    failureThreshold: 15
    successThreshold: 1
  ## @param compactor.customLivenessProbe Custom livenessProbe that overrides the default one
  ##
  customLivenessProbe: {}
  ## @param compactor.customReadinessProbe Custom readinessProbe that overrides the default one
  ##
  customReadinessProbe: {}
  ## @param compactor.customStartupProbe Custom startupProbe that overrides the default one
  ##
  customStartupProbe: {}
  ## compactor resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param compactor.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if compactor.resources is set (compactor.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "nano"
  ## @param compactor.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
  ## Configure Pods Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param compactor.podSecurityContext.enabled Enabled Compactor pods' Security Context
  ## @param compactor.podSecurityContext.fsGroupChangePolicy Set filesystem group change policy
  ## @param compactor.podSecurityContext.sysctls Set kernel settings using the sysctl interface
  ## @param compactor.podSecurityContext.supplementalGroups Set filesystem extra groups
  ## @param compactor.podSecurityContext.fsGroup Set Compactor pod's Security Context fsGroup
  ##
  podSecurityContext:
    enabled: true
    fsGroupChangePolicy: Always
    sysctls: []
    supplementalGroups: []
    fsGroup: 1001
  ## Configure Container Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param compactor.containerSecurityContext.enabled Enabled containers' Security Context
  ## @param compactor.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in container
  ## @param compactor.containerSecurityContext.runAsUser Set containers' Security Context runAsUser
  ## @param compactor.containerSecurityContext.runAsGroup Set containers' Security Context runAsGroup
  ## @param compactor.containerSecurityContext.runAsNonRoot Set container's Security Context runAsNonRoot
  ## @param compactor.containerSecurityContext.privileged Set container's Security Context privileged
  ## @param compactor.containerSecurityContext.readOnlyRootFilesystem Set container's Security Context readOnlyRootFilesystem
  ## @param compactor.containerSecurityContext.allowPrivilegeEscalation Set container's Security Context allowPrivilegeEscalation
  ## @param compactor.containerSecurityContext.capabilities.drop List of capabilities to be dropped
  ## @param compactor.containerSecurityContext.seccompProfile.type Set container's Security Context seccomp profile
  ##
  containerSecurityContext:
    enabled: true
    seLinuxOptions: {}
    runAsUser: 1001
    runAsGroup: 1001
    runAsNonRoot: true
    privileged: false
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
    seccompProfile:
      type: "RuntimeDefault"
  ## @param compactor.lifecycleHooks for the compactor container(s) to automate configuration before or after startup
  ##
  lifecycleHooks: {}
  ## @param compactor.automountServiceAccountToken Mount Service Account token in pod
  ##
  automountServiceAccountToken: false
  ## @param compactor.hostAliases compactor pods host aliases
  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
  ##
  hostAliases: []
  ## @param compactor.podLabels Extra labels for compactor pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  ##
  podLabels: {}
  ## @param compactor.podAnnotations Annotations for compactor pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  ##
  podAnnotations: {}
  ## @param compactor.podAffinityPreset Pod affinity preset. Ignored if `compactor.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAffinityPreset: ""
  ## @param compactor.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `compactor.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAntiAffinityPreset: soft
  ## Node compactor.affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ##
  nodeAffinityPreset:
    ## @param compactor.nodeAffinityPreset.type Node affinity preset type. Ignored if `compactor.affinity` is set. Allowed values: `soft` or `hard`
    ##
    type: ""
    ## @param compactor.nodeAffinityPreset.key Node label key to match. Ignored if `compactor.affinity` is set
    ##
    key: ""
    ## @param compactor.nodeAffinityPreset.values Node label values to match. Ignored if `compactor.affinity` is set
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []
  ## @param compactor.affinity Affinity for Compactor pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## NOTE: `compactor.podAffinityPreset`, `compactor.podAntiAffinityPreset`, and `compactor.nodeAffinityPreset` will be ignored when it's set
  ##
  affinity: {}
  ## @param compactor.nodeSelector Node labels for Compactor pods assignment
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/
  ##
  nodeSelector: {}
  ## @param compactor.tolerations Tolerations for Compactor pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  ## @param compactor.topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains
  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
  ##
  topologySpreadConstraints: []
  ## @param compactor.priorityClassName Compactor pods' priorityClassName
  ##
  priorityClassName: ""
  ## @param compactor.schedulerName Kubernetes pod scheduler registry
  ## https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  schedulerName: ""
  ## @param compactor.terminationGracePeriodSeconds Seconds pod needs to terminate gracefully
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods
  ##
  terminationGracePeriodSeconds: ""
  ## @param compactor.updateStrategy.type Compactor statefulset strategy type
  ## @param compactor.updateStrategy.rollingUpdate Compactor statefulset rolling update configuration parameters
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  ##
  updateStrategy:
    type: RollingUpdate
    rollingUpdate: {}
  ## @param compactor.extraVolumes Optionally specify extra list of additional volumes for the Compactor pod(s)
  ##
  extraVolumes: []
  ## @param compactor.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the Compactor container(s)
  ##
  extraVolumeMounts: []
  ## @param compactor.sidecars Add additional sidecar containers to the Compactor pod(s)
  ## e.g:
  ## sidecars:
  ##   - name: your-image-name
  ##     image: your-image
  ##     imagePullPolicy: Always
  ##     ports:
  ##       - name: portname
  ##         containerPort: 1234
  ##
  sidecars: []
  ## @param compactor.initContainers Add additional init containers to the Compactor pod(s)
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  ## e.g:
  ## initContainers:
  ##  - name: your-image-name
  ##    image: your-image
  ##    imagePullPolicy: Always
  ##    command: ['sh', '-c', 'echo "hello world"']
  ##
  initContainers: []
  ## Enable persistence using Persistent Volume Claims
  ## ref: https://kubernetes.io/docs/concepts/storage/persistent-volumes/
  ##
  persistence:
    ## @param compactor.persistence.enabled Enable persistence in Compactor instances
    ##
    enabled: true
    ## @param compactor.persistence.storageClass PVC Storage Class for Compactor data volume
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    storageClass: ""
    ## @param compactor.persistence.accessModes PVC Access modes
    ##
    accessModes:
      - ReadWriteOnce
    ## @param compactor.persistence.size PVC Storage Request for Compactor data volume
    ##
    size: 8Gi
    ## @param compactor.persistence.annotations Additional PVC annotations
    ##
    annotations: {}
    ## @param compactor.persistence.selector Selector to match an existing Persistent Volume for Compactor's data PVC
    ## If set, the PVC can't have a PV dynamically provisioned for it
    ## E.g.
    ## selector:
    ##   matchLabels:
    ##     app: my-app
    ##
    selector: {}
    ## @param compactor.persistence.dataSource PVC data source
    ##
    dataSource: {}
  ## @section Compactor Traffic Exposure Parameters
  ##

  ## compactor service parameters
  ##
  service:
    ## @param compactor.service.type Compactor service type
    ##
    type: ClusterIP
    ## @param compactor.service.ports.http Compactor HTTP service port
    ## @param compactor.service.ports.grpc Compactor GRPC service port
    ##
    ports:
      http: 8080
      grpc: 9095
    ## Node ports to expose
    ## NOTE: choose port between <30000-32767>
    ## @param compactor.service.nodePorts.http Node port for HTTP
    ## @param compactor.service.nodePorts.grpc Node port for GRPC
    ##
    nodePorts:
      http: ""
      grpc: 9095
    ## @param compactor.service.sessionAffinityConfig Additional settings for the sessionAffinity
    ## sessionAffinityConfig:
    ##   clientIP:
    ##     timeoutSeconds: 300
    ##
    sessionAffinityConfig: {}
    ## @param compactor.service.sessionAffinity Control where client requests go, to the same pod or round-robin
    ## Values: ClientIP or None
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/
    ##
    sessionAffinity: None
    ## @param compactor.service.clusterIP Compactor service Cluster IP
    ## e.g.:
    ## clusterIP: None
    ##
    clusterIP: ""
    ## @param compactor.service.loadBalancerIP Compactor service Load Balancer IP
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer
    ##
    loadBalancerIP: ""
    ## @param compactor.service.loadBalancerSourceRanges Compactor service Load Balancer sources
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
    ## e.g:
    ## loadBalancerSourceRanges:
    ##   - 10.10.10.0/24
    ##
    loadBalancerSourceRanges: []
    ## @param compactor.service.externalTrafficPolicy Compactor service external traffic policy
    ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    externalTrafficPolicy: Cluster
    ## @param compactor.service.annotations Additional custom annotations for Compactor service
    ##
    annotations: {}
    ## @param compactor.service.extraPorts Extra ports to expose in the Compactor service
    ##
    extraPorts: []
  ## Network Policies
  ## Ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/
  ##
  networkPolicy:
    ## @param compactor.networkPolicy.enabled Specifies whether a NetworkPolicy should be created
    ##
    enabled: true
    ## @param compactor.networkPolicy.allowExternal Don't require server label for connections
    ## The Policy model to apply. When set to false, only pods with the correct
    ## server label will have network access to the ports server is listening
    ## on. When true, server will accept connections from any source
    ## (with the correct destination port).
    ##
    allowExternal: true
    ## @param compactor.networkPolicy.allowExternalEgress Allow the pod to access any range of port and all destinations.
    ##
    allowExternalEgress: true
    ## @param compactor.networkPolicy.extraIngress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraIngress:
    ##   - ports:
    ##       - port: 1234
    ##     from:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    extraIngress: []
    ## @param compactor.networkPolicy.extraEgress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraEgress:
    ##   - ports:
    ##       - port: 1234
    ##     to:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    ##
    extraEgress: []
    ## @param compactor.networkPolicy.ingressNSMatchLabels [object] Labels to match to allow traffic from other namespaces
    ## @param compactor.networkPolicy.ingressNSPodMatchLabels [object] Pod labels to match to allow traffic from other namespaces
    ##
    ingressNSMatchLabels: {}
    ingressNSPodMatchLabels: {}
  ## Pod Disruption Budget configuration
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb
  ## @param compactor.pdb.create Enable/disable a Pod Disruption Budget creation
  ## @param compactor.pdb.minAvailable Minimum number/percentage of pods that should remain scheduled
  ## @param compactor.pdb.maxUnavailable Maximum number/percentage of pods that may be made unavailable
  ##
  pdb:
    create: false
    minAvailable: 1
    maxUnavailable: ""
## @section Distributor Deployment Parameters
##
distributor:
  ## @param distributor.extraEnvVars Array with extra environment variables to add to distributor nodes
  ## e.g:
  ## extraEnvVars:
  ##   - name: FOO
  ##     value: "bar"
  ##
  extraEnvVars: []
  ## @param distributor.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for distributor nodes
  ##
  extraEnvVarsCM: ""
  ## @param distributor.extraEnvVarsSecret Name of existing Secret containing extra env vars for distributor nodes
  ##
  extraEnvVarsSecret: ""
  ## @param distributor.command Override default container command (useful when using custom images)
  ##
  command: []
  ## @param distributor.args Override default container args (useful when using custom images)
  ##
  args: []
  ## @param distributor.extraArgs Add additional args to the default container args (useful to override configuration)
  ## e.g:
  ## extraArgs:
  ##   - "-log.level=debug"
  extraArgs: []
  ## @param distributor.replicaCount Number of Distributor replicas to deploy
  ##
  replicaCount: 1
  ## Configure extra options for Distributor containers' liveness, readiness and startup probes
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  ## @param distributor.livenessProbe.enabled Enable livenessProbe on Distributor nodes
  ## @param distributor.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
  ## @param distributor.livenessProbe.periodSeconds Period seconds for livenessProbe
  ## @param distributor.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
  ## @param distributor.livenessProbe.failureThreshold Failure threshold for livenessProbe
  ## @param distributor.livenessProbe.successThreshold Success threshold for livenessProbe
  ##
  livenessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param distributor.readinessProbe.enabled Enable readinessProbe on Distributor nodes
  ## @param distributor.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
  ## @param distributor.readinessProbe.periodSeconds Period seconds for readinessProbe
  ## @param distributor.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
  ## @param distributor.readinessProbe.failureThreshold Failure threshold for readinessProbe
  ## @param distributor.readinessProbe.successThreshold Success threshold for readinessProbe
  ##
  readinessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param distributor.startupProbe.enabled Enable startupProbe on Distributor containers
  ## @param distributor.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe
  ## @param distributor.startupProbe.periodSeconds Period seconds for startupProbe
  ## @param distributor.startupProbe.timeoutSeconds Timeout seconds for startupProbe
  ## @param distributor.startupProbe.failureThreshold Failure threshold for startupProbe
  ## @param distributor.startupProbe.successThreshold Success threshold for startupProbe
  ##
  startupProbe:
    enabled: false
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 1
    failureThreshold: 15
    successThreshold: 1
  ## @param distributor.customLivenessProbe Custom livenessProbe that overrides the default one
  ##
  customLivenessProbe: {}
  ## @param distributor.customReadinessProbe Custom readinessProbe that overrides the default one
  ##
  customReadinessProbe: {}
  ## @param distributor.customStartupProbe Custom startupProbe that overrides the default one
  ##
  customStartupProbe: {}
  ## Distributor resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param distributor.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if distributor.resources is set (distributor.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "nano"
  ## @param distributor.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
  ## Configure Pods Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param distributor.podSecurityContext.enabled Enabled Distributor pods' Security Context
  ## @param distributor.podSecurityContext.fsGroupChangePolicy Set filesystem group change policy
  ## @param distributor.podSecurityContext.sysctls Set kernel settings using the sysctl interface
  ## @param distributor.podSecurityContext.supplementalGroups Set filesystem extra groups
  ## @param distributor.podSecurityContext.fsGroup Set Distributor pod's Security Context fsGroup
  ##
  podSecurityContext:
    enabled: true
    fsGroupChangePolicy: Always
    sysctls: []
    supplementalGroups: []
    fsGroup: 1001
  ## Configure Container Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param distributor.containerSecurityContext.enabled Enabled containers' Security Context
  ## @param distributor.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in container
  ## @param distributor.containerSecurityContext.runAsUser Set containers' Security Context runAsUser
  ## @param distributor.containerSecurityContext.runAsGroup Set containers' Security Context runAsGroup
  ## @param distributor.containerSecurityContext.runAsNonRoot Set container's Security Context runAsNonRoot
  ## @param distributor.containerSecurityContext.privileged Set container's Security Context privileged
  ## @param distributor.containerSecurityContext.readOnlyRootFilesystem Set container's Security Context readOnlyRootFilesystem
  ## @param distributor.containerSecurityContext.allowPrivilegeEscalation Set container's Security Context allowPrivilegeEscalation
  ## @param distributor.containerSecurityContext.capabilities.drop List of capabilities to be dropped
  ## @param distributor.containerSecurityContext.seccompProfile.type Set container's Security Context seccomp profile
  ##
  containerSecurityContext:
    enabled: true
    seLinuxOptions: {}
    runAsUser: 1001
    runAsGroup: 1001
    runAsNonRoot: true
    privileged: false
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
    seccompProfile:
      type: "RuntimeDefault"
  ## @param distributor.lifecycleHooks for the distributor container(s) to automate configuration before or after startup
  ##
  lifecycleHooks: {}
  ## @param distributor.automountServiceAccountToken Mount Service Account token in pod
  ##
  automountServiceAccountToken: false
  ## @param distributor.hostAliases distributor pods host aliases
  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
  ##
  hostAliases: []
  ## @param distributor.podLabels Extra labels for distributor pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  ##
  podLabels: {}
  ## @param distributor.podAnnotations Annotations for distributor pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  ##
  podAnnotations: {}
  ## @param distributor.podAffinityPreset Pod affinity preset. Ignored if `distributor.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAffinityPreset: ""
  ## @param distributor.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `distributor.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAntiAffinityPreset: soft
  ## Node distributor.affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ##
  nodeAffinityPreset:
    ## @param distributor.nodeAffinityPreset.type Node affinity preset type. Ignored if `distributor.affinity` is set. Allowed values: `soft` or `hard`
    ##
    type: ""
    ## @param distributor.nodeAffinityPreset.key Node label key to match. Ignored if `distributor.affinity` is set
    ##
    key: ""
    ## @param distributor.nodeAffinityPreset.values Node label values to match. Ignored if `distributor.affinity` is set
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []
  ## @param distributor.affinity Affinity for Distributor pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## NOTE: `distributor.podAffinityPreset`, `distributor.podAntiAffinityPreset`, and `distributor.nodeAffinityPreset` will be ignored when it's set
  ##
  affinity: {}
  ## @param distributor.nodeSelector Node labels for Distributor pods assignment
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/
  ##
  nodeSelector: {}
  ## @param distributor.tolerations Tolerations for Distributor pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  ## @param distributor.topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains
  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
  ##
  topologySpreadConstraints: []
  ## @param distributor.priorityClassName Distributor pods' priorityClassName
  ##
  priorityClassName: ""
  ## @param distributor.schedulerName Kubernetes pod scheduler registry
  ## https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  schedulerName: ""
  ## @param distributor.terminationGracePeriodSeconds Seconds pod needs to terminate gracefully
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods
  ##
  terminationGracePeriodSeconds: ""
  ## @param distributor.updateStrategy.type Distributor statefulset strategy type
  ## @param distributor.updateStrategy.rollingUpdate Distributor statefulset rolling update configuration parameters
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  ##
  updateStrategy:
    type: RollingUpdate
    rollingUpdate: {}
  ## @param distributor.extraVolumes Optionally specify extra list of additional volumes for the Distributor pod(s)
  ##
  extraVolumes: []
  ## @param distributor.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the Distributor container(s)
  ##
  extraVolumeMounts: []
  ## @param distributor.sidecars Add additional sidecar containers to the Distributor pod(s)
  ## e.g:
  ## sidecars:
  ##   - name: your-image-name
  ##     image: your-image
  ##     imagePullPolicy: Always
  ##     ports:
  ##       - name: portname
  ##         containerPort: 1234
  ##
  sidecars: []
  ## @param distributor.initContainers Add additional init containers to the Distributor pod(s)
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  ## e.g:
  ## initContainers:
  ##  - name: your-image-name
  ##    image: your-image
  ##    imagePullPolicy: Always
  ##    command: ['sh', '-c', 'echo "hello world"']
  ##
  initContainers: []
  ## @section Distributor Traffic Exposure Parameters
  ##

  ## distributor service parameters
  ##
  service:
    ## @param distributor.service.type Distributor service type
    ##
    type: ClusterIP
    ## @param distributor.service.ports.http Distributor HTTP service port
    ## @param distributor.service.ports.grpc Distributor GRPC service port
    ##
    ports:
      http: 8080
      grpc: 9095
    ## Node ports to expose
    ## NOTE: choose port between <30000-32767>
    ## @param distributor.service.nodePorts.http Node port for HTTP
    ## @param distributor.service.nodePorts.grpc Node port for GRPC
    ##
    nodePorts:
      http: ""
      grpc: 9095
    ## @param distributor.service.sessionAffinityConfig Additional settings for the sessionAffinity
    ## sessionAffinityConfig:
    ##   clientIP:
    ##     timeoutSeconds: 300
    ##
    sessionAffinityConfig: {}
    ## @param distributor.service.sessionAffinity Control where client requests go, to the same pod or round-robin
    ## Values: ClientIP or None
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/
    ##
    sessionAffinity: None
    ## @param distributor.service.clusterIP Distributor service Cluster IP
    ## e.g.:
    ## clusterIP: None
    ##
    clusterIP: ""
    ## @param distributor.service.loadBalancerIP Distributor service Load Balancer IP
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer
    ##
    loadBalancerIP: ""
    ## @param distributor.service.loadBalancerSourceRanges Distributor service Load Balancer sources
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
    ## e.g:
    ## loadBalancerSourceRanges:
    ##   - 10.10.10.0/24
    ##
    loadBalancerSourceRanges: []
    ## @param distributor.service.externalTrafficPolicy Distributor service external traffic policy
    ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    externalTrafficPolicy: Cluster
    ## @param distributor.service.annotations Additional custom annotations for Distributor service
    ##
    annotations: {}
    ## @param distributor.service.extraPorts Extra ports to expose in the Distributor service
    ##
    extraPorts: []
    ## Headless service properties
    ##
    headless:
      ## @param distributor.service.headless.annotations Annotations for the headless service.
      ##
      annotations: {}
  ## Network Policies
  ## Ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/
  ##
  networkPolicy:
    ## @param distributor.networkPolicy.enabled Specifies whether a NetworkPolicy should be created
    ##
    enabled: true
    ## @param distributor.networkPolicy.allowExternal Don't require server label for connections
    ## The Policy model to apply. When set to false, only pods with the correct
    ## server label will have network access to the ports server is listening
    ## on. When true, server will accept connections from any source
    ## (with the correct destination port).
    ##
    allowExternal: true
    ## @param distributor.networkPolicy.allowExternalEgress Allow the pod to access any range of port and all destinations.
    ##
    allowExternalEgress: true
    ## @param distributor.networkPolicy.extraIngress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraIngress:
    ##   - ports:
    ##       - port: 1234
    ##     from:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    extraIngress: []
    ## @param distributor.networkPolicy.extraEgress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraEgress:
    ##   - ports:
    ##       - port: 1234
    ##     to:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    ##
    extraEgress: []
    ## @param distributor.networkPolicy.ingressNSMatchLabels [object] Labels to match to allow traffic from other namespaces
    ## @param distributor.networkPolicy.ingressNSPodMatchLabels [object] Pod labels to match to allow traffic from other namespaces
    ##
    ingressNSMatchLabels: {}
    ingressNSPodMatchLabels: {}
  ## Pod Disruption Budget configuration
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb
  ## @param distributor.pdb.create Enable/disable a Pod Disruption Budget creation
  ## @param distributor.pdb.minAvailable Minimum number/percentage of pods that should remain scheduled
  ## @param distributor.pdb.maxUnavailable Maximum number/percentage of pods that may be made unavailable
  ##
  pdb:
    create: false
    minAvailable: 1
    maxUnavailable: ""
## @section Gateway Deployment Parameters
##
gateway:
  ## @param gateway.enabled Enable Gateway deployment
  ##
  enabled: true
  ## Bitnami Nginx image
  ## ref: https://hub.docker.com/r/bitnami/grafana-nginx/tags/
  ## @param gateway.image.registry [default: REGISTRY_NAME] Nginx image registry
  ## @param gateway.image.repository [default: REPOSITORY_NAME/nginx] Nginx image repository
  ## @skip gateway.image.tag Nginx image tag (immutable tags are recommended)
  ## @param gateway.image.digest Nginx image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag
  ## @param gateway.image.pullPolicy Nginx image pull policy
  ## @param gateway.image.pullSecrets Nginx image pull secrets
  ## @param gateway.image.debug Enable debugging in the initialization process
  ##
  image:
    registry: docker.io
    repository: bitnami/nginx
    tag: 1.26.0-debian-12-r0
    digest: ""
    ## Specify a imagePullPolicy
    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
    ## ref: https://kubernetes.io/docs/concepts/containers/images/#pre-pulled-images
    ##
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ## e.g:
    ## pullSecrets:
    ##   - myRegistryKeySecretName
    ##
    pullSecrets: []
    debug: false
  ## @param gateway.extraEnvVars Array with extra environment variables to add to gateway nodes
  ## e.g:
  ## extraEnvVars:
  ##   - name: FOO
  ##     value: "bar"
  ##
  extraEnvVars: []
  ## @param gateway.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for gateway nodes
  ##
  extraEnvVarsCM: ""
  ## @param gateway.extraEnvVarsSecret Name of existing Secret containing extra env vars for gateway nodes
  ##
  extraEnvVarsSecret: ""
  ## @param gateway.command Override default container command (useful when using custom images)
  ##
  command: []
  ## @param gateway.args Override default container args (useful when using custom images)
  ##
  args: []
  ## @param gateway.verboseLogging Show the gateway access_log
  ##
  verboseLogging: false
  ## @param gateway.replicaCount Number of Gateway replicas to deploy
  ##
  replicaCount: 1
  ## @param gateway.auth.enabled Enable basic auth
  ## @param gateway.auth.username Basic auth username
  ## @param gateway.auth.password Basic auth password
  ## @param gateway.auth.existingSecret Name of a secret containing the Basic auth password
  ##
  auth:
    enabled: false
    username: "user"
    password: ""
    existingSecret: ""
  ## Configure extra options for Gateway containers' liveness, readiness and startup probes
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  ## @param gateway.livenessProbe.enabled Enable livenessProbe on Gateway nodes
  ## @param gateway.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
  ## @param gateway.livenessProbe.periodSeconds Period seconds for livenessProbe
  ## @param gateway.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
  ## @param gateway.livenessProbe.failureThreshold Failure threshold for livenessProbe
  ## @param gateway.livenessProbe.successThreshold Success threshold for livenessProbe
  ##
  livenessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 10
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param gateway.readinessProbe.enabled Enable readinessProbe on Gateway nodes
  ## @param gateway.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
  ## @param gateway.readinessProbe.periodSeconds Period seconds for readinessProbe
  ## @param gateway.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
  ## @param gateway.readinessProbe.failureThreshold Failure threshold for readinessProbe
  ## @param gateway.readinessProbe.successThreshold Success threshold for readinessProbe
  ##
  readinessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 10
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param gateway.startupProbe.enabled Enable startupProbe on Gateway containers
  ## @param gateway.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe
  ## @param gateway.startupProbe.periodSeconds Period seconds for startupProbe
  ## @param gateway.startupProbe.timeoutSeconds Timeout seconds for startupProbe
  ## @param gateway.startupProbe.failureThreshold Failure threshold for startupProbe
  ## @param gateway.startupProbe.successThreshold Success threshold for startupProbe
  ##
  startupProbe:
    enabled: false
    initialDelaySeconds: 10
    periodSeconds: 10
    timeoutSeconds: 1
    failureThreshold: 15
    successThreshold: 1
  ## @param gateway.customLivenessProbe Custom livenessProbe that overrides the default one
  ##
  customLivenessProbe: {}
  ## @param gateway.customReadinessProbe Custom readinessProbe that overrides the default one
  ##
  customReadinessProbe: {}
  ## @param gateway.customStartupProbe Custom startupProbe that overrides the default one
  ##
  customStartupProbe: {}
  ## @param gateway.containerPorts.http Gateway HTTP port
  ##
  containerPorts:
    http: 8080
  ## gateway resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param gateway.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if gateway.resources is set (gateway.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "nano"
  ## @param gateway.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
  ## Configure Pods Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param gateway.podSecurityContext.enabled Enabled Gateway pods' Security Context
  ## @param gateway.podSecurityContext.fsGroupChangePolicy Set filesystem group change policy
  ## @param gateway.podSecurityContext.sysctls Set kernel settings using the sysctl interface
  ## @param gateway.podSecurityContext.supplementalGroups Set filesystem extra groups
  ## @param gateway.podSecurityContext.fsGroup Set Gateway pod's Security Context fsGroup
  ##
  podSecurityContext:
    enabled: true
    fsGroupChangePolicy: Always
    sysctls: []
    supplementalGroups: []
    fsGroup: 1001
  ## Configure Container Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param gateway.containerSecurityContext.enabled Enabled containers' Security Context
  ## @param gateway.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in container
  ## @param gateway.containerSecurityContext.runAsUser Set containers' Security Context runAsUser
  ## @param gateway.containerSecurityContext.runAsGroup Set containers' Security Context runAsGroup
  ## @param gateway.containerSecurityContext.runAsNonRoot Set container's Security Context runAsNonRoot
  ## @param gateway.containerSecurityContext.privileged Set container's Security Context privileged
  ## @param gateway.containerSecurityContext.readOnlyRootFilesystem Set container's Security Context readOnlyRootFilesystem
  ## @param gateway.containerSecurityContext.allowPrivilegeEscalation Set container's Security Context allowPrivilegeEscalation
  ## @param gateway.containerSecurityContext.capabilities.drop List of capabilities to be dropped
  ## @param gateway.containerSecurityContext.seccompProfile.type Set container's Security Context seccomp profile
  ##
  containerSecurityContext:
    enabled: true
    seLinuxOptions: {}
    runAsUser: 1001
    runAsGroup: 1001
    runAsNonRoot: true
    privileged: false
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
    seccompProfile:
      type: "RuntimeDefault"
  ## @param gateway.lifecycleHooks for the gateway container(s) to automate configuration before or after startup
  ##
  lifecycleHooks: {}
  ## @param gateway.automountServiceAccountToken Mount Service Account token in pod
  ##
  automountServiceAccountToken: false
  ## @param gateway.hostAliases gateway pods host aliases
  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
  ##
  hostAliases: []
  ## @param gateway.podLabels Extra labels for gateway pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  ##
  podLabels: {}
  ## @param gateway.podAnnotations Annotations for gateway pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  ##
  podAnnotations: {}
  ## @param gateway.podAffinityPreset Pod affinity preset. Ignored if `gateway.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAffinityPreset: ""
  ## @param gateway.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `gateway.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAntiAffinityPreset: soft
  ## Node gateway.affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ##
  nodeAffinityPreset:
    ## @param gateway.nodeAffinityPreset.type Node affinity preset type. Ignored if `gateway.affinity` is set. Allowed values: `soft` or `hard`
    ##
    type: ""
    ## @param gateway.nodeAffinityPreset.key Node label key to match. Ignored if `gateway.affinity` is set
    ##
    key: ""
    ## @param gateway.nodeAffinityPreset.values Node label values to match. Ignored if `gateway.affinity` is set
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []
  ## @param gateway.affinity Affinity for Gateway pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## NOTE: `gateway.podAffinityPreset`, `gateway.podAntiAffinityPreset`, and `gateway.nodeAffinityPreset` will be ignored when it's set
  ##
  affinity: {}
  ## @param gateway.nodeSelector Node labels for Gateway pods assignment
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/
  ##
  nodeSelector: {}
  ## @param gateway.tolerations Tolerations for Gateway pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  ## @param gateway.topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains
  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
  ##
  topologySpreadConstraints: []
  ## @param gateway.priorityClassName Gateway pods' priorityClassName
  ##
  priorityClassName: ""
  ## @param gateway.schedulerName Kubernetes pod scheduler registry
  ## https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  schedulerName: ""
  ## @param gateway.updateStrategy.type Gateway statefulset strategy type
  ## @param gateway.updateStrategy.rollingUpdate Gateway statefulset rolling update configuration parameters
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  ##
  updateStrategy:
    type: RollingUpdate
    rollingUpdate: {}
  ## @param gateway.extraVolumes Optionally specify extra list of additional volumes for the Gateway pod(s)
  ##
  extraVolumes: []
  ## @param gateway.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the Gateway container(s)
  ##
  extraVolumeMounts: []
  ## @param gateway.sidecars Add additional sidecar containers to the Gateway pod(s)
  ## e.g:
  ## sidecars:
  ##   - name: your-image-name
  ##     image: your-image
  ##     imagePullPolicy: Always
  ##     ports:
  ##       - name: portname
  ##         containerPort: 1234
  ##
  sidecars: []
  ## @param gateway.initContainers Add additional init containers to the Gateway pod(s)
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  ## e.g:
  ## initContainers:
  ##  - name: your-image-name
  ##    image: your-image
  ##    imagePullPolicy: Always
  ##    command: ['sh', '-c', 'echo "hello world"']
  ##
  initContainers: []
  ## @section Gateway Traffic Exposure Parameters
  ##

  ## gateway service parameters
  ##
  service:
    ## @param gateway.service.type Gateway service type
    ##
    type: ClusterIP
    ## @param gateway.service.ports.http Gateway HTTP service port
    ##
    ports:
      http: 80
    ## Node ports to expose
    ## NOTE: choose port between <30000-32767>
    ## @param gateway.service.nodePorts.http Node port for HTTP
    ##
    nodePorts:
      http: ""
    ## @param gateway.service.sessionAffinityConfig Additional settings for the sessionAffinity
    ## sessionAffinityConfig:
    ##   clientIP:
    ##     timeoutSeconds: 300
    ##
    sessionAffinityConfig: {}
    ## @param gateway.service.sessionAffinity Control where client requests go, to the same pod or round-robin
    ## Values: ClientIP or None
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/
    ##
    sessionAffinity: None
    ## @param gateway.service.clusterIP Gateway service Cluster IP
    ## e.g.:
    ## clusterIP: None
    ##
    clusterIP: ""
    ## @param gateway.service.loadBalancerIP Gateway service Load Balancer IP
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer
    ##
    loadBalancerIP: ""
    ## @param gateway.service.loadBalancerSourceRanges Gateway service Load Balancer sources
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
    ## e.g:
    ## loadBalancerSourceRanges:
    ##   - 10.10.10.0/24
    ##
    loadBalancerSourceRanges: []
    ## @param gateway.service.externalTrafficPolicy Gateway service external traffic policy
    ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    externalTrafficPolicy: Cluster
    ## @param gateway.service.annotations Additional custom annotations for Gateway service
    ##
    annotations: {}
    ## @param gateway.service.extraPorts Extra ports to expose in the Gateway service
    ##
    extraPorts: []
  ## Network Policies
  ## Ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/
  ##
  networkPolicy:
    ## @param gateway.networkPolicy.enabled Specifies whether a NetworkPolicy should be created
    ##
    enabled: true
    ## @param gateway.networkPolicy.allowExternal Don't require server label for connections
    ## The Policy model to apply. When set to false, only pods with the correct
    ## server label will have network access to the ports server is listening
    ## on. When true, server will accept connections from any source
    ## (with the correct destination port).
    ##
    allowExternal: true
    ## @param gateway.networkPolicy.allowExternalEgress Allow the pod to access any range of port and all destinations.
    ##
    allowExternalEgress: true
    ## @param gateway.networkPolicy.extraIngress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraIngress:
    ##   - ports:
    ##       - port: 1234
    ##     from:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    extraIngress: []
    ## @param gateway.networkPolicy.extraEgress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraEgress:
    ##   - ports:
    ##       - port: 1234
    ##     to:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    ##
    extraEgress: []
    ## @param gateway.networkPolicy.ingressNSMatchLabels [object] Labels to match to allow traffic from other namespaces
    ## @param gateway.networkPolicy.ingressNSPodMatchLabels [object] Pod labels to match to allow traffic from other namespaces
    ##
    ingressNSMatchLabels: {}
    ingressNSPodMatchLabels: {}
  ## Configure the ingress resource that allows you to access the Mimir Gateway installation
  ## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/
  ##
  ingress:
    ## @param gateway.ingress.enabled Enable ingress record generation for Mimir Gateway
    ##
    enabled: false
    ## @param gateway.ingress.pathType Ingress path type
    ##
    pathType: ImplementationSpecific
    ## @param gateway.ingress.apiVersion Force Ingress API version (automatically detected if not set)
    ##
    apiVersion: ""
    ## @param gateway.ingress.ingressClassName IngressClass that will be be used to implement the Ingress (Kubernetes 1.18+)
    ## This is supported in Kubernetes 1.18+ and required if you have more than one IngressClass marked as the default for your cluster .
    ## ref: https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/
    ##
    ingressClassName: ""
    ## @param gateway.ingress.hostname Default host for the ingress record
    ##
    hostname: grafana-mimir.local
    ## @param gateway.ingress.path Default path for the ingress record
    ## NOTE: You may need to set this to '/*' in order to use this with ALB ingress controllers
    ##
    path: /
    ## @param gateway.ingress.annotations Additional annotations for the Ingress resource. To enable certificate autogeneration, place here your cert-manager annotations.
    ## For a full list of possible ingress annotations, please see
    ## ref: https://github.com/kubernetes/ingress-nginx/blob/main/docs/user-guide/nginx-configuration/annotations.md
    ## Use this parameter to set the required annotations for cert-manager, see
    ## ref: https://cert-manager.io/docs/usage/ingress/#supported-annotations
    ##
    ## e.g:
    ## annotations:
    ##   kubernetes.io/ingress.class: nginx
    ##   cert-manager.io/cluster-issuer: cluster-issuer-name
    ##
    annotations: {}
    ## @param gateway.ingress.tls Enable TLS configuration for the host defined at `ingress.hostname` parameter
    ## TLS certificates will be retrieved from a TLS secret with name: `{{- printf "%s-tls" .Values.ingress.hostname }}`
    ## You can:
    ##   - Use the `ingress.secrets` parameter to create this TLS secret
    ##   - Rely on cert-manager to create it by setting the corresponding annotations
    ##   - Rely on Helm to create self-signed certificates by setting `ingress.selfSigned=true`
    ##
    tls: false
    ## @param gateway.ingress.selfSigned Create a TLS secret for this ingress record using self-signed certificates generated by Helm
    ##
    selfSigned: false
    ## @param gateway.ingress.extraHosts An array with additional hostname(s) to be covered with the ingress record
    ## e.g:
    ## extraHosts:
    ##   - name: mimir-gateway.local
    ##     path: /
    ##
    extraHosts: []
    ## @param gateway.ingress.extraPaths An array with additional arbitrary paths that may need to be added to the ingress under the main host
    ## e.g:
    ## extraPaths:
    ## - path: /*
    ##   backend:
    ##     serviceName: ssl-redirect
    ##     servicePort: use-annotation
    ##
    extraPaths: []
    ## @param gateway.ingress.extraTls TLS configuration for additional hostname(s) to be covered with this ingress record
    ## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/#tls
    ## e.g:
    ## extraTls:
    ## - hosts:
    ##     - mimir-gateway.local
    ##   secretName: mimir-gateway.local-tls
    ##
    extraTls: []
    ## @param gateway.ingress.secrets Custom TLS certificates as secrets
    ## NOTE: 'key' and 'certificate' are expected in PEM format
    ## NOTE: 'name' should line up with a 'secretName' set further up
    ## If it is not set and you're using cert-manager, this is unneeded, as it will create a secret for you with valid certificates
    ## If it is not set and you're NOT using cert-manager either, self-signed certificates will be created valid for 365 days
    ## It is also possible to create and manage the certificates outside of this helm chart
    ## Please see README.md for more information
    ## e.g:
    ## secrets:
    ##   - name: mimir-gateway.local-tls
    ##     key: |-
    ##       -----BEGIN RSA PRIVATE KEY-----
    ##       ...
    ##       -----END RSA PRIVATE KEY-----
    ##     certificate: |-
    ##       -----BEGIN CERTIFICATE-----
    ##       ...
    ##       -----END CERTIFICATE-----
    ##
    secrets: []
  ## Pod Disruption Budget configuration
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb
  ## @param gateway.pdb.create Enable/disable a Pod Disruption Budget creation
  ## @param gateway.pdb.minAvailable Minimum number/percentage of pods that should remain scheduled
  ## @param gateway.pdb.maxUnavailable Maximum number/percentage of pods that may be made unavailable
  ##
  pdb:
    create: false
    minAvailable: 1
    maxUnavailable: ""
## @section Ingester Deployment Parameters
##
ingester:
  ## @param ingester.extraEnvVars Array with extra environment variables to add to ingester nodes
  ## e.g:
  ## extraEnvVars:
  ##   - name: FOO
  ##     value: "bar"
  ##
  extraEnvVars: []
  ## @param ingester.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for ingester nodes
  ##
  extraEnvVarsCM: ""
  ## @param ingester.extraEnvVarsSecret Name of existing Secret containing extra env vars for ingester nodes
  ##
  extraEnvVarsSecret: ""
  ## @param ingester.command Override default container command (useful when using custom images)
  ##
  command: []
  ## @param ingester.args Override default container args (useful when using custom images)
  ##
  args: []
  ## @param ingester.extraArgs Add additional args to the default container args (useful to override configuration)
  ## e.g:
  ## extraArgs:
  ##   - "-log.level=debug"
  extraArgs: []
  ## @param ingester.replicaCount Number of Ingester replicas to deploy
  ## at
  replicaCount: 2
  ## @param ingester.podManagementPolicy Statefulset Pod management policy, it needs to be Parallel to be able to complete the cluster join
  ## Ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  ##
  podManagementPolicy: OrderedReady
  ## Configure extra options for Ingester containers' liveness, readiness and startup probes
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  ## @param ingester.livenessProbe.enabled Enable livenessProbe on Ingester nodes
  ## @param ingester.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
  ## @param ingester.livenessProbe.periodSeconds Period seconds for livenessProbe
  ## @param ingester.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
  ## @param ingester.livenessProbe.failureThreshold Failure threshold for livenessProbe
  ## @param ingester.livenessProbe.successThreshold Success threshold for livenessProbe
  ##
  livenessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param ingester.readinessProbe.enabled Enable readinessProbe on Ingester nodes
  ## @param ingester.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
  ## @param ingester.readinessProbe.periodSeconds Period seconds for readinessProbe
  ## @param ingester.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
  ## @param ingester.readinessProbe.failureThreshold Failure threshold for readinessProbe
  ## @param ingester.readinessProbe.successThreshold Success threshold for readinessProbe
  ##
  readinessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param ingester.startupProbe.enabled Enable startupProbe on Ingester containers
  ## @param ingester.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe
  ## @param ingester.startupProbe.periodSeconds Period seconds for startupProbe
  ## @param ingester.startupProbe.timeoutSeconds Timeout seconds for startupProbe
  ## @param ingester.startupProbe.failureThreshold Failure threshold for startupProbe
  ## @param ingester.startupProbe.successThreshold Success threshold for startupProbe
  ##
  startupProbe:
    enabled: false
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 1
    failureThreshold: 15
    successThreshold: 1
  ## @param ingester.customLivenessProbe Custom livenessProbe that overrides the default one
  ##
  customLivenessProbe: {}
  ## @param ingester.customReadinessProbe Custom readinessProbe that overrides the default one
  ##
  customReadinessProbe: {}
  ## @param ingester.customStartupProbe Custom startupProbe that overrides the default one
  ##
  customStartupProbe: {}
  ## ingester resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param ingester.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if ingester.resources is set (ingester.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "nano"
  ## @param ingester.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
  ## Configure Pods Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param ingester.podSecurityContext.enabled Enabled Ingester pods' Security Context
  ## @param ingester.podSecurityContext.fsGroupChangePolicy Set filesystem group change policy
  ## @param ingester.podSecurityContext.sysctls Set kernel settings using the sysctl interface
  ## @param ingester.podSecurityContext.supplementalGroups Set filesystem extra groups
  ## @param ingester.podSecurityContext.fsGroup Set Ingester pod's Security Context fsGroup
  ##
  podSecurityContext:
    enabled: true
    fsGroupChangePolicy: Always
    sysctls: []
    supplementalGroups: []
    fsGroup: 1001
  ## Configure Container Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param ingester.containerSecurityContext.enabled Enabled containers' Security Context
  ## @param ingester.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in container
  ## @param ingester.containerSecurityContext.runAsUser Set containers' Security Context runAsUser
  ## @param ingester.containerSecurityContext.runAsGroup Set containers' Security Context runAsGroup
  ## @param ingester.containerSecurityContext.runAsNonRoot Set container's Security Context runAsNonRoot
  ## @param ingester.containerSecurityContext.privileged Set container's Security Context privileged
  ## @param ingester.containerSecurityContext.readOnlyRootFilesystem Set container's Security Context readOnlyRootFilesystem
  ## @param ingester.containerSecurityContext.allowPrivilegeEscalation Set container's Security Context allowPrivilegeEscalation
  ## @param ingester.containerSecurityContext.capabilities.drop List of capabilities to be dropped
  ## @param ingester.containerSecurityContext.seccompProfile.type Set container's Security Context seccomp profile
  ##
  containerSecurityContext:
    enabled: true
    seLinuxOptions: {}
    runAsUser: 1001
    runAsGroup: 1001
    runAsNonRoot: true
    privileged: false
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
    seccompProfile:
      type: "RuntimeDefault"
  ## @param ingester.lifecycleHooks for the ingester container(s) to automate configuration before or after startup
  ##
  lifecycleHooks: {}
  ## @param ingester.automountServiceAccountToken Mount Service Account token in pod
  ##
  automountServiceAccountToken: false
  ## @param ingester.hostAliases ingester pods host aliases
  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
  ##
  hostAliases: []
  ## @param ingester.podLabels Extra labels for ingester pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  ##
  podLabels: {}
  ## @param ingester.podAnnotations Annotations for ingester pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  ##
  podAnnotations: {}
  ## @param ingester.podAffinityPreset Pod affinity preset. Ignored if `ingester.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAffinityPreset: ""
  ## @param ingester.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `ingester.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAntiAffinityPreset: soft
  ## Node ingester.affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ##
  nodeAffinityPreset:
    ## @param ingester.nodeAffinityPreset.type Node affinity preset type. Ignored if `ingester.affinity` is set. Allowed values: `soft` or `hard`
    ##
    type: ""
    ## @param ingester.nodeAffinityPreset.key Node label key to match. Ignored if `ingester.affinity` is set
    ##
    key: ""
    ## @param ingester.nodeAffinityPreset.values Node label values to match. Ignored if `ingester.affinity` is set
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []
  ## @param ingester.affinity Affinity for Ingester pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## NOTE: `ingester.podAffinityPreset`, `ingester.podAntiAffinityPreset`, and `ingester.nodeAffinityPreset` will be ignored when it's set
  ##
  affinity: {}
  ## @param ingester.nodeSelector Node labels for Ingester pods assignment
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/
  ##
  nodeSelector: {}
  ## @param ingester.tolerations Tolerations for Ingester pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  ## @param ingester.topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains
  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
  ##
  topologySpreadConstraints: []
  ## @param ingester.priorityClassName Ingester pods' priorityClassName
  ##
  priorityClassName: ""
  ## @param ingester.schedulerName Kubernetes pod scheduler registry
  ## https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  schedulerName: ""
  ## @param ingester.terminationGracePeriodSeconds Seconds pod needs to terminate gracefully
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods
  ##
  terminationGracePeriodSeconds: ""
  ## @param ingester.updateStrategy.type Ingester statefulset strategy type
  ## @param ingester.updateStrategy.rollingUpdate Ingester statefulset rolling update configuration parameters
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  ##
  updateStrategy:
    type: RollingUpdate
    rollingUpdate: {}
  ## @param ingester.extraVolumes Optionally specify extra list of additional volumes for the Ingester pod(s)
  ##
  extraVolumes: []
  ## @param ingester.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the Ingester container(s)
  ##
  extraVolumeMounts: []
  ## @param ingester.sidecars Add additional sidecar containers to the Ingester pod(s)
  ## e.g:
  ## sidecars:
  ##   - name: your-image-name
  ##     image: your-image
  ##     imagePullPolicy: Always
  ##     ports:
  ##       - name: portname
  ##         containerPort: 1234
  ##
  sidecars: []
  ## @param ingester.initContainers Add additional init containers to the Ingester pod(s)
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  ## e.g:
  ## initContainers:
  ##  - name: your-image-name
  ##    image: your-image
  ##    imagePullPolicy: Always
  ##    command: ['sh', '-c', 'echo "hello world"']
  ##
  initContainers: []
  ## Enable persistence using Persistent Volume Claims
  ## ref: https://kubernetes.io/docs/concepts/storage/persistent-volumes/
  ##
  persistence:
    ## @param ingester.persistence.enabled Enable persistence in Ingester instances
    ##
    enabled: true
    ## @param ingester.persistence.storageClass PVC Storage Class for Ingester data volume
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    storageClass: ""
    ## @param ingester.persistence.accessModes PVC Access modes
    ##
    accessModes:
      - ReadWriteOnce
    ## @param ingester.persistence.size PVC Storage Request for Ingester data volume
    ##
    size: 8Gi
    ## @param ingester.persistence.annotations Additional PVC annotations
    ##
    annotations: {}
    ## @param ingester.persistence.selector Selector to match an existing Persistent Volume for Ingester's data PVC
    ## If set, the PVC can't have a PV dynamically provisioned for it
    ## E.g.
    ## selector:
    ##   matchLabels:
    ##     app: my-app
    ##
    selector: {}
    ## @param ingester.persistence.dataSource PVC data source
    ##
    dataSource: {}
  ## @section Ingester Traffic Exposure Parameters
  ##

  ## ingester service parameters
  ##
  service:
    ## @param ingester.service.type Ingester service type
    ##
    type: ClusterIP
    ## @param ingester.service.ports.http Ingester HTTP service port
    ## @param ingester.service.ports.grpc Ingester GRPC service port
    ##
    ports:
      http: 8080
      grpc: 9095
    ## Node ports to expose
    ## NOTE: choose port between <30000-32767>
    ## @param ingester.service.nodePorts.http Node port for HTTP
    ## @param ingester.service.nodePorts.grpc Node port for GRPC
    ##
    nodePorts:
      http: ""
      grpc: 9095
    ## @param ingester.service.sessionAffinityConfig Additional settings for the sessionAffinity
    ## sessionAffinityConfig:
    ##   clientIP:
    ##     timeoutSeconds: 300
    ##
    sessionAffinityConfig: {}
    ## @param ingester.service.sessionAffinity Control where client requests go, to the same pod or round-robin
    ## Values: ClientIP or None
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/
    ##
    sessionAffinity: None
    ## @param ingester.service.clusterIP Ingester service Cluster IP
    ## e.g.:
    ## clusterIP: None
    ##
    clusterIP: ""
    ## @param ingester.service.loadBalancerIP Ingester service Load Balancer IP
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer
    ##
    loadBalancerIP: ""
    ## @param ingester.service.loadBalancerSourceRanges Ingester service Load Balancer sources
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
    ## e.g:
    ## loadBalancerSourceRanges:
    ##   - 10.10.10.0/24
    ##
    loadBalancerSourceRanges: []
    ## @param ingester.service.externalTrafficPolicy Ingester service external traffic policy
    ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    externalTrafficPolicy: Cluster
    ## @param ingester.service.annotations Additional custom annotations for Ingester service
    ##
    annotations: {}
    ## @param ingester.service.extraPorts Extra ports to expose in the Ingester service
    ##
    extraPorts: []
    ## Headless service properties
    ##
    headless:
      ## @param ingester.service.headless.annotations Annotations for the headless service.
      ##
      annotations: {}
  ## Network Policies
  ## Ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/
  ##
  networkPolicy:
    ## @param ingester.networkPolicy.enabled Specifies whether a NetworkPolicy should be created
    ##
    enabled: true
    ## @param ingester.networkPolicy.allowExternal Don't require server label for connections
    ## The Policy model to apply. When set to false, only pods with the correct
    ## server label will have network access to the ports server is listening
    ## on. When true, server will accept connections from any source
    ## (with the correct destination port).
    ##
    allowExternal: true
    ## @param ingester.networkPolicy.allowExternalEgress Allow the pod to access any range of port and all destinations.
    ##
    allowExternalEgress: true
    ## @param ingester.networkPolicy.extraIngress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraIngress:
    ##   - ports:
    ##       - port: 1234
    ##     from:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    extraIngress: []
    ## @param ingester.networkPolicy.extraEgress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraEgress:
    ##   - ports:
    ##       - port: 1234
    ##     to:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    ##
    extraEgress: []
    ## @param ingester.networkPolicy.ingressNSMatchLabels [object] Labels to match to allow traffic from other namespaces
    ## @param ingester.networkPolicy.ingressNSPodMatchLabels [object] Pod labels to match to allow traffic from other namespaces
    ##
    ingressNSMatchLabels: {}
    ingressNSPodMatchLabels: {}
  ## Pod Disruption Budget configuration
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb
  ## @param ingester.pdb.create Enable/disable a Pod Disruption Budget creation
  ## @param ingester.pdb.minAvailable Minimum number/percentage of pods that should remain scheduled
  ## @param ingester.pdb.maxUnavailable Maximum number/percentage of pods that may be made unavailable
  ##
  pdb:
    create: false
    minAvailable: 1
    maxUnavailable: ""
# @section overrides-exporter Deployment Parameters
##
overridesExporter:
  ## @param overridesExporter.enabled Enable overrides-exporter deployment
  ##
  enabled: false
  ## @param overridesExporter.extraEnvVars Array with extra environment variables to add to overrides-exporter nodes
  ## e.g:
  ## extraEnvVars:
  ##   - name: FOO
  ##     value: "bar"
  ##
  extraEnvVars: []
  ## @param overridesExporter.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for overrides-exporter nodes
  ##
  extraEnvVarsCM: ""
  ## @param overridesExporter.extraEnvVarsSecret Name of existing Secret containing extra env vars for overrides-exporter nodes
  ##
  extraEnvVarsSecret: ""
  ## @param overridesExporter.command Override default container command (useful when using custom images)
  ##
  command: []
  ## @param overridesExporter.args Override default container args (useful when using custom images)
  ##
  args: []
  ## @param overridesExporter.extraArgs Add additional args to the default container args (useful to override configuration)
  ## e.g:
  ## extraArgs:
  ##   - "-log.level=debug"
  extraArgs: []
  ## @param overridesExporter.replicaCount Number of Overrides Exporter replicas to deploy
  ##
  replicaCount: 1
  ## Configure extra options for Overrides Exporter containers' liveness, readiness and startup probes
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  ## @param overridesExporter.livenessProbe.enabled Enable livenessProbe on Overrides Exporter nodes
  ## @param overridesExporter.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
  ## @param overridesExporter.livenessProbe.periodSeconds Period seconds for livenessProbe
  ## @param overridesExporter.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
  ## @param overridesExporter.livenessProbe.failureThreshold Failure threshold for livenessProbe
  ## @param overridesExporter.livenessProbe.successThreshold Success threshold for livenessProbe
  ##
  livenessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param overridesExporter.readinessProbe.enabled Enable readinessProbe on Overrides Exporter nodes
  ## @param overridesExporter.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
  ## @param overridesExporter.readinessProbe.periodSeconds Period seconds for readinessProbe
  ## @param overridesExporter.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
  ## @param overridesExporter.readinessProbe.failureThreshold Failure threshold for readinessProbe
  ## @param overridesExporter.readinessProbe.successThreshold Success threshold for readinessProbe
  ##
  readinessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param overridesExporter.startupProbe.enabled Enable startupProbe on Overrides Exporter containers
  ## @param overridesExporter.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe
  ## @param overridesExporter.startupProbe.periodSeconds Period seconds for startupProbe
  ## @param overridesExporter.startupProbe.timeoutSeconds Timeout seconds for startupProbe
  ## @param overridesExporter.startupProbe.failureThreshold Failure threshold for startupProbe
  ## @param overridesExporter.startupProbe.successThreshold Success threshold for startupProbe
  ##
  startupProbe:
    enabled: false
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 1
    failureThreshold: 15
    successThreshold: 1
  ## @param overridesExporter.customLivenessProbe Custom livenessProbe that overrides the default one
  ##
  customLivenessProbe: {}
  ## @param overridesExporter.customReadinessProbe Custom readinessProbe that overrides the default one
  ##
  customReadinessProbe: {}
  ## @param overridesExporter.customStartupProbe Custom startupProbe that overrides the default one
  ##
  customStartupProbe: {}
  ## overrides-exporter resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param overridesExporter.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if overridesExporter.resources is set (overridesExporter.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "nano"
  ## @param overridesExporter.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
  ## Configure Pods Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param overridesExporter.podSecurityContext.enabled Enabled Overrides Exporter pods' Security Context
  ## @param overridesExporter.podSecurityContext.fsGroupChangePolicy Set filesystem group change policy
  ## @param overridesExporter.podSecurityContext.sysctls Set kernel settings using the sysctl interface
  ## @param overridesExporter.podSecurityContext.supplementalGroups Set filesystem extra groups
  ## @param overridesExporter.podSecurityContext.fsGroup Set Overrides Exporter pod's Security Context fsGroup
  ##
  podSecurityContext:
    enabled: true
    fsGroupChangePolicy: Always
    sysctls: []
    supplementalGroups: []
    fsGroup: 1001
  ## Configure Container Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param overridesExporter.containerSecurityContext.enabled Enabled containers' Security Context
  ## @param overridesExporter.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in container
  ## @param overridesExporter.containerSecurityContext.runAsUser Set containers' Security Context runAsUser
  ## @param overridesExporter.containerSecurityContext.runAsGroup Set containers' Security Context runAsGroup
  ## @param overridesExporter.containerSecurityContext.runAsNonRoot Set container's Security Context runAsNonRoot
  ## @param overridesExporter.containerSecurityContext.privileged Set container's Security Context privileged
  ## @param overridesExporter.containerSecurityContext.readOnlyRootFilesystem Set container's Security Context readOnlyRootFilesystem
  ## @param overridesExporter.containerSecurityContext.allowPrivilegeEscalation Set container's Security Context allowPrivilegeEscalation
  ## @param overridesExporter.containerSecurityContext.capabilities.drop List of capabilities to be dropped
  ## @param overridesExporter.containerSecurityContext.seccompProfile.type Set container's Security Context seccomp profile
  ##
  containerSecurityContext:
    enabled: true
    seLinuxOptions: {}
    runAsUser: 1001
    runAsGroup: 1001
    runAsNonRoot: true
    privileged: false
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
    seccompProfile:
      type: "RuntimeDefault"
  ## @param overridesExporter.lifecycleHooks for the ingester container(s) to automate configuration before or after startup
  ##
  lifecycleHooks: {}
  ## @param overridesExporter.automountServiceAccountToken Mount Service Account token in pod
  ##
  automountServiceAccountToken: false
  ## @param overridesExporter.hostAliases ingester pods host aliases
  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
  ##
  hostAliases: []
  ## @param overridesExporter.podLabels Extra labels for ingester pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  ##
  podLabels: {}
  ## @param overridesExporter.podAnnotations Annotations for ingester pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  ##
  podAnnotations: {}
  ## @param overridesExporter.podAffinityPreset Pod affinity preset. Ignored if `overridesExporter.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAffinityPreset: ""
  ## @param overridesExporter.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `overridesExporter.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAntiAffinityPreset: soft
  ## Node overridesExporter.affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ##
  nodeAffinityPreset:
    ## @param overridesExporter.nodeAffinityPreset.type Node affinity preset type. Ignored if `overridesExporter.affinity` is set. Allowed values: `soft` or `hard`
    ##
    type: ""
    ## @param overridesExporter.nodeAffinityPreset.key Node label key to match. Ignored if `overridesExporter.affinity` is set
    ##
    key: ""
    ## @param overridesExporter.nodeAffinityPreset.values Node label values to match. Ignored if `overridesExporter.affinity` is set
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []
  ## @param overridesExporter.affinity Affinity for Overrides Exporter pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## NOTE: `overridesExporter.podAffinityPreset`, `overridesExporter.podAntiAffinityPreset`, and `overridesExporter.nodeAffinityPreset` will be ignored when it's set
  ##
  affinity: {}
  ## @param overridesExporter.nodeSelector Node labels for Overrides Exporter pods assignment
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/
  ##
  nodeSelector: {}
  ## @param overridesExporter.tolerations Tolerations for Overrides Exporter pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  ## @param overridesExporter.topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains
  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
  ##
  topologySpreadConstraints: []
  ## @param overridesExporter.priorityClassName Overrides Exporter pods' priorityClassName
  ##
  priorityClassName: ""
  ## @param overridesExporter.schedulerName Kubernetes pod scheduler registry
  ## https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  schedulerName: ""
  ## @param overridesExporter.terminationGracePeriodSeconds Seconds pod needs to terminate gracefully
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods
  ##
  terminationGracePeriodSeconds: ""
  ## @param overridesExporter.updateStrategy.type Overrides Exporter statefulset strategy type
  ## @param overridesExporter.updateStrategy.rollingUpdate Overrides Exporter statefulset rolling update configuration parameters
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  ##
  updateStrategy:
    type: RollingUpdate
    rollingUpdate: {}
  ## @param overridesExporter.extraVolumes Optionally specify extra list of additional volumes for the Overrides Exporter pod(s)
  ##
  extraVolumes: []
  ## @param overridesExporter.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the Overrides Exporter container(s)
  ##
  extraVolumeMounts: []
  ## @param overridesExporter.sidecars Add additional sidecar containers to the Overrides Exporter pod(s)
  ## e.g:
  ## sidecars:
  ##   - name: your-image-name
  ##     image: your-image
  ##     imagePullPolicy: Always
  ##     ports:
  ##       - name: portname
  ##         containerPort: 1234
  ##
  sidecars: []
  ## @param overridesExporter.initContainers Add additional init containers to the Overrides Exporter pod(s)
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  ## e.g:
  ## initContainers:
  ##  - name: your-image-name
  ##    image: your-image
  ##    imagePullPolicy: Always
  ##    command: ['sh', '-c', 'echo "hello world"']
  ##
  initContainers: []
  ## @section Overrides Exporter Traffic Exposure Parameters
  ##

  ## ingester service parameters
  ##
  service:
    ## @param overridesExporter.service.type Overrides Exporter service type
    ##
    type: ClusterIP
    ## @param overridesExporter.service.ports.http Overrides Exporter HTTP service port
    ## @param overridesExporter.service.ports.grpc Overrides Exporter GRPC service port
    ##
    ports:
      http: 8080
      grpc: 9095
    ## Node ports to expose
    ## NOTE: choose port between <30000-32767>
    ## @param overridesExporter.service.nodePorts.http Node port for HTTP
    ## @param overridesExporter.service.nodePorts.grpc Node port for GRPC
    ##
    nodePorts:
      http: ""
      grpc: 9095
    ## @param overridesExporter.service.sessionAffinityConfig Additional settings for the sessionAffinity
    ## sessionAffinityConfig:
    ##   clientIP:
    ##     timeoutSeconds: 300
    ##
    sessionAffinityConfig: {}
    ## @param overridesExporter.service.sessionAffinity Control where client requests go, to the same pod or round-robin
    ## Values: ClientIP or None
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/
    ##
    sessionAffinity: None
    ## @param overridesExporter.service.clusterIP Overrides Exporter service Cluster IP
    ## e.g.:
    ## clusterIP: None
    ##
    clusterIP: ""
    ## @param overridesExporter.service.loadBalancerIP Overrides Exporter service Load Balancer IP
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer
    ##
    loadBalancerIP: ""
    ## @param overridesExporter.service.loadBalancerSourceRanges Overrides Exporter service Load Balancer sources
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
    ## e.g:
    ## loadBalancerSourceRanges:
    ##   - 10.10.10.0/24
    ##
    loadBalancerSourceRanges: []
    ## @param overridesExporter.service.externalTrafficPolicy Overrides Exporter service external traffic policy
    ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    externalTrafficPolicy: Cluster
    ## @param overridesExporter.service.annotations Additional custom annotations for Overrides Exporter service
    ##
    annotations: {}
    ## @param overridesExporter.service.extraPorts Extra ports to expose in the Overrides Export service
    ##
    extraPorts: []
    ## Headless service properties
    ##
    headless:
      ## @param overridesExporter.service.headless.annotations Annotations for the headless service.
      ##
      annotations: {}
  ## Network Policies
  ## Ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/
  ##
  networkPolicy:
    ## @param overridesExporter.networkPolicy.enabled Specifies whether a NetworkPolicy should be created
    ##
    enabled: true
    ## @param overridesExporter.networkPolicy.allowExternal Don't require server label for connections
    ## The Policy model to apply. When set to false, only pods with the correct
    ## server label will have network access to the ports server is listening
    ## on. When true, server will accept connections from any source
    ## (with the correct destination port).
    ##
    allowExternal: true
    ## @param overridesExporter.networkPolicy.allowExternalEgress Allow the pod to access any range of port and all destinations.
    ##
    allowExternalEgress: true
    ## @param overridesExporter.networkPolicy.extraIngress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraIngress:
    ##   - ports:
    ##       - port: 1234
    ##     from:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    extraIngress: []
    ## @param overridesExporter.networkPolicy.extraEgress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraEgress:
    ##   - ports:
    ##       - port: 1234
    ##     to:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    ##
    extraEgress: []
    ## @param overridesExporter.networkPolicy.ingressNSMatchLabels [object] Labels to match to allow traffic from other namespaces
    ## @param overridesExporter.networkPolicy.ingressNSPodMatchLabels [object] Pod labels to match to allow traffic from other namespaces
    ##
    ingressNSMatchLabels: {}
    ingressNSPodMatchLabels: {}
  ## Pod Disruption Budget configuration
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb
  ## @param overridesExporter.pdb.create Enable/disable a Pod Disruption Budget creation
  ## @param overridesExporter.pdb.minAvailable Minimum number/percentage of pods that should remain scheduled
  ## @param overridesExporter.pdb.maxUnavailable Maximum number/percentage of pods that may be made unavailable
  ##
  pdb:
    create: false
    minAvailable: 1
    maxUnavailable: ""
## @section Querier Deployment Parameters
##
querier:
  ## @param querier.extraEnvVars Array with extra environment variables to add to querier nodes
  ## e.g:
  ## extraEnvVars:
  ##   - name: FOO
  ##     value: "bar"
  ##
  extraEnvVars: []
  ## @param querier.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for querier nodes
  ##
  extraEnvVarsCM: ""
  ## @param querier.extraEnvVarsSecret Name of existing Secret containing extra env vars for querier nodes
  ##
  extraEnvVarsSecret: ""
  ## @param querier.command Override default container command (useful when using custom images)
  ##
  command: []
  ## @param querier.args Override default container args (useful when using custom images)
  ##
  args: []
  ## @param querier.extraArgs Add additional args to the default container args (useful to override configuration)
  ## e.g:
  ## extraArgs:
  ##   - "-log.level=debug"
  extraArgs: []
  ## @param querier.replicaCount Number of Querier replicas to deploy
  ##
  replicaCount: 1
  ## Configure extra options for Querier containers' liveness, readiness and startup probes
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  ## @param querier.livenessProbe.enabled Enable livenessProbe on Querier nodes
  ## @param querier.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
  ## @param querier.livenessProbe.periodSeconds Period seconds for livenessProbe
  ## @param querier.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
  ## @param querier.livenessProbe.failureThreshold Failure threshold for livenessProbe
  ## @param querier.livenessProbe.successThreshold Success threshold for livenessProbe
  ##
  livenessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param querier.readinessProbe.enabled Enable readinessProbe on Querier nodes
  ## @param querier.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
  ## @param querier.readinessProbe.periodSeconds Period seconds for readinessProbe
  ## @param querier.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
  ## @param querier.readinessProbe.failureThreshold Failure threshold for readinessProbe
  ## @param querier.readinessProbe.successThreshold Success threshold for readinessProbe
  ##
  readinessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param querier.startupProbe.enabled Enable startupProbe on Querier containers
  ## @param querier.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe
  ## @param querier.startupProbe.periodSeconds Period seconds for startupProbe
  ## @param querier.startupProbe.timeoutSeconds Timeout seconds for startupProbe
  ## @param querier.startupProbe.failureThreshold Failure threshold for startupProbe
  ## @param querier.startupProbe.successThreshold Success threshold for startupProbe
  ##
  startupProbe:
    enabled: false
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 1
    failureThreshold: 15
    successThreshold: 1
  ## @param querier.customLivenessProbe Custom livenessProbe that overrides the default one
  ##
  customLivenessProbe: {}
  ## @param querier.customReadinessProbe Custom readinessProbe that overrides the default one
  ##
  customReadinessProbe: {}
  ## @param querier.customStartupProbe Custom startupProbe that overrides the default one
  ##
  customStartupProbe: {}
  ## querier resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param querier.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if querier.resources is set (querier.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "nano"
  ## @param querier.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
  ## Configure Pods Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param querier.podSecurityContext.enabled Enabled Querier pods' Security Context
  ## @param querier.podSecurityContext.fsGroupChangePolicy Set filesystem group change policy
  ## @param querier.podSecurityContext.sysctls Set kernel settings using the sysctl interface
  ## @param querier.podSecurityContext.supplementalGroups Set filesystem extra groups
  ## @param querier.podSecurityContext.fsGroup Set Querier pod's Security Context fsGroup
  ##
  podSecurityContext:
    enabled: true
    fsGroupChangePolicy: Always
    sysctls: []
    supplementalGroups: []
    fsGroup: 1001
  ## Configure Container Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param querier.containerSecurityContext.enabled Enabled containers' Security Context
  ## @param querier.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in container
  ## @param querier.containerSecurityContext.runAsUser Set containers' Security Context runAsUser
  ## @param querier.containerSecurityContext.runAsGroup Set containers' Security Context runAsGroup
  ## @param querier.containerSecurityContext.runAsNonRoot Set container's Security Context runAsNonRoot
  ## @param querier.containerSecurityContext.privileged Set container's Security Context privileged
  ## @param querier.containerSecurityContext.readOnlyRootFilesystem Set container's Security Context readOnlyRootFilesystem
  ## @param querier.containerSecurityContext.allowPrivilegeEscalation Set container's Security Context allowPrivilegeEscalation
  ## @param querier.containerSecurityContext.capabilities.drop List of capabilities to be dropped
  ## @param querier.containerSecurityContext.seccompProfile.type Set container's Security Context seccomp profile
  ##
  containerSecurityContext:
    enabled: true
    seLinuxOptions: {}
    runAsUser: 1001
    runAsGroup: 1001
    runAsNonRoot: true
    privileged: false
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
    seccompProfile:
      type: "RuntimeDefault"
  ## @param querier.lifecycleHooks for the ingester container(s) to automate configuration before or after startup
  ##
  lifecycleHooks: {}
  ## @param querier.automountServiceAccountToken Mount Service Account token in pod
  ##
  automountServiceAccountToken: false
  ## @param querier.hostAliases ingester pods host aliases
  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
  ##
  hostAliases: []
  ## @param querier.podLabels Extra labels for ingester pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  ##
  podLabels: {}
  ## @param querier.podAnnotations Annotations for ingester pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  ##
  podAnnotations: {}
  ## @param querier.podAffinityPreset Pod affinity preset. Ignored if `querier.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAffinityPreset: ""
  ## @param querier.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `querier.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAntiAffinityPreset: soft
  ## Node querier.affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ##
  nodeAffinityPreset:
    ## @param querier.nodeAffinityPreset.type Node affinity preset type. Ignored if `querier.affinity` is set. Allowed values: `soft` or `hard`
    ##
    type: ""
    ## @param querier.nodeAffinityPreset.key Node label key to match. Ignored if `querier.affinity` is set
    ##
    key: ""
    ## @param querier.nodeAffinityPreset.values Node label values to match. Ignored if `querier.affinity` is set
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []
  ## @param querier.affinity Affinity for Querier pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## NOTE: `querier.podAffinityPreset`, `querier.podAntiAffinityPreset`, and `querier.nodeAffinityPreset` will be ignored when it's set
  ##
  affinity: {}
  ## @param querier.nodeSelector Node labels for Querier pods assignment
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/
  ##
  nodeSelector: {}
  ## @param querier.tolerations Tolerations for Querier pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  ## @param querier.topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains
  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
  ##
  topologySpreadConstraints: []
  ## @param querier.priorityClassName Querier pods' priorityClassName
  ##
  priorityClassName: ""
  ## @param querier.schedulerName Kubernetes pod scheduler registry
  ## https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  schedulerName: ""
  ## @param querier.terminationGracePeriodSeconds Seconds pod needs to terminate gracefully
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods
  ##
  terminationGracePeriodSeconds: ""
  ## @param querier.updateStrategy.type Querier statefulset strategy type
  ## @param querier.updateStrategy.rollingUpdate Querier statefulset rolling update configuration parameters
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  ##
  updateStrategy:
    type: RollingUpdate
    rollingUpdate: {}
  ## @param querier.extraVolumes Optionally specify extra list of additional volumes for the Querier pod(s)
  ##
  extraVolumes: []
  ## @param querier.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the Querier container(s)
  ##
  extraVolumeMounts: []
  ## @param querier.sidecars Add additional sidecar containers to the Querier pod(s)
  ## e.g:
  ## sidecars:
  ##   - name: your-image-name
  ##     image: your-image
  ##     imagePullPolicy: Always
  ##     ports:
  ##       - name: portname
  ##         containerPort: 1234
  ##
  sidecars: []
  ## @param querier.initContainers Add additional init containers to the Querier pod(s)
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  ## e.g:
  ## initContainers:
  ##  - name: your-image-name
  ##    image: your-image
  ##    imagePullPolicy: Always
  ##    command: ['sh', '-c', 'echo "hello world"']
  ##
  initContainers: []
  ## @section Querier Traffic Exposure Parameters
  ##

  ## ingester service parameters
  ##
  service:
    ## @param querier.service.type Querier service type
    ##
    type: ClusterIP
    ## @param querier.service.ports.http Querier HTTP service port
    ## @param querier.service.ports.grpc Querier GRPC service port
    ##
    ports:
      http: 8080
      grpc: 9095
    ## Node ports to expose
    ## NOTE: choose port between <30000-32767>
    ## @param querier.service.nodePorts.http Node port for HTTP
    ## @param querier.service.nodePorts.grpc Node port for GRPC
    ##
    nodePorts:
      http: ""
      grpc: 9095
    ## @param querier.service.sessionAffinityConfig Additional settings for the sessionAffinity
    ## sessionAffinityConfig:
    ##   clientIP:
    ##     timeoutSeconds: 300
    ##
    sessionAffinityConfig: {}
    ## @param querier.service.sessionAffinity Control where client requests go, to the same pod or round-robin
    ## Values: ClientIP or None
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/
    ##
    sessionAffinity: None
    ## @param querier.service.clusterIP Querier service Cluster IP
    ## e.g.:
    ## clusterIP: None
    ##
    clusterIP: ""
    ## @param querier.service.loadBalancerIP Querier service Load Balancer IP
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer
    ##
    loadBalancerIP: ""
    ## @param querier.service.loadBalancerSourceRanges Querier service Load Balancer sources
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
    ## e.g:
    ## loadBalancerSourceRanges:
    ##   - 10.10.10.0/24
    ##
    loadBalancerSourceRanges: []
    ## @param querier.service.externalTrafficPolicy Querier service external traffic policy
    ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    externalTrafficPolicy: Cluster
    ## @param querier.service.annotations Additional custom annotations for Querier service
    ##
    annotations: {}
    ## @param querier.service.extraPorts Extra ports to expose in the Querier service
    ##
    extraPorts: []
    ## Headless service properties
    ##
    headless:
      ## @param querier.service.headless.annotations Annotations for the headless service.
      ##
      annotations: {}
  ## Network Policies
  ## Ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/
  ##
  networkPolicy:
    ## @param querier.networkPolicy.enabled Specifies whether a NetworkPolicy should be created
    ##
    enabled: true
    ## @param querier.networkPolicy.allowExternal Don't require server label for connections
    ## The Policy model to apply. When set to false, only pods with the correct
    ## server label will have network access to the ports server is listening
    ## on. When true, server will accept connections from any source
    ## (with the correct destination port).
    ##
    allowExternal: true
    ## @param querier.networkPolicy.allowExternalEgress Allow the pod to access any range of port and all destinations.
    ##
    allowExternalEgress: true
    ## @param querier.networkPolicy.extraIngress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraIngress:
    ##   - ports:
    ##       - port: 1234
    ##     from:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    extraIngress: []
    ## @param querier.networkPolicy.extraEgress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraEgress:
    ##   - ports:
    ##       - port: 1234
    ##     to:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    ##
    extraEgress: []
    ## @param querier.networkPolicy.ingressNSMatchLabels [object] Labels to match to allow traffic from other namespaces
    ## @param querier.networkPolicy.ingressNSPodMatchLabels [object] Pod labels to match to allow traffic from other namespaces
    ##
    ingressNSMatchLabels: {}
    ingressNSPodMatchLabels: {}
  ## Pod Disruption Budget configuration
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb
  ## @param querier.pdb.create Enable/disable a Pod Disruption Budget creation
  ## @param querier.pdb.minAvailable Minimum number/percentage of pods that should remain scheduled
  ## @param querier.pdb.maxUnavailable Maximum number/percentage of pods that may be made unavailable
  ##
  pdb:
    create: false
    minAvailable: 1
    maxUnavailable: ""
## @section Query Frontend Deployment Parameters
##
queryFrontend:
  ## @param queryFrontend.extraEnvVars Array with extra environment variables to add to ingester nodes
  ## e.g:
  ## extraEnvVars:
  ##   - name: FOO
  ##     value: "bar"
  ##
  extraEnvVars: []
  ## @param queryFrontend.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for ingester nodes
  ##
  extraEnvVarsCM: ""
  ## @param queryFrontend.extraEnvVarsSecret Name of existing Secret containing extra env vars for ingester nodes
  ##
  extraEnvVarsSecret: ""
  ## @param queryFrontend.command Override default container command (useful when using custom images)
  ##
  command: []
  ## @param queryFrontend.args Override default container args (useful when using custom images)
  ##
  args: []
  ## @param queryFrontend.extraArgs Add additional args to the default container args (useful to override configuration)
  ## e.g:
  ## extraArgs:
  ##   - "-log.level=debug"
  extraArgs: []
  ## @param queryFrontend.replicaCount Number of Query Frontend replicas to deploy
  ##
  replicaCount: 1
  ## Configure extra options for Query Frontend containers' liveness, readiness and startup probes
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  ## @param queryFrontend.livenessProbe.enabled Enable livenessProbe on Query Frontend nodes
  ## @param queryFrontend.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
  ## @param queryFrontend.livenessProbe.periodSeconds Period seconds for livenessProbe
  ## @param queryFrontend.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
  ## @param queryFrontend.livenessProbe.failureThreshold Failure threshold for livenessProbe
  ## @param queryFrontend.livenessProbe.successThreshold Success threshold for livenessProbe
  ##
  livenessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param queryFrontend.readinessProbe.enabled Enable readinessProbe on Query Frontend nodes
  ## @param queryFrontend.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
  ## @param queryFrontend.readinessProbe.periodSeconds Period seconds for readinessProbe
  ## @param queryFrontend.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
  ## @param queryFrontend.readinessProbe.failureThreshold Failure threshold for readinessProbe
  ## @param queryFrontend.readinessProbe.successThreshold Success threshold for readinessProbe
  ##
  readinessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param queryFrontend.startupProbe.enabled Enable startupProbe on Query Frontend containers
  ## @param queryFrontend.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe
  ## @param queryFrontend.startupProbe.periodSeconds Period seconds for startupProbe
  ## @param queryFrontend.startupProbe.timeoutSeconds Timeout seconds for startupProbe
  ## @param queryFrontend.startupProbe.failureThreshold Failure threshold for startupProbe
  ## @param queryFrontend.startupProbe.successThreshold Success threshold for startupProbe
  ##
  startupProbe:
    enabled: false
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 1
    failureThreshold: 15
    successThreshold: 1
  ## @param queryFrontend.customLivenessProbe Custom livenessProbe that overrides the default one
  ##
  customLivenessProbe: {}
  ## @param queryFrontend.customReadinessProbe Custom readinessProbe that overrides the default one
  ##
  customReadinessProbe: {}
  ## @param queryFrontend.customStartupProbe Custom startupProbe that overrides the default one
  ##
  customStartupProbe: {}
  ## ingester resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param queryFrontend.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if queryFrontend.resources is set (queryFrontend.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "nano"
  ## @param queryFrontend.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
  ## Configure Pods Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param queryFrontend.podSecurityContext.enabled Enabled Query Frontend pods' Security Context
  ## @param queryFrontend.podSecurityContext.fsGroupChangePolicy Set filesystem group change policy
  ## @param queryFrontend.podSecurityContext.sysctls Set kernel settings using the sysctl interface
  ## @param queryFrontend.podSecurityContext.supplementalGroups Set filesystem extra groups
  ## @param queryFrontend.podSecurityContext.fsGroup Set Query Frontend pod's Security Context fsGroup
  ##
  podSecurityContext:
    enabled: true
    fsGroupChangePolicy: Always
    sysctls: []
    supplementalGroups: []
    fsGroup: 1001
  ## Configure Container Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param queryFrontend.containerSecurityContext.enabled Enabled containers' Security Context
  ## @param queryFrontend.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in container
  ## @param queryFrontend.containerSecurityContext.runAsUser Set containers' Security Context runAsUser
  ## @param queryFrontend.containerSecurityContext.runAsGroup Set containers' Security Context runAsGroup
  ## @param queryFrontend.containerSecurityContext.runAsNonRoot Set container's Security Context runAsNonRoot
  ## @param queryFrontend.containerSecurityContext.privileged Set container's Security Context privileged
  ## @param queryFrontend.containerSecurityContext.readOnlyRootFilesystem Set container's Security Context readOnlyRootFilesystem
  ## @param queryFrontend.containerSecurityContext.allowPrivilegeEscalation Set container's Security Context allowPrivilegeEscalation
  ## @param queryFrontend.containerSecurityContext.capabilities.drop List of capabilities to be dropped
  ## @param queryFrontend.containerSecurityContext.seccompProfile.type Set container's Security Context seccomp profile
  ##
  containerSecurityContext:
    enabled: true
    seLinuxOptions: {}
    runAsUser: 1001
    runAsGroup: 1001
    runAsNonRoot: true
    privileged: false
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
    seccompProfile:
      type: "RuntimeDefault"
  ## @param queryFrontend.lifecycleHooks for the ingester container(s) to automate configuration before or after startup
  ##
  lifecycleHooks: {}
  ## @param queryFrontend.automountServiceAccountToken Mount Service Account token in pod
  ##
  automountServiceAccountToken: false
  ## @param queryFrontend.hostAliases ingester pods host aliases
  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
  ##
  hostAliases: []
  ## @param queryFrontend.podLabels Extra labels for ingester pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  ##
  podLabels: {}
  ## @param queryFrontend.podAnnotations Annotations for ingester pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  ##
  podAnnotations: {}
  ## @param queryFrontend.podAffinityPreset Pod affinity preset. Ignored if `queryFrontend.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAffinityPreset: ""
  ## @param queryFrontend.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `queryFrontend.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAntiAffinityPreset: soft
  ## Node queryFrontendaffinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ##
  nodeAffinityPreset:
    ## @param queryFrontend.nodeAffinityPreset.type Node affinity preset type. Ignored if `queryFrontend.affinity` is set. Allowed values: `soft` or `hard`
    ##
    type: ""
    ## @param queryFrontend.nodeAffinityPreset.key Node label key to match. Ignored if `queryFrontend.affinity` is set
    ##
    key: ""
    ## @param queryFrontend.nodeAffinityPreset.values Node label values to match. Ignored if `queryFrontend.affinity` is set
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []
  ## @param queryFrontend.affinity Affinity for Query Frontend pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## NOTE: `queryFrontend.podAffinityPreset`, `queryFrontend.podAntiAffinityPreset`, and `queryFrontend.nodeAffinityPreset` will be ignored when it's set
  ##
  affinity: {}
  ## @param queryFrontend.nodeSelector Node labels for Query Frontend pods assignment
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/
  ##
  nodeSelector: {}
  ## @param queryFrontend.tolerations Tolerations for Query Frontend pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  ## @param queryFrontend.topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains
  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
  ##
  topologySpreadConstraints: []
  ## @param queryFrontend.priorityClassName Query Frontend pods' priorityClassName
  ##
  priorityClassName: ""
  ## @param queryFrontend.schedulerName Kubernetes pod scheduler registry
  ## https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  schedulerName: ""
  ## @param queryFrontend.terminationGracePeriodSeconds Seconds pod needs to terminate gracefully
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods
  ##
  terminationGracePeriodSeconds: ""
  ## @param queryFrontend.updateStrategy.type Query Frontend statefulset strategy type
  ## @param queryFrontend.updateStrategy.rollingUpdate Query Frontend statefulset rolling update configuration parameters
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  ##
  updateStrategy:
    type: RollingUpdate
    rollingUpdate: {}
  ## @param queryFrontend.extraVolumes Optionally specify extra list of additional volumes for the Query Frontend pod(s)
  ##
  extraVolumes: []
  ## @param queryFrontend.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the Query Frontend container(s)
  ##
  extraVolumeMounts: []
  ## @param queryFrontend.sidecars Add additional sidecar containers to the Query Frontend pod(s)
  ## e.g:
  ## sidecars:
  ##   - name: your-image-name
  ##     image: your-image
  ##     imagePullPolicy: Always
  ##     ports:
  ##       - name: portname
  ##         containerPort: 1234
  ##
  sidecars: []
  ## @param queryFrontend.initContainers Add additional init containers to the Query Frontend pod(s)
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  ## e.g:
  ## initContainers:
  ##  - name: your-image-name
  ##    image: your-image
  ##    imagePullPolicy: Always
  ##    command: ['sh', '-c', 'echo "hello world"']
  ##
  initContainers: []
  ## @section Query Frontend Traffic Exposure Parameters
  ##

  ## ingester service parameters
  ##
  service:
    ## @param queryFrontend.service.type Query Frontend service type
    ##
    type: ClusterIP
    ## @param queryFrontend.service.ports.http Query Frontend HTTP service port
    ## @param queryFrontend.service.ports.grpc Query Frontend GRPC service port
    ##
    ports:
      http: 8080
      grpc: 9095
    ## Node ports to expose
    ## NOTE: choose port between <30000-32767>
    ## @param queryFrontend.service.nodePorts.http Node port for HTTP
    ## @param queryFrontend.service.nodePorts.grpc Node port for GRPC
    ##
    nodePorts:
      http: ""
      grpc: 9095
    ## @param queryFrontend.service.sessionAffinityConfig Additional settings for the sessionAffinity
    ## sessionAffinityConfig:
    ##   clientIP:
    ##     timeoutSeconds: 300
    ##
    sessionAffinityConfig: {}
    ## @param queryFrontend.service.sessionAffinity Control where client requests go, to the same pod or round-robin
    ## Values: ClientIP or None
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/
    ##
    sessionAffinity: None
    ## @param queryFrontend.service.clusterIP Query Frontend service Cluster IP
    ## e.g.:
    ## clusterIP: None
    ##
    clusterIP: ""
    ## @param queryFrontend.service.loadBalancerIP Query Frontend service Load Balancer IP
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer
    ##
    loadBalancerIP: ""
    ## @param queryFrontend.service.loadBalancerSourceRanges Query Frontend service Load Balancer sources
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
    ## e.g:
    ## loadBalancerSourceRanges:
    ##   - 10.10.10.0/24
    ##
    loadBalancerSourceRanges: []
    ## @param queryFrontend.service.externalTrafficPolicy Query Frontend service external traffic policy
    ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    externalTrafficPolicy: Cluster
    ## @param queryFrontend.service.annotations Additional custom annotations for Query Frontend service
    ##
    annotations: {}
    ## @param queryFrontend.service.extraPorts Extra ports to expose in the Query Frontend service
    ##
    extraPorts: []
    ## Headless service properties
    ##
    headless:
      ## @param queryFrontend.service.headless.annotations Annotations for the headless service.
      ##
      annotations: {}
  ## Network Policies
  ## Ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/
  ##
  networkPolicy:
    ## @param queryFrontend.networkPolicy.enabled Specifies whether a NetworkPolicy should be created
    ##
    enabled: true
    ## @param queryFrontend.networkPolicy.allowExternal Don't require server label for connections
    ## The Policy model to apply. When set to false, only pods with the correct
    ## server label will have network access to the ports server is listening
    ## on. When true, server will accept connections from any source
    ## (with the correct destination port).
    ##
    allowExternal: true
    ## @param queryFrontend.networkPolicy.allowExternalEgress Allow the pod to access any range of port and all destinations.
    ##
    allowExternalEgress: true
    ## @param queryFrontend.networkPolicy.extraIngress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraIngress:
    ##   - ports:
    ##       - port: 1234
    ##     from:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    extraIngress: []
    ## @param queryFrontend.networkPolicy.extraEgress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraEgress:
    ##   - ports:
    ##       - port: 1234
    ##     to:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    ##
    extraEgress: []
    ## @param queryFrontend.networkPolicy.ingressNSMatchLabels [object] Labels to match to allow traffic from other namespaces
    ## @param queryFrontend.networkPolicy.ingressNSPodMatchLabels [object] Pod labels to match to allow traffic from other namespaces
    ##
    ingressNSMatchLabels: {}
    ingressNSPodMatchLabels: {}
  ## Pod Disruption Budget configuration
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb
  ## @param queryFrontend.pdb.create Enable/disable a Pod Disruption Budget creation
  ## @param queryFrontend.pdb.minAvailable Minimum number/percentage of pods that should remain scheduled
  ## @param queryFrontend.pdb.maxUnavailable Maximum number/percentage of pods that may be made unavailable
  ##
  pdb:
    create: false
    minAvailable: 1
    maxUnavailable: ""
# @section query-scheduler Deployment Parameters
##
queryScheduler:
  ## @param queryScheduler.enabled Enable query-scheduler deployment
  ##
  enabled: false
  ## @param queryScheduler.extraEnvVars Array with extra environment variables to add to query-scheduler nodes
  ## e.g:
  ## extraEnvVars:
  ##   - name: FOO
  ##     value: "bar"
  ##
  extraEnvVars: []
  ## @param queryScheduler.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for query-scheduler nodes
  ##
  extraEnvVarsCM: ""
  ## @param queryScheduler.extraEnvVarsSecret Name of existing Secret containing extra env vars for query-scheduler nodes
  ##
  extraEnvVarsSecret: ""
  ## @param queryScheduler.command Override default container command (useful when using custom images)
  ##
  command: []
  ## @param queryScheduler.args Override default container args (useful when using custom images)
  ##
  args: []
  ## @param queryScheduler.extraArgs Add additional args to the default container args (useful to override configuration)
  ## e.g:
  ## extraArgs:
  ##   - "-log.level=debug"
  extraArgs: []
  ## @param queryScheduler.replicaCount Number of Query Scheduler replicas to deploy
  ##
  replicaCount: 1
  ## Configure extra options for Query Scheduler containers' liveness, readiness and startup probes
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  ## @param queryScheduler.livenessProbe.enabled Enable livenessProbe on Query Scheduler nodes
  ## @param queryScheduler.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
  ## @param queryScheduler.livenessProbe.periodSeconds Period seconds for livenessProbe
  ## @param queryScheduler.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
  ## @param queryScheduler.livenessProbe.failureThreshold Failure threshold for livenessProbe
  ## @param queryScheduler.livenessProbe.successThreshold Success threshold for livenessProbe
  ##
  livenessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param queryScheduler.readinessProbe.enabled Enable readinessProbe on Query Scheduler nodes
  ## @param queryScheduler.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
  ## @param queryScheduler.readinessProbe.periodSeconds Period seconds for readinessProbe
  ## @param queryScheduler.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
  ## @param queryScheduler.readinessProbe.failureThreshold Failure threshold for readinessProbe
  ## @param queryScheduler.readinessProbe.successThreshold Success threshold for readinessProbe
  ##
  readinessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 30
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param queryScheduler.startupProbe.enabled Enable startupProbe on Query Scheduler containers
  ## @param queryScheduler.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe
  ## @param queryScheduler.startupProbe.periodSeconds Period seconds for startupProbe
  ## @param queryScheduler.startupProbe.timeoutSeconds Timeout seconds for startupProbe
  ## @param queryScheduler.startupProbe.failureThreshold Failure threshold for startupProbe
  ## @param queryScheduler.startupProbe.successThreshold Success threshold for startupProbe
  ##
  startupProbe:
    enabled: false
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 1
    failureThreshold: 15
    successThreshold: 1
  ## @param queryScheduler.customLivenessProbe Custom livenessProbe that overrides the default one
  ##
  customLivenessProbe: {}
  ## @param queryScheduler.customReadinessProbe Custom readinessProbe that overrides the default one
  ##
  customReadinessProbe: {}
  ## @param queryScheduler.customStartupProbe Custom startupProbe that overrides the default one
  ##
  customStartupProbe: {}
  ## query-scheduler resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param queryScheduler.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if queryScheduler.resources is set (queryScheduler.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "nano"
  ## @param queryScheduler.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
  ## Configure Pods Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param queryScheduler.podSecurityContext.enabled Enabled Query Scheduler pods' Security Context
  ## @param queryScheduler.podSecurityContext.fsGroupChangePolicy Set filesystem group change policy
  ## @param queryScheduler.podSecurityContext.sysctls Set kernel settings using the sysctl interface
  ## @param queryScheduler.podSecurityContext.supplementalGroups Set filesystem extra groups
  ## @param queryScheduler.podSecurityContext.fsGroup Set Query Scheduler pod's Security Context fsGroup
  ##
  podSecurityContext:
    enabled: true
    fsGroupChangePolicy: Always
    sysctls: []
    supplementalGroups: []
    fsGroup: 1001
  ## Configure Container Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param queryScheduler.containerSecurityContext.enabled Enabled containers' Security Context
  ## @param queryScheduler.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in container
  ## @param queryScheduler.containerSecurityContext.runAsUser Set containers' Security Context runAsUser
  ## @param queryScheduler.containerSecurityContext.runAsGroup Set containers' Security Context runAsGroup
  ## @param queryScheduler.containerSecurityContext.runAsNonRoot Set container's Security Context runAsNonRoot
  ## @param queryScheduler.containerSecurityContext.privileged Set container's Security Context privileged
  ## @param queryScheduler.containerSecurityContext.readOnlyRootFilesystem Set container's Security Context readOnlyRootFilesystem
  ## @param queryScheduler.containerSecurityContext.allowPrivilegeEscalation Set container's Security Context allowPrivilegeEscalation
  ## @param queryScheduler.containerSecurityContext.capabilities.drop List of capabilities to be dropped
  ## @param queryScheduler.containerSecurityContext.seccompProfile.type Set container's Security Context seccomp profile
  ##
  containerSecurityContext:
    enabled: true
    seLinuxOptions: {}
    runAsUser: 1001
    runAsGroup: 1001
    runAsNonRoot: true
    privileged: false
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
    seccompProfile:
      type: "RuntimeDefault"
  ## @param queryScheduler.lifecycleHooks for the ingester container(s) to automate configuration before or after startup
  ##
  lifecycleHooks: {}
  ## @param queryScheduler.automountServiceAccountToken Mount Service Account token in pod
  ##
  automountServiceAccountToken: false
  ## @param queryScheduler.hostAliases ingester pods host aliases
  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
  ##
  hostAliases: []
  ## @param queryScheduler.podLabels Extra labels for ingester pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  ##
  podLabels: {}
  ## @param queryScheduler.podAnnotations Annotations for ingester pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  ##
  podAnnotations: {}
  ## @param queryScheduler.podAffinityPreset Pod affinity preset. Ignored if `queryScheduler.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAffinityPreset: ""
  ## @param queryScheduler.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `queryScheduler.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAntiAffinityPreset: soft
  ## Node queryScheduler.affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ##
  nodeAffinityPreset:
    ## @param queryScheduler.nodeAffinityPreset.type Node affinity preset type. Ignored if `queryScheduler.affinity` is set. Allowed values: `soft` or `hard`
    ##
    type: ""
    ## @param queryScheduler.nodeAffinityPreset.key Node label key to match. Ignored if `queryScheduler.affinity` is set
    ##
    key: ""
    ## @param queryScheduler.nodeAffinityPreset.values Node label values to match. Ignored if `queryScheduler.affinity` is set
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []
  ## @param queryScheduler.affinity Affinity for Query Scheduler pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## NOTE: `queryScheduler.podAffinityPreset`, `queryScheduler.podAntiAffinityPreset`, and `queryScheduler.nodeAffinityPreset` will be ignored when it's set
  ##
  affinity: {}
  ## @param queryScheduler.nodeSelector Node labels for Query Scheduler pods assignment
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/
  ##
  nodeSelector: {}
  ## @param queryScheduler.tolerations Tolerations for Query Scheduler pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  ## @param queryScheduler.topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains
  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
  ##
  topologySpreadConstraints: []
  ## @param queryScheduler.priorityClassName Query Scheduler pods' priorityClassName
  ##
  priorityClassName: ""
  ## @param queryScheduler.schedulerName Kubernetes pod scheduler registry
  ## https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  schedulerName: ""
  ## @param queryScheduler.terminationGracePeriodSeconds Seconds pod needs to terminate gracefully
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods
  ##
  terminationGracePeriodSeconds: ""
  ## @param queryScheduler.updateStrategy.type Query Scheduler statefulset strategy type
  ## @param queryScheduler.updateStrategy.rollingUpdate Query Scheduler statefulset rolling update configuration parameters
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  ##
  updateStrategy:
    type: RollingUpdate
    rollingUpdate: {}
  ## @param queryScheduler.extraVolumes Optionally specify extra list of additional volumes for the Query Scheduler pod(s)
  ##
  extraVolumes: []
  ## @param queryScheduler.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the Query Scheduler container(s)
  ##
  extraVolumeMounts: []
  ## @param queryScheduler.sidecars Add additional sidecar containers to the Query Scheduler pod(s)
  ## e.g:
  ## sidecars:
  ##   - name: your-image-name
  ##     image: your-image
  ##     imagePullPolicy: Always
  ##     ports:
  ##       - name: portname
  ##         containerPort: 1234
  ##
  sidecars: []
  ## @param queryScheduler.initContainers Add additional init containers to the Query Scheduler pod(s)
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  ## e.g:
  ## initContainers:
  ##  - name: your-image-name
  ##    image: your-image
  ##    imagePullPolicy: Always
  ##    command: ['sh', '-c', 'echo "hello world"']
  ##
  initContainers: []
  ## @section Query Scheduler Traffic Exposure Parameters
  ##

  ## ingester service parameters
  ##
  service:
    ## @param queryScheduler.service.type Query Scheduler service type
    ##
    type: ClusterIP
    ## @param queryScheduler.service.ports.http Query Scheduler HTTP service port
    ## @param queryScheduler.service.ports.grpc Query Scheduler GRPC service port
    ##
    ports:
      http: 8080
      grpc: 9095
    ## Node ports to expose
    ## NOTE: choose port between <30000-32767>
    ## @param queryScheduler.service.nodePorts.http Node port for HTTP
    ## @param queryScheduler.service.nodePorts.grpc Node port for GRPC
    ##
    nodePorts:
      http: ""
      grpc: 9095
    ## @param queryScheduler.service.sessionAffinityConfig Additional settings for the sessionAffinity
    ## sessionAffinityConfig:
    ##   clientIP:
    ##     timeoutSeconds: 300
    ##
    sessionAffinityConfig: {}
    ## @param queryScheduler.service.sessionAffinity Control where client requests go, to the same pod or round-robin
    ## Values: ClientIP or None
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/
    ##
    sessionAffinity: None
    ## @param queryScheduler.service.clusterIP Query Scheduler service Cluster IP
    ## e.g.:
    ## clusterIP: None
    ##
    clusterIP: ""
    ## @param queryScheduler.service.loadBalancerIP Query Scheduler service Load Balancer IP
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer
    ##
    loadBalancerIP: ""
    ## @param queryScheduler.service.loadBalancerSourceRanges Query Scheduler service Load Balancer sources
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
    ## e.g:
    ## loadBalancerSourceRanges:
    ##   - 10.10.10.0/24
    ##
    loadBalancerSourceRanges: []
    ## @param queryScheduler.service.externalTrafficPolicy Query Scheduler service external traffic policy
    ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    externalTrafficPolicy: Cluster
    ## @param queryScheduler.service.annotations Additional custom annotations for Query Scheduler service
    ##
    annotations: {}
    ## @param queryScheduler.service.extraPorts Extra ports to expose in the Query Scheduler service
    ##
    extraPorts: []
    ## Headless service properties
    ##
    headless:
      ## @param queryScheduler.service.headless.annotations Annotations for the headless service.
      ##
      annotations: {}
  ## Network Policies
  ## Ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/
  ##
  networkPolicy:
    ## @param queryScheduler.networkPolicy.enabled Specifies whether a NetworkPolicy should be created
    ##
    enabled: true
    ## @param queryScheduler.networkPolicy.allowExternal Don't require server label for connections
    ## The Policy model to apply. When set to false, only pods with the correct
    ## server label will have network access to the ports server is listening
    ## on. When true, server will accept connections from any source
    ## (with the correct destination port).
    ##
    allowExternal: true
    ## @param queryScheduler.networkPolicy.allowExternalEgress Allow the pod to access any range of port and all destinations.
    ##
    allowExternalEgress: true
    ## @param queryScheduler.networkPolicy.extraIngress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraIngress:
    ##   - ports:
    ##       - port: 1234
    ##     from:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    extraIngress: []
    ## @param queryScheduler.networkPolicy.extraEgress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraEgress:
    ##   - ports:
    ##       - port: 1234
    ##     to:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    ##
    extraEgress: []
    ## @param queryScheduler.networkPolicy.ingressNSMatchLabels [object] Labels to match to allow traffic from other namespaces
    ## @param queryScheduler.networkPolicy.ingressNSPodMatchLabels [object] Pod labels to match to allow traffic from other namespaces
    ##
    ingressNSMatchLabels: {}
    ingressNSPodMatchLabels: {}
  ## Pod Disruption Budget configuration
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb
  ## @param queryScheduler.pdb.create Enable/disable a Pod Disruption Budget creation
  ## @param queryScheduler.pdb.minAvailable Minimum number/percentage of pods that should remain scheduled
  ## @param queryScheduler.pdb.maxUnavailable Maximum number/percentage of pods that may be made unavailable
  ##
  pdb:
    create: false
    minAvailable: 1
    maxUnavailable: ""
## @section Store Gateway Deployment Parameters
##
storeGateway:
  ## @param storeGateway.extraEnvVars Array with extra environment variables to add to ingester nodes
  ## e.g:
  ## extraEnvVars:
  ##   - name: FOO
  ##     value: "bar"
  ##
  extraEnvVars: []
  ## @param storeGateway.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for ingester nodes
  ##
  extraEnvVarsCM: ""
  ## @param storeGateway.extraEnvVarsSecret Name of existing Secret containing extra env vars for ingester nodes
  ##
  extraEnvVarsSecret: ""
  ## @param storeGateway.command Override default container command (useful when using custom images)
  ##
  command: []
  ## @param storeGateway.args Override default container args (useful when using custom images)
  ##
  args: []
  ## @param storeGateway.extraArgs Add additional args to the default container args (useful to override configuration)
  ## e.g:
  ## extraArgs:
  ##   - "-log.level=debug"
  extraArgs: []
  ## @param storeGateway.replicaCount Number of Store Gateway replicas to deploy
  ##
  replicaCount: 1
  ## @param storeGateway.podManagementPolicy Statefulset Pod management policy, it needs to be Parallel to be able to complete the cluster join
  ## Ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  ##
  podManagementPolicy: OrderedReady
  ## Configure extra options for Store Gateway containers' liveness, readiness and startup probes
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  ## @param storeGateway.livenessProbe.enabled Enable livenessProbe on Store Gateway nodes
  ## @param storeGateway.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
  ## @param storeGateway.livenessProbe.periodSeconds Period seconds for livenessProbe
  ## @param storeGateway.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
  ## @param storeGateway.livenessProbe.failureThreshold Failure threshold for livenessProbe
  ## @param storeGateway.livenessProbe.successThreshold Success threshold for livenessProbe
  ##
  livenessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 60
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param storeGateway.readinessProbe.enabled Enable readinessProbe on Store Gateway nodes
  ## @param storeGateway.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
  ## @param storeGateway.readinessProbe.periodSeconds Period seconds for readinessProbe
  ## @param storeGateway.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
  ## @param storeGateway.readinessProbe.failureThreshold Failure threshold for readinessProbe
  ## @param storeGateway.readinessProbe.successThreshold Success threshold for readinessProbe
  ##
  readinessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 60
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param storeGateway.startupProbe.enabled Enable startupProbe on Store Gateway containers
  ## @param storeGateway.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe
  ## @param storeGateway.startupProbe.periodSeconds Period seconds for startupProbe
  ## @param storeGateway.startupProbe.timeoutSeconds Timeout seconds for startupProbe
  ## @param storeGateway.startupProbe.failureThreshold Failure threshold for startupProbe
  ## @param storeGateway.startupProbe.successThreshold Success threshold for startupProbe
  ##
  startupProbe:
    enabled: false
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 1
    failureThreshold: 15
    successThreshold: 1
  ## @param storeGateway.customLivenessProbe Custom livenessProbe that overrides the default one
  ##
  customLivenessProbe: {}
  ## @param storeGateway.customReadinessProbe Custom readinessProbe that overrides the default one
  ##
  customReadinessProbe: {}
  ## @param storeGateway.customStartupProbe Custom startupProbe that overrides the default one
  ##
  customStartupProbe: {}
  ## ingester resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param storeGateway.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if storeGateway.resources is set (storeGateway.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "nano"
  ## @param storeGateway.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
  ## Configure Pods Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param storeGateway.podSecurityContext.enabled Enabled Store Gateway pods' Security Context
  ## @param storeGateway.podSecurityContext.fsGroupChangePolicy Set filesystem group change policy
  ## @param storeGateway.podSecurityContext.sysctls Set kernel settings using the sysctl interface
  ## @param storeGateway.podSecurityContext.supplementalGroups Set filesystem extra groups
  ## @param storeGateway.podSecurityContext.fsGroup Set Store Gateway pod's Security Context fsGroup
  ##
  podSecurityContext:
    enabled: true
    fsGroupChangePolicy: Always
    sysctls: []
    supplementalGroups: []
    fsGroup: 1001
  ## Configure Container Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param storeGateway.containerSecurityContext.enabled Enabled containers' Security Context
  ## @param storeGateway.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in container
  ## @param storeGateway.containerSecurityContext.runAsUser Set containers' Security Context runAsUser
  ## @param storeGateway.containerSecurityContext.runAsGroup Set containers' Security Context runAsGroup
  ## @param storeGateway.containerSecurityContext.runAsNonRoot Set container's Security Context runAsNonRoot
  ## @param storeGateway.containerSecurityContext.privileged Set container's Security Context privileged
  ## @param storeGateway.containerSecurityContext.readOnlyRootFilesystem Set container's Security Context readOnlyRootFilesystem
  ## @param storeGateway.containerSecurityContext.allowPrivilegeEscalation Set container's Security Context allowPrivilegeEscalation
  ## @param storeGateway.containerSecurityContext.capabilities.drop List of capabilities to be dropped
  ## @param storeGateway.containerSecurityContext.seccompProfile.type Set container's Security Context seccomp profile
  ##
  containerSecurityContext:
    enabled: true
    seLinuxOptions: {}
    runAsUser: 1001
    runAsGroup: 1001
    runAsNonRoot: true
    privileged: false
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
    seccompProfile:
      type: "RuntimeDefault"
  ## @param storeGateway.lifecycleHooks for the ingester container(s) to automate configuration before or after startup
  ##
  lifecycleHooks: {}
  ## @param storeGateway.automountServiceAccountToken Mount Service Account token in pod
  ##
  automountServiceAccountToken: false
  ## @param storeGateway.hostAliases ingester pods host aliases
  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
  ##
  hostAliases: []
  ## @param storeGateway.podLabels Extra labels for ingester pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  ##
  podLabels: {}
  ## @param storeGateway.podAnnotations Annotations for ingester pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  ##
  podAnnotations: {}
  ## @param storeGateway.podAffinityPreset Pod affinity preset. Ignored if `storeGateway.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAffinityPreset: ""
  ## @param storeGateway.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `storeGateway.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAntiAffinityPreset: soft
  ## Node storeGateway.affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ##
  nodeAffinityPreset:
    ## @param storeGateway.nodeAffinityPreset.type Node affinity preset type. Ignored if `storeGateway.affinity` is set. Allowed values: `soft` or `hard`
    ##
    type: ""
    ## @param storeGateway.nodeAffinityPreset.key Node label key to match. Ignored if `storeGateway.affinity` is set
    ##
    key: ""
    ## @param storeGateway.nodeAffinityPreset.values Node label values to match. Ignored if `storeGateway.affinity` is set
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []
  ## @param storeGateway.affinity Affinity for Store Gateway pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## NOTE: `storeGateway.podAffinityPreset`, `storeGateway.podAntiAffinityPreset`, and `storeGateway.nodeAffinityPreset` will be ignored when it's set
  ##
  affinity: {}
  ## @param storeGateway.nodeSelector Node labels for Store Gateway pods assignment
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/
  ##
  nodeSelector: {}
  ## @param storeGateway.tolerations Tolerations for Store Gateway pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  ## @param storeGateway.topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains
  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
  ##
  topologySpreadConstraints: []
  ## @param storeGateway.priorityClassName Store Gateway pods' priorityClassName
  ##
  priorityClassName: ""
  ## @param storeGateway.schedulerName Kubernetes pod scheduler registry
  ## https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  schedulerName: ""
  ## @param storeGateway.terminationGracePeriodSeconds Seconds pod needs to terminate gracefully
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods
  ##
  terminationGracePeriodSeconds: ""
  ## @param storeGateway.updateStrategy.type Store Gateway statefulset strategy type
  ## @param storeGateway.updateStrategy.rollingUpdate Store Gateway statefulset rolling update configuration parameters
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  ##
  updateStrategy:
    type: RollingUpdate
    rollingUpdate: {}
  ## @param storeGateway.extraVolumes Optionally specify extra list of additional volumes for the Store Gateway pod(s)
  ##
  extraVolumes: []
  ## @param storeGateway.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the Store Gateway container(s)
  ##
  extraVolumeMounts: []
  ## @param storeGateway.sidecars Add additional sidecar containers to the Store Gateway pod(s)
  ## e.g:
  ## sidecars:
  ##   - name: your-image-name
  ##     image: your-image
  ##     imagePullPolicy: Always
  ##     ports:
  ##       - name: portname
  ##         containerPort: 1234
  ##
  sidecars: []
  ## @param storeGateway.initContainers Add additional init containers to the Store Gateway pod(s)
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  ## e.g:
  ## initContainers:
  ##  - name: your-image-name
  ##    image: your-image
  ##    imagePullPolicy: Always
  ##    command: ['sh', '-c', 'echo "hello world"']
  ##
  initContainers: []
  ## Enable persistence using Persistent Volume Claims
  ## ref: https://kubernetes.io/docs/concepts/storage/persistent-volumes/
  ##
  persistence:
    ## @param storeGateway.persistence.enabled Enable persistence in Store Gateway instances
    ##
    enabled: true
    ## @param storeGateway.persistence.existingClaim Name of an existing PVC to use
    ##
    existingClaim: ""
    ## @param storeGateway.persistence.storageClass PVC Storage Class for Store Gateway data volume
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    storageClass: ""
    ## @param storeGateway.persistence.accessModes PVC Access modes
    ##
    accessModes:
      - ReadWriteOnce
    ## @param storeGateway.persistence.size PVC Storage Request for Store Gateway data volume
    ##
    size: 8Gi
    ## @param storeGateway.persistence.annotations Additional PVC annotations
    ##
    annotations: {}
    ## @param storeGateway.persistence.selector Selector to match an existing Persistent Volume for Store Gateway's data PVC
    ## If set, the PVC can't have a PV dynamically provisioned for it
    ## E.g.
    ## selector:
    ##   matchLabels:
    ##     app: my-app
    ##
    selector: {}
    ## @param storeGateway.persistence.dataSource PVC data source
    ##
    dataSource: {}
  ## @section Store Gateway Traffic Exposure Parameters
  ##

  ## ingester service parameters
  ##
  service:
    ## @param storeGateway.service.type Store Gateway service type
    ##
    type: ClusterIP
    ## @param storeGateway.service.ports.http Store Gateway HTTP service port
    ## @param storeGateway.service.ports.grpc Store Gateway GRPC service port
    ##
    ports:
      http: 8080
      grpc: 9095
    ## Node ports to expose
    ## NOTE: choose port between <30000-32767>
    ## @param storeGateway.service.nodePorts.http Node port for HTTP
    ## @param storeGateway.service.nodePorts.grpc Node port for GRPC
    ##
    nodePorts:
      http: ""
      grpc: 9095
    ## @param storeGateway.service.sessionAffinityConfig Additional settings for the sessionAffinity
    ## sessionAffinityConfig:
    ##   clientIP:
    ##     timeoutSeconds: 300
    ##
    sessionAffinityConfig: {}
    ## @param storeGateway.service.sessionAffinity Control where client requests go, to the same pod or round-robin
    ## Values: ClientIP or None
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/
    ##
    sessionAffinity: None
    ## @param storeGateway.service.clusterIP Store Gateway service Cluster IP
    ## e.g.:
    ## clusterIP: None
    ##
    clusterIP: ""
    ## @param storeGateway.service.loadBalancerIP Store Gateway service Load Balancer IP
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer
    ##
    loadBalancerIP: ""
    ## @param storeGateway.service.loadBalancerSourceRanges Store Gateway service Load Balancer sources
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
    ## e.g:
    ## loadBalancerSourceRanges:
    ##   - 10.10.10.0/24
    ##
    loadBalancerSourceRanges: []
    ## @param storeGateway.service.externalTrafficPolicy Store Gateway service external traffic policy
    ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    externalTrafficPolicy: Cluster
    ## @param storeGateway.service.annotations Additional custom annotations for Store Gateway service
    ##
    annotations: {}
    ## @param storeGateway.service.extraPorts Extra ports to expose in the Store Gateway service
    ##
    extraPorts: []
    ## Headless service properties
    ##
    headless:
      ## @param storeGateway.service.headless.annotations Annotations for the headless service.
      ##
      annotations: {}
  ## Network Policies
  ## Ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/
  ##
  networkPolicy:
    ## @param storeGateway.networkPolicy.enabled Specifies whether a NetworkPolicy should be created
    ##
    enabled: true
    ## @param storeGateway.networkPolicy.allowExternal Don't require server label for connections
    ## The Policy model to apply. When set to false, only pods with the correct
    ## server label will have network access to the ports server is listening
    ## on. When true, server will accept connections from any source
    ## (with the correct destination port).
    ##
    allowExternal: true
    ## @param storeGateway.networkPolicy.allowExternalEgress Allow the pod to access any range of port and all destinations.
    ##
    allowExternalEgress: true
    ## @param storeGateway.networkPolicy.extraIngress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraIngress:
    ##   - ports:
    ##       - port: 1234
    ##     from:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    extraIngress: []
    ## @param storeGateway.networkPolicy.extraEgress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraEgress:
    ##   - ports:
    ##       - port: 1234
    ##     to:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    ##
    extraEgress: []
    ## @param storeGateway.networkPolicy.ingressNSMatchLabels [object] Labels to match to allow traffic from other namespaces
    ## @param storeGateway.networkPolicy.ingressNSPodMatchLabels [object] Pod labels to match to allow traffic from other namespaces
    ##
    ingressNSMatchLabels: {}
    ingressNSPodMatchLabels: {}
  ## Pod Disruption Budget configuration
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb
  ## @param storeGateway.pdb.create Enable/disable a Pod Disruption Budget creation
  ## @param storeGateway.pdb.minAvailable Minimum number/percentage of pods that should remain scheduled
  ## @param storeGateway.pdb.maxUnavailable Maximum number/percentage of pods that may be made unavailable
  ##
  pdb:
    create: false
    minAvailable: 1
    maxUnavailable: ""
## @section Ruler Deployment Parameters
##
ruler:
  ## @param ruler.enabled Deploy ruler component
  ##
  enabled: false
  ## @param ruler.extraEnvVars Array with extra environment variables to add to ruler nodes
  ## e.g:
  ## extraEnvVars:
  ##   - name: FOO
  ##     value: "bar"
  ##
  extraEnvVars: []
  ## @param ruler.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for ruler nodes
  ##
  extraEnvVarsCM: ""
  ## @param ruler.extraEnvVarsSecret Name of existing Secret containing extra env vars for ruler nodes
  ##
  extraEnvVarsSecret: ""
  ## @param ruler.command Override default container command (useful when using custom images)
  ##
  command: []
  ## @param ruler.args Override default container args (useful when using custom images)
  ##
  args: []
  ## @param ruler.extraArgs Add additional args to the default container args (useful to override configuration)
  ## e.g:
  ## extraArgs:
  ##   - "-log.level=debug"
  extraArgs: []
  ## @param ruler.podManagementPolicy podManagementPolicy to manage scaling operation
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  ##
  podManagementPolicy: ""
  ## @param ruler.replicaCount Number of Ruler replicas to deploy
  ##
  replicaCount: 1
  ## Configure extra options for Ruler containers' liveness, readiness and startup probes
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes
  ## @param ruler.livenessProbe.enabled Enable livenessProbe on Ruler nodes
  ## @param ruler.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
  ## @param ruler.livenessProbe.periodSeconds Period seconds for livenessProbe
  ## @param ruler.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
  ## @param ruler.livenessProbe.failureThreshold Failure threshold for livenessProbe
  ## @param ruler.livenessProbe.successThreshold Success threshold for livenessProbe
  ##
  livenessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 10
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param ruler.readinessProbe.enabled Enable readinessProbe on Ruler nodes
  ## @param ruler.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
  ## @param ruler.readinessProbe.periodSeconds Period seconds for readinessProbe
  ## @param ruler.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
  ## @param ruler.readinessProbe.failureThreshold Failure threshold for readinessProbe
  ## @param ruler.readinessProbe.successThreshold Success threshold for readinessProbe
  ##
  readinessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 10
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param ruler.startupProbe.enabled Enable startupProbe on Ruler containers
  ## @param ruler.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe
  ## @param ruler.startupProbe.periodSeconds Period seconds for startupProbe
  ## @param ruler.startupProbe.timeoutSeconds Timeout seconds for startupProbe
  ## @param ruler.startupProbe.failureThreshold Failure threshold for startupProbe
  ## @param ruler.startupProbe.successThreshold Success threshold for startupProbe
  ##
  startupProbe:
    enabled: false
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 1
    failureThreshold: 15
    successThreshold: 1
  ## @param ruler.customLivenessProbe Custom livenessProbe that overrides the default one
  ##
  customLivenessProbe: {}
  ## @param ruler.customReadinessProbe Custom readinessProbe that overrides the default one
  ##
  customReadinessProbe: {}
  ## @param ruler.customStartupProbe Custom startupProbe that overrides the default one
  ##
  customStartupProbe: {}
  ## @param ruler.lifecycleHooks for the ruler container(s) to automate configuration before or after startup
  ##
  lifecycleHooks: {}
  ## ruler resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param ruler.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if ruler.resources is set (ruler.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "nano"
  ## @param ruler.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
  ## Configure Pods Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param ruler.podSecurityContext.enabled Enabled Ruler pods' Security Context
  ## @param ruler.podSecurityContext.fsGroupChangePolicy Set filesystem group change policy
  ## @param ruler.podSecurityContext.sysctls Set kernel settings using the sysctl interface
  ## @param ruler.podSecurityContext.supplementalGroups Set filesystem extra groups
  ## @param ruler.podSecurityContext.fsGroup Set Ruler pod's Security Context fsGroup
  ##
  podSecurityContext:
    enabled: true
    fsGroupChangePolicy: Always
    sysctls: []
    supplementalGroups: []
    fsGroup: 1001
  ## Configure Container Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param ruler.containerSecurityContext.enabled Enabled containers' Security Context
  ## @param ruler.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in container
  ## @param ruler.containerSecurityContext.runAsUser Set containers' Security Context runAsUser
  ## @param ruler.containerSecurityContext.runAsGroup Set containers' Security Context runAsGroup
  ## @param ruler.containerSecurityContext.runAsNonRoot Set container's Security Context runAsNonRoot
  ## @param ruler.containerSecurityContext.privileged Set container's Security Context privileged
  ## @param ruler.containerSecurityContext.readOnlyRootFilesystem Set container's Security Context readOnlyRootFilesystem
  ## @param ruler.containerSecurityContext.allowPrivilegeEscalation Set container's Security Context allowPrivilegeEscalation
  ## @param ruler.containerSecurityContext.capabilities.drop List of capabilities to be dropped
  ## @param ruler.containerSecurityContext.seccompProfile.type Set container's Security Context seccomp profile
  ##
  containerSecurityContext:
    enabled: true
    seLinuxOptions: {}
    runAsUser: 1001
    runAsGroup: 1001
    runAsNonRoot: true
    privileged: false
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
    seccompProfile:
      type: "RuntimeDefault"
  ## @param ruler.automountServiceAccountToken Mount Service Account token in pod
  ##
  automountServiceAccountToken: false
  ## @param ruler.hostAliases ruler pods host aliases
  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
  ##
  hostAliases: []
  ## @param ruler.podLabels Extra labels for ruler pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  ##
  podLabels: {}
  ## @param ruler.podAnnotations Annotations for ruler pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  ##
  podAnnotations: {}
  ## @param ruler.podAffinityPreset Pod affinity preset. Ignored if `ruler.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAffinityPreset: ""
  ## @param ruler.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `ruler.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAntiAffinityPreset: soft
  ## Node ruler.affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ##
  nodeAffinityPreset:
    ## @param ruler.nodeAffinityPreset.type Node affinity preset type. Ignored if `ruler.affinity` is set. Allowed values: `soft` or `hard`
    ##
    type: ""
    ## @param ruler.nodeAffinityPreset.key Node label key to match. Ignored if `ruler.affinity` is set
    ##
    key: ""
    ## @param ruler.nodeAffinityPreset.values Node label values to match. Ignored if `ruler.affinity` is set
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []
  ## @param ruler.affinity Affinity for ruler pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## NOTE: `ruler.podAffinityPreset`, `ruler.podAntiAffinityPreset`, and `ruler.nodeAffinityPreset` will be ignored when it's set
  ##
  affinity: {}
  ## @param ruler.nodeSelector Node labels for Ruler pods assignment
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/
  ##
  nodeSelector: {}
  ## @param ruler.tolerations Tolerations for Ruler pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  ## @param ruler.topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains
  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
  ##
  topologySpreadConstraints: []
  ## @param ruler.priorityClassName Ruler pods' priorityClassName
  ##
  priorityClassName: ""
  ## @param ruler.schedulerName Kubernetes pod scheduler registry
  ## https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  schedulerName: ""
  ## @param ruler.terminationGracePeriodSeconds Seconds pod needs to terminate gracefully
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods
  ##
  terminationGracePeriodSeconds: ""
  ## @param ruler.updateStrategy.type Ruler statefulset strategy type
  ## @param ruler.updateStrategy.rollingUpdate Ruler statefulset rolling update configuration parameters
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  ##
  updateStrategy:
    type: RollingUpdate
    rollingUpdate: {}
  ## @param ruler.extraVolumes Optionally specify extra list of additional volumes for the Ruler pod(s)
  ##
  extraVolumes: []
  ## @param ruler.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the ruler container(s)
  ##
  extraVolumeMounts: []
  ## @param ruler.sidecars Add additional sidecar containers to the Ruler pod(s)
  ## e.g:
  ## sidecars:
  ##   - name: your-image-name
  ##     image: your-image
  ##     imagePullPolicy: Always
  ##     ports:
  ##       - name: portname
  ##         containerPort: 1234
  ##
  sidecars: []
  ## @param ruler.initContainers Add additional init containers to the Ruler pod(s)
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  ## e.g:
  ## initContainers:
  ##  - name: your-image-name
  ##    image: your-image
  ##    imagePullPolicy: Always
  ##    command: ['sh', '-c', 'echo "hello world"']
  ##
  initContainers: []
  ## @section Ruler Persistence Parameters
  ##

  ## Enable persistence using Persistent Volume Claims
  ## ref: https://kubernetes.io/docs/concepts/storage/persistent-volumes/
  ##
  persistence:
    ## @param ruler.persistence.enabled Enable persistence in Ruler instances
    ##
    enabled: true
    ## @param ruler.persistence.storageClass PVC Storage Class for Ruler data volume
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    storageClass: ""
    ## @param ruler.persistence.accessModes PVC Access modes
    ##
    accessModes:
      - ReadWriteOnce
    ## @param ruler.persistence.size PVC Storage Request for Ruler data volume
    ##
    size: 8Gi
    ## @param ruler.persistence.annotations Additional PVC annotations
    ##
    annotations: {}
    ## @param ruler.persistence.selector Selector to match an existing Persistent Volume for Ruler's data PVC
    ## If set, the PVC can't have a PV dynamically provisioned for it
    ## E.g.
    ## selector:
    ##   matchLabels:
    ##     app: my-app
    ##
    selector: {}
  ## @section Ruler Traffic Exposure Parameters
  ##

  ## ruler service parameters
  ##
  service:
    ## @param ruler.service.type Ruler service type
    ##
    type: ClusterIP
    ## @param ruler.service.ports.http Ruler HTTP service port
    ## @param ruler.service.ports.grpc Ruler GRPC service port
    ##
    ports:
      http: 8080
      grpc: 9095
    ## Node ports to expose
    ## NOTE: choose port between <30000-32767>
    ## @param ruler.service.nodePorts.http Node port for HTTP
    ## @param ruler.service.nodePorts.grpc Node port for GRPC
    ##
    nodePorts:
      http: ""
      grpc: ""
    ## @param ruler.service.sessionAffinityConfig Additional settings for the sessionAffinity
    ## sessionAffinityConfig:
    ##   clientIP:
    ##     timeoutSeconds: 300
    ##
    sessionAffinityConfig: {}
    ## @param ruler.service.sessionAffinity Control where client requests go, to the same pod or round-robin
    ## Values: ClientIP or None
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/
    ##
    sessionAffinity: None
    ## @param ruler.service.clusterIP Ruler service Cluster IP
    ## e.g.:
    ## clusterIP: None
    ##
    clusterIP: ""
    ## @param ruler.service.loadBalancerIP Ruler service Load Balancer IP
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer
    ##
    loadBalancerIP: ""
    ## @param ruler.service.loadBalancerSourceRanges Ruler service Load Balancer sources
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
    ## e.g:
    ## loadBalancerSourceRanges:
    ##   - 10.10.10.0/24
    ##
    loadBalancerSourceRanges: []
    ## @param ruler.service.externalTrafficPolicy Ruler service external traffic policy
    ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    externalTrafficPolicy: Cluster
    ## @param ruler.service.annotations Additional custom annotations for Ruler service
    ##
    annotations: {}
    ## @param ruler.service.extraPorts Extra ports to expose in the Ruler service
    ##
    extraPorts: []
  ## Network Policies
  ## Ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/
  ##
  networkPolicy:
    ## @param ruler.networkPolicy.enabled Specifies whether a NetworkPolicy should be created
    ##
    enabled: true
    ## @param ruler.networkPolicy.allowExternal Don't require server label for connections
    ## The Policy model to apply. When set to false, only pods with the correct
    ## server label will have network access to the ports server is listening
    ## on. When true, server will accept connections from any source
    ## (with the correct destination port).
    ##
    allowExternal: true
    ## @param ruler.networkPolicy.allowExternalEgress Allow the pod to access any range of port and all destinations.
    ##
    allowExternalEgress: true
    ## @param ruler.networkPolicy.extraIngress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraIngress:
    ##   - ports:
    ##       - port: 1234
    ##     from:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    extraIngress: []
    ## @param ruler.networkPolicy.extraEgress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraEgress:
    ##   - ports:
    ##       - port: 1234
    ##     to:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    ##
    extraEgress: []
    ## @param ruler.networkPolicy.ingressNSMatchLabels [object] Labels to match to allow traffic from other namespaces
    ## @param ruler.networkPolicy.ingressNSPodMatchLabels [object] Pod labels to match to allow traffic from other namespaces
    ##
    ingressNSMatchLabels: {}
    ingressNSPodMatchLabels: {}
  ## Pod Disruption Budget configuration
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb
  ## @param ruler.pdb.create Enable/disable a Pod Disruption Budget creation
  ## @param ruler.pdb.minAvailable Minimum number/percentage of pods that should remain scheduled
  ## @param ruler.pdb.maxUnavailable Maximum number/percentage of pods that may be made unavailable
  ##
  pdb:
    create: false
    minAvailable: 1
    maxUnavailable: ""
  ## BlockStorage config for ruler pods
  ## ref: https://grafana.com/docs/mimir/latest/operators-guide/configure/reference-configuration-parameters/#alertmanager_storage
  ## @param ruler.blockStorage.backend Backend storage to use. NOTE: if minio.enable == true, this configuration will be ignored.
  ## @param ruler.blockStorage.config Configures connection to the backend store. NOTE: if minio.enable == true, this configuration will be ignored.
  ## e.g.:
  ## config:
  ##   access_key_id: AKIAMYACCESSKEY123456789
  ##   secret_access_key: MYSECRETACCESSKEY
  ##   region: us-east-1
  ##   bucket_name: ruler
  ##   endpoint: s3.us-east-1.amazonaws.com
  ##   insecure: false
  ##
  blockStorage:
    backend: s3
    config: {}
## @section Init Container Parameters
##

## 'volumePermissions' init container parameters
## Changes the owner and group of the persistent volume mount point to runAsUser:fsGroup values
##   based on the *podSecurityContext/*containerSecurityContext parameters
##
volumePermissions:
  ## @param volumePermissions.enabled Enable init container that changes the owner/group of the PV mount point to `runAsUser:fsGroup`
  ##
  enabled: false
  ## OS Shell + Utility image
  ## ref: https://hub.docker.com/r/bitnami/os-shell/tags/
  ## @param volumePermissions.image.registry [default: REGISTRY_NAME] OS Shell + Utility image registry
  ## @param volumePermissions.image.repository [default: REPOSITORY_NAME/os-shell] OS Shell + Utility image repository
  ## @skip volumePermissions.image.tag OS Shell + Utility image tag (immutable tags are recommended)
  ## @param volumePermissions.image.pullPolicy OS Shell + Utility image pull policy
  ## @param volumePermissions.image.pullSecrets OS Shell + Utility image pull secrets
  ##
  image:
    registry: docker.io
    repository: bitnami/os-shell
    tag: 12-debian-12-r21
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ## e.g:
    ## pullSecrets:
    ##   - myRegistryKeySecretName
    ##
    pullSecrets: []
  ## Init container's resource requests and limits
  ## ref: http://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param volumePermissions.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if volumePermissions.resources is set (volumePermissions.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "nano"
  ## @param volumePermissions.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
  ## Init container Container Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
  ## @param volumePermissions.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in container
  ## @param volumePermissions.containerSecurityContext.runAsUser Set init container's Security Context runAsUser
  ## NOTE: when runAsUser is set to special value "auto", init container will try to chown the
  ##   data folder to auto-determined user&group, using commands: `id -u`:`id -G | cut -d" " -f2`
  ##   "auto" is especially useful for OpenShift which has scc with dynamic user ids (and 0 is not allowed)
  ##
  containerSecurityContext:
    seLinuxOptions: {}
    runAsUser: 0
## @section Other Parameters
##

## RBAC configuration
##
rbac:
  ## @param rbac.create Specifies whether RBAC resources should be created
  ##
  create: false
  ## @param rbac.rules Custom RBAC rules to set
  ## e.g:
  ## rules:
  ##   - apiGroups:
  ##       - ""
  ##     resources:
  ##       - pods
  ##     verbs:
  ##       - get
  ##       - list
  ##
  rules: []
## ServiceAccount configuration
##
serviceAccount:
  ## @param serviceAccount.create Specifies whether a ServiceAccount should be created
  ##
  create: true
  ## @param serviceAccount.name The name of the ServiceAccount to use.
  ## If not set and create is true, a name is generated using the common.names.fullname template
  ##
  name: ""
  ## @param serviceAccount.annotations Additional Service Account annotations (evaluated as a template)
  ##
  annotations: {}
  ## @param serviceAccount.automountServiceAccountToken Automount service account token for the server service account
  ##
  automountServiceAccountToken: false
## Prometheus metrics
##
metrics:
  ## @param metrics.enabled Enable the export of Prometheus metrics
  ##
  enabled: false
  ## Prometheus Operator ServiceMonitor configuration
  ##
  serviceMonitor:
    ## @param metrics.serviceMonitor.enabled if `true`, creates a Prometheus Operator ServiceMonitor (also requires `metrics.enabled` to be `true`)
    ##
    enabled: false
    ## @param metrics.serviceMonitor.namespace Namespace in which Prometheus is running
    ##
    namespace: ""
    ## @param metrics.serviceMonitor.annotations Additional custom annotations for the ServiceMonitor
    ##
    annotations: {}
    ## @param metrics.serviceMonitor.labels Extra labels for the ServiceMonitor
    ##
    labels: {}
    ## @param metrics.serviceMonitor.jobLabel The name of the label on the target service to use as the job name in Prometheus
    ##
    jobLabel: ""
    ## @param metrics.serviceMonitor.honorLabels honorLabels chooses the metric's labels on collisions with target labels
    ##
    honorLabels: false
    ## @param metrics.serviceMonitor.interval Interval at which metrics should be scraped.
    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ## e.g:
    ## interval: 10s
    ##
    interval: ""
    ## @param metrics.serviceMonitor.scrapeTimeout Timeout after which the scrape is ended
    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ## e.g:
    ## scrapeTimeout: 10s
    ##
    scrapeTimeout: ""
    ## @param metrics.serviceMonitor.metricRelabelings Specify additional relabeling of metrics
    ##
    metricRelabelings: []
    ## @param metrics.serviceMonitor.relabelings Specify general relabeling
    ##
    relabelings: []
    ## @param metrics.serviceMonitor.selector Prometheus instance selector labels
    ## ref: https://github.com/bitnami/charts/tree/main/bitnami/prometheus-operator#prometheus-configuration
    ## selector:
    ##   prometheus: my-prometheus
    ##
    selector: {}
# @section MinIO&reg; chart parameters
## @extra minio For full list of MinIO&reg; values configurations please refere [here](https://github.com/bitnami/charts/tree/main/bitnami/minio)
##
minio:
  ## @param minio.enabled Enable/disable MinIO&reg; chart installation
  ## to be used as an objstore for Mastodon
  ##
  enabled: true
  ## MinIO&reg; authentication parameters
  ##
  auth:
    ## @param minio.auth.rootUser MinIO&reg; root username
    ##
    rootUser: admin
    ## @param minio.auth.rootPassword Password for MinIO&reg; root user
    ##
    rootPassword: ""
    ## @param minio.auth.existingSecret Name of an existing secret containing the MinIO&reg; credentials
    ##
    existingSecret: ""
  ## @param minio.defaultBuckets Comma, semi-colon or space separated list of MinIO&reg; buckets to create
  ##
  defaultBuckets: "mimir, ruler, alertmanager"
  ## @param minio.provisioning.enabled Enable/disable MinIO&reg; provisioning job
  ## @param minio.provisioning.extraCommands Extra commands to run on MinIO&reg; provisioning job
  ##
  provisioning:
    enabled: true
    # We need to allow downloads in order for the UI to work
    extraCommands:
      - "mc anonymous set download provisioning/mimir"
      - "mc anonymous set download provisioning/ruler"
      - "mc anonymous set download provisioning/alertmanager"
  ## @param minio.tls.enabled Enable/disable MinIO&reg; TLS support
  ##
  tls:
    enabled: false
  ## @param minio.service.type MinIO&reg; service type
  ## @param minio.service.loadBalancerIP MinIO&reg; service LoadBalancer IP
  ## @param minio.service.ports.api MinIO&reg; service port
  ##
  service:
    type: ClusterIP
    loadBalancerIP: ""
    ports:
      api: 80
  ## MinIO&reg; containers' resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## We usually recommend not to specify default resources and to leave this as a conscious
  ## choice for the user. This also increases chances charts run on environments with little
  ## resources, such as Minikube. If you do want to specify resources, uncomment the following
  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  ## @param minio.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, small, medium, large, xlarge, 2xlarge). This is ignored if resources is set (resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "micro"
  ## @param minio.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
## @section External Memcached (Chunks) Parameters
##
externalMemcachedChunks:
  ## @param externalMemcachedChunks.host Host of a running external memcached instance
  ##
  host: ""
  ## @param externalMemcachedChunks.port Port of a running external memcached instance
  ##
  port: 11211
## @section Memcached Sub-chart Parameters (Chunks)
## Memcached sub-chart (Chunks)
##
memcachedchunks:
  ## @param memcachedchunks.enabled Deploy memcached sub-chart
  ##
  enabled: true
  ## Bitnami Memcached image version
  ## ref: https://hub.docker.com/r/bitnami/memcached/tags/
  ## @param memcachedchunks.image.registry [default: REGISTRY_NAME] Memcached image registry
  ## @param memcachedchunks.image.repository [default: REPOSITORY_NAME/memcached] Memcached image repository
  ## @skip memcachedchunks.image.tag Memcached image tag (immutable tags are recommended)
  ## @param memcachedchunks.image.digest Memcached image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag
  ##
  image:
    registry: docker.io
    repository: bitnami/memcached
    tag: 1.6.27-debian-12-r1
    digest: ""
  ## @param memcachedchunks.nameOverride override the subchart name
  ##
  nameOverride: ""
  ## @param memcachedchunks.architecture Memcached architecture
  ##
  architecture: high-availability
  ## @param memcachedchunks.service.ports.memcached Memcached service port
  ##
  service:
    ports:
      memcached: 11211
  ## Memcached resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param memcachedchunks.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, small, medium, large, xlarge, 2xlarge). This is ignored if resources is set (resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "nano"
  ## @param memcachedchunks.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
## @section External Memcached (Frontend) Parameters
##
externalMemcachedFrontend:
  ## @param externalMemcachedFrontend.host Host of a running external memcached instance
  ##
  host: ""
  ## @param externalMemcachedFrontend.port Port of a running external memcached instance
  ##
  port: 11211
## @section Memcached Sub-chart Parameters (Frontend)
## Memcached sub-chart (Frontend)
##
memcachedfrontend:
  ## @param memcachedfrontend.enabled Deploy memcached sub-chart
  ##
  enabled: true
  ## Bitnami Memcached image version
  ## ref: https://hub.docker.com/r/bitnami/memcached/tags/
  ## @param memcachedfrontend.image.registry [default: REGISTRY_NAME] Memcached image registry
  ## @param memcachedfrontend.image.repository [default: REPOSITORY_NAME/memcached] Memcached image repository
  ## @skip memcachedfrontend.image.tag Memcached image tag (immutable tags are recommended)
  ## @param memcachedfrontend.image.digest Memcached image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag
  ##
  image:
    registry: docker.io
    repository: bitnami/memcached
    tag: 1.6.27-debian-12-r1
    digest: ""
  ## @param memcachedfrontend.architecture Memcached architecture
  ##
  architecture: high-availability
  ## @param memcachedfrontend.nameOverride override the subchart name
  ##
  nameOverride: ""
  ## @param memcachedfrontend.service.ports.memcached Memcached service port
  ##
  service:
    ports:
      memcached: 11211
  ## Memcached resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param memcachedfrontend.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, small, medium, large, xlarge, 2xlarge). This is ignored if resources is set (resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "nano"
  ## @param memcachedfrontend.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
## @section External Memcached (Index) Parameters
##
externalMemcachedIndex:
  ## @param externalMemcachedIndex.host Host of a running external memcached instance
  ##
  host: ""
  ## @param externalMemcachedIndex.port Port of a running external memcached instance
  ##
  port: 11211
## @section Memcached Sub-chart Parameters (Index)
## Memcached sub-chart (Index)
##
memcachedindex:
  ## @param memcachedindex.enabled Deploy memcached sub-chart
  ##
  enabled: true
  ## Bitnami Memcached image version
  ## ref: https://hub.docker.com/r/bitnami/memcached/tags/
  ## @param memcachedindex.image.registry [default: REGISTRY_NAME] Memcached image registry
  ## @param memcachedindex.image.repository [default: REPOSITORY_NAME/memcached] Memcached image repository
  ## @skip memcachedindex.image.tag Memcached image tag (immutable tags are recommended)
  ## @param memcachedindex.image.digest Memcached image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag
  ##
  image:
    registry: docker.io
    repository: bitnami/memcached
    tag: 1.6.27-debian-12-r1
    digest: ""
  ## @param memcachedindex.architecture Memcached architecture
  ##
  architecture: high-availability
  ## @param memcachedindex.nameOverride override the subchart name
  ##
  nameOverride: ""
  ## @param memcachedindex.service.ports.memcached Memcached service port
  ##
  service:
    ports:
      memcached: 11211
  ## Memcached resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param memcachedindex.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, small, medium, large, xlarge, 2xlarge). This is ignored if resources is set (resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "nano"
  ## @param memcachedindex.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
## @section External Memcached (Metadata) Parameters
##
externalMemcachedMetadata:
  ## @param externalMemcachedMetadata.host Host of a running external memcached instance
  ##
  host: ""
  ## @param externalMemcachedMetadata.port Port of a running external memcached instance
  ##
  port: 11211
## @section Memcached Sub-chart Parameters (Metadata)
## Memcached sub-chart (Metadata)
##
memcachedmetadata:
  ## @param memcachedmetadata.enabled Deploy memcached sub-chart
  ##
  enabled: true
  ## Bitnami Memcached image version
  ## ref: https://hub.docker.com/r/bitnami/memcached/tags/
  ## @param memcachedmetadata.image.registry [default: REGISTRY_NAME] Memcached image registry
  ## @param memcachedmetadata.image.repository [default: REPOSITORY_NAME/memcached] Memcached image repository
  ## @skip memcachedmetadata.image.tag Memcached image tag (immutable tags are recommended)
  ## @param memcachedmetadata.image.digest Memcached image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag
  ##
  image:
    registry: docker.io
    repository: bitnami/memcached
    tag: 1.6.27-debian-12-r1
    digest: ""
  ## @param memcachedmetadata.architecture Memcached architecture
  ##
  architecture: high-availability
  ## @param memcachedmetadata.nameOverride override the subchart name
  ##
  nameOverride: ""
  ## @param memcachedmetadata.service.ports.memcached Memcached service port
  ##
  service:
    ports:
      memcached: 11211
  ## Memcached resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param memcachedmetadata.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, small, medium, large, xlarge, 2xlarge). This is ignored if resources is set (resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "nano"
  ## @param memcachedmetadata.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}

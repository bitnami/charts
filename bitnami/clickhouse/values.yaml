# Copyright Broadcom, Inc. All Rights Reserved.
# SPDX-License-Identifier: APACHE-2.0

## @section Global parameters
## Global Docker image parameters
## Please, note that this will override the image parameters, including dependencies, configured to use the global value
## Current available global Docker image parameters: imageRegistry, imagePullSecrets and storageClass
##

## @param global.imageRegistry Global Docker image registry
## @param global.imagePullSecrets Global Docker registry secret names as an array
## @param global.defaultStorageClass Global default StorageClass for Persistent Volume(s)
##
global:
  imageRegistry: ""
  ## E.g.
  ## imagePullSecrets:
  ##   - myRegistryKeySecretName
  ##
  imagePullSecrets: []
  defaultStorageClass: ""
  ## Security parameters
  ##
  security:
    ## @param global.security.allowInsecureImages Allows skipping image verification
    allowInsecureImages: false
  ## Compatibility adaptations for Kubernetes platforms
  ##
  compatibility:
    ## Compatibility adaptations for Openshift
    ##
    openshift:
      ## @param global.compatibility.openshift.adaptSecurityContext Adapt the securityContext sections of the deployment to make them compatible with Openshift restricted-v2 SCC: remove runAsUser, runAsGroup and fsGroup and let the platform use their allowed default IDs. Possible values: auto (apply if the detected running cluster is Openshift), force (perform the adaptation always), disabled (do not perform adaptation)
      ##
      adaptSecurityContext: auto

## @section Common parameters

## @param kubeVersion Override Kubernetes version
##
kubeVersion: ""
## @param apiVersions Override Kubernetes API versions reported by .Capabilities
##
apiVersions: []
## @param nameOverride String to partially override common.names.name
##
nameOverride: ""
## @param fullnameOverride String to fully override common.names.fullname
##
fullnameOverride: ""
## @param namespaceOverride String to fully override common.names.namespace
##
namespaceOverride: ""
## @param commonLabels Labels to add to all deployed objects
##
commonLabels: {}
## @param commonAnnotations Annotations to add to all deployed objects
##
commonAnnotations: {}
## @param clusterDomain Kubernetes cluster domain name
##
clusterDomain: cluster.local
## @param extraDeploy Array of extra objects to deploy with the release
##
extraDeploy: []
## @param usePasswordFiles Mount credentials as files instead of using environment variables
##
usePasswordFiles: true
## Enable diagnostic mode in the deployment
##
diagnosticMode:
  ## @param diagnosticMode.enabled Enable diagnostic mode (all probes will be disabled and the command will be overridden)
  ##
  enabled: false
  ## @param diagnosticMode.command Command to override all containers in the deployment
  ##
  command:
    - sleep
  ## @param diagnosticMode.args Args to override all containers in the deployment
  ##
  args:
    - infinity

## @section Default Init Container Parameters

defaultInitContainers:
  ## 'volume-permissions' init container
  ## Used to change the owner and group of the persistent volume(s) mountpoint(s) to 'runAsUser:fsGroup' on each node
  ##
  volumePermissions:
    ## @param defaultInitContainers.volumePermissions.enabled Enable init container that changes the owner and group of the persistent volume
    ##
    enabled: false
    ## @param defaultInitContainers.volumePermissions.image.registry [default: REGISTRY_NAME] "volume-permissions" init-containers' image registry
    ## @param defaultInitContainers.volumePermissions.image.repository [default: REPOSITORY_NAME/os-shell] "volume-permissions" init-containers' image repository
    ## @skip defaultInitContainers.volumePermissions.image.tag "volume-permissions" init-containers' image tag (immutable tags are recommended)
    ## @param defaultInitContainers.volumePermissions.image.digest "volume-permissions" init-containers' image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag
    ## @param defaultInitContainers.volumePermissions.image.pullPolicy "volume-permissions" init-containers' image pull policy
    ## @param defaultInitContainers.volumePermissions.image.pullSecrets "volume-permissions" init-containers' image pull secrets
    ##
    image:
      registry: docker.io
      repository: bitnami/os-shell
      tag: 12-debian-12-r43
      digest: ""
      pullPolicy: IfNotPresent
      ## Optionally specify an array of imagePullSecrets.
      ## Secrets must be manually created in the namespace.
      ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
      ## Example:
      ## pullSecrets:
      ##   - myRegistryKeySecretName
      ##
      pullSecrets: []
    ## Configure "volume-permissions" init-container Security Context
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
    ## @param defaultInitContainers.volumePermissions.containerSecurityContext.enabled Enabled "volume-permissions" init-containers' Security Context
    ## @param defaultInitContainers.volumePermissions.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in "volume-permissions" init-containers
    ## @param defaultInitContainers.volumePermissions.containerSecurityContext.runAsUser Set runAsUser in "volume-permissions" init-containers' Security Context
    ## @param defaultInitContainers.volumePermissions.containerSecurityContext.privileged Set privileged in "volume-permissions" init-containers' Security Context
    ## @param defaultInitContainers.volumePermissions.containerSecurityContext.allowPrivilegeEscalation Set allowPrivilegeEscalation in "volume-permissions" init-containers' Security Context
    ## @param defaultInitContainers.volumePermissions.containerSecurityContext.capabilities.add List of capabilities to be added in "volume-permissions" init-containers
    ## @param defaultInitContainers.volumePermissions.containerSecurityContext.capabilities.drop List of capabilities to be dropped in "volume-permissions" init-containers
    ## @param defaultInitContainers.volumePermissions.containerSecurityContext.seccompProfile.type Set seccomp profile in "volume-permissions" init-containers
    ##
    containerSecurityContext:
      enabled: true
      seLinuxOptions: {}
      runAsUser: 0
      privileged: false
      allowPrivilegeEscalation: false
      capabilities:
        add: []
        drop: ["ALL"]
      seccompProfile:
        type: "RuntimeDefault"
    ## ClickHouse Keeper "volume-permissions" init container resource requests and limits
    ## ref: http://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
    ## @param defaultInitContainers.volumePermissions.resourcesPreset Set ClickHouse Keeper "volume-permissions" init container resources according to one common preset (allowed values: none, nano, small, medium, large, xlarge, 2xlarge). This is ignored if defaultInitContainers.volumePermissions.resources is set (defaultInitContainers.volumePermissions.resources is recommended for production).
    ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
    ##
    resourcesPreset: "nano"
    ## @param defaultInitContainers.volumePermissions.resources Set ClickHouse Keeper "volume-permissions" init container requests and limits for different resources like CPU or memory (essential for production workloads)
    ## E.g:
    ## resources:
    ##   requests:
    ##     cpu: 2
    ##     memory: 512Mi
    ##   limits:
    ##     cpu: 3
    ##     memory: 1024Mi
    ##
    resources: {}

## @section ClickHouse parameters

## Bitnami ClickHouse image
## ref: https://hub.docker.com/r/bitnami/clickhouse/tags/
## @param image.registry [default: REGISTRY_NAME] ClickHouse image registry
## @param image.repository [default: REPOSITORY_NAME/clickhouse] ClickHouse image repository
## @skip image.tag ClickHouse image tag (immutable tags are recommended)
## @param image.digest ClickHouse image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag
## @param image.pullPolicy ClickHouse image pull policy
## @param image.pullSecrets ClickHouse image pull secrets
## @param image.debug Enable ClickHouse image debug mode
##
image:
  registry: docker.io
  repository: bitnami/clickhouse
  tag: 25.4.2-debian-12-r0
  digest: ""
  ## Specify a imagePullPolicy
  ## ref: http://kubernetes.io/docs/concepts/containers/images/#pre-pulled-images
  ##
  pullPolicy: IfNotPresent
  ## Optionally specify an array of imagePullSecrets.
  ## Secrets must be manually created in the namespace.
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  ## e.g:
  ## pullSecrets:
  ##   - myRegistryKeySecretName
  ##
  pullSecrets: []
  ## Enable debug mode
  ##
  debug: false
## @param clusterName ClickHouse cluster name
##
clusterName: default
## Authentication
## @param auth.username ClickHouse Admin username
## @param auth.password ClickHouse Admin password
## @param auth.existingSecret Name of a secret containing the Admin password
## @param auth.existingSecretKey Name of the key inside the existing secret
##
auth:
  username: default
  password: ""
  existingSecret: ""
  existingSecretKey: ""
## @param tls.enabled Enable TLS configuration for ClickHouse
## @param tls.autoGenerated.enabled Enable automatic generation of TLS certificates
## @param tls.autoGenerated.engine Mechanism to generate the certificates (allowed values: helm, cert-manager)
## @param tls.autoGenerated.certManager.existingIssuer The name of an existing Issuer to use for generating the certificates (only for `cert-manager` engine)
## @param tls.autoGenerated.certManager.existingIssuerKind Existing Issuer kind, defaults to Issuer (only for `cert-manager` engine)
## @param tls.autoGenerated.certManager.keyAlgorithm Key algorithm for the certificates (only for `cert-manager` engine)
## @param tls.autoGenerated.certManager.keySize Key size for the certificates (only for `cert-manager` engine)
## @param tls.autoGenerated.certManager.duration Duration for the certificates (only for `cert-manager` engine)
## @param tls.autoGenerated.certManager.renewBefore Renewal period for the certificates (only for `cert-manager` engine)
## @param tls.ca CA certificate for TLS. Ignored if `tls.existingCASecret` is set
## @param tls.existingCASecret The name of an existing Secret containing the CA certificate for TLS
## @param tls.server.cert TLS certificate for ClickHouse servers. Ignored if `tls.server.existingSecret` is set
## @param tls.server.key TLS key for ClickHouse servers. Ignored if `tls.server.existingSecret` is set
## @param tls.server.existingSecret The name of an existing Secret containing the TLS certificates for ClickHouse servers
## @param tls.keeper.cert TLS certificate for ClickHouse Keeper. Ignored if `tls.keeper.existingSecret` is set
## @param tls.keeper.key TLS key for ClickHouse Keeper. Ignored if `tls.keeper.existingSecret` is set
## @param tls.keeper.existingSecret The name of an existing Secret containing the TLS certificates for ClickHouse Keeper
##
tls:
  enabled: false
  autoGenerated:
    enabled: true
    engine: helm
    certManager:
      existingIssuer: ""
      existingIssuerKind: ""
      keySize: 2048
      keyAlgorithm: RSA
      duration: 2160h
      renewBefore: 360h
  ca: ""
  existingCASecret: ""
  server:
    cert: ""
    key: ""
    existingSecret: ""
  keeper:
    cert: ""
    key: ""
    existingSecret: ""
## @param logLevel Logging level
##
logLevel: information
## @param sampling.enabled Enable logging tables collected by sampling query profiler
##
sampling:
  enabled: false
## @param configuration Specify content for ClickHouse configuration (basic one auto-generated based on other values otherwise)
##
configuration: {}
## @param existingConfigmap The name of an existing ConfigMap with your custom configuration for ClickHouse
##
existingConfigmap: ""
## @param configdFiles Extra configuration files to be mounted at config.d
## ref: https://clickhouse.com/docs/operations/configuration-files
##
configdFiles: {}
## @param existingConfigdConfigmap The name of an existing ConfigMap with extra configuration files for ClickHouse
##
existingConfigdConfigmap: ""
## @param usersdFiles Extra users configuration files to be mounted at users.d
## ref: https://clickhouse.com/docs/operations/configuration-files#user-settings
##
usersdFiles: {}
## @param existingUsersdConfigmap The name of an existing ConfigMap with extra users configuration files for ClickHouse
##
existingUsersdConfigmap: ""
## @param existingUsersdSecret The name of an existing Secret with extra users configuration files for ClickHouse
##
existingUsersdSecret: ""
## @param initdbScripts Dictionary of initdb scripts
## Specify dictionary of scripts to be run at first boot
## Example:
## initdbScripts:
##   my_init_script.sh: |
##      #!/bin/bash
##      echo "Do something."
##
initdbScripts: {}
## @param initdbScriptsSecret ConfigMap with the initdb scripts (Note: Overrides `initdbScripts`)
##
initdbScriptsSecret: ""
## @param startdbScripts Dictionary of startdb scripts
## Specify dictionary of scripts to be run on every start
## Example:
## startdbScripts:
##   my_start_script.sh: |
##      #!/bin/bash
##      echo "Do something."
##
startdbScripts: {}
## @param startdbScriptsSecret ConfigMap with the startdb scripts (Note: Overrides `startdbScripts`)
##
startdbScriptsSecret: ""
## @param shards Number of ClickHouse shards to deploy
##
shards: 2
## @param replicaCount Number of ClickHouse replicas per shard to deploy
## if keeper enable, same as keeper count, keeper cluster by shards.
##
replicaCount: 3
## @param distributeReplicasByZone Schedules replicas of the same shard to different availability zones
##
distributeReplicasByZone: false
## @param containerPorts.http ClickHouse HTTP container port
## @param containerPorts.https ClickHouse HTTPS container port
## @param containerPorts.tcp ClickHouse TCP container port
## @param containerPorts.tcpSecure ClickHouse TCP (secure) container port
## @param containerPorts.mysql ClickHouse MySQL container port
## @param containerPorts.postgresql ClickHouse PostgreSQL container port
## @param containerPorts.interserver ClickHouse Interserver container port
## @param containerPorts.metrics ClickHouse metrics container port
##
containerPorts:
  http: 8123
  https: 8443
  tcp: 9000
  tcpSecure: 9440
  mysql: 9004
  postgresql: 9005
  interserver: 9009
  metrics: 8001
## Configure extra options for ClickHouse containers' liveness and readiness probes
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
## @param livenessProbe.enabled Enable livenessProbe on ClickHouse containers
## @param livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
## @param livenessProbe.periodSeconds Period seconds for livenessProbe
## @param livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
## @param livenessProbe.failureThreshold Failure threshold for livenessProbe
## @param livenessProbe.successThreshold Success threshold for livenessProbe
##
livenessProbe:
  enabled: true
  failureThreshold: 3
  initialDelaySeconds: 10
  periodSeconds: 10
  successThreshold: 1
  timeoutSeconds: 1
## @param readinessProbe.enabled Enable readinessProbe on ClickHouse containers
## @param readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
## @param readinessProbe.periodSeconds Period seconds for readinessProbe
## @param readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
## @param readinessProbe.failureThreshold Failure threshold for readinessProbe
## @param readinessProbe.successThreshold Success threshold for readinessProbe
##
readinessProbe:
  enabled: true
  failureThreshold: 3
  initialDelaySeconds: 10
  periodSeconds: 10
  successThreshold: 1
  timeoutSeconds: 1
## @param startupProbe.enabled Enable startupProbe on ClickHouse containers
## @param startupProbe.initialDelaySeconds Initial delay seconds for startupProbe
## @param startupProbe.periodSeconds Period seconds for startupProbe
## @param startupProbe.timeoutSeconds Timeout seconds for startupProbe
## @param startupProbe.failureThreshold Failure threshold for startupProbe
## @param startupProbe.successThreshold Success threshold for startupProbe
##
startupProbe:
  enabled: false
  failureThreshold: 3
  initialDelaySeconds: 10
  periodSeconds: 10
  successThreshold: 1
  timeoutSeconds: 1
## @param customLivenessProbe Custom livenessProbe that overrides the default one
##
customLivenessProbe: {}
## @param customReadinessProbe Custom readinessProbe that overrides the default one
##
customReadinessProbe: {}
## @param customStartupProbe Custom startupProbe that overrides the default one
##
customStartupProbe: {}
## ClickHouse resource requests and limits
## ref: http://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
## @param resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if resources is set (resources is recommended for production).
## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
##
resourcesPreset: "small"
## @param resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
## Example:
## resources:
##   requests:
##     cpu: 2
##     memory: 512Mi
##   limits:
##     cpu: 3
##     memory: 1024Mi
##
resources: {}
## Configure Pods Security Context
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
## @param podSecurityContext.enabled Enabled ClickHouse pods' Security Context
## @param podSecurityContext.fsGroupChangePolicy Set filesystem group change policy
## @param podSecurityContext.sysctls Set kernel settings using the sysctl interface
## @param podSecurityContext.supplementalGroups Set filesystem extra groups
## @param podSecurityContext.fsGroup Set ClickHouse pod's Security Context fsGroup
## If you are using Kubernetes 1.18, the following code needs to be commented out.
##
podSecurityContext:
  enabled: true
  fsGroupChangePolicy: Always
  sysctls: []
  supplementalGroups: []
  fsGroup: 1001
## Configure Container Security Context
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
## @param containerSecurityContext.enabled Enable containers' Security Context
## @param containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in container
## @param containerSecurityContext.runAsUser Set containers' Security Context runAsUser
## @param containerSecurityContext.runAsGroup Set containers' Security Context runAsGroup
## @param containerSecurityContext.runAsNonRoot Set containers' Security Context runAsNonRoot
## @param containerSecurityContext.readOnlyRootFilesystem Set read only root file system pod's
## @param containerSecurityContext.privileged Set ClickHouse container's Security Context privileged
## @param containerSecurityContext.allowPrivilegeEscalation Set ClickHouse container's Security Context allowPrivilegeEscalation
## @param containerSecurityContext.capabilities.drop List of capabilities to be dropped
## @param containerSecurityContext.seccompProfile.type Set container's Security Context seccomp profile
##
containerSecurityContext:
  enabled: true
  seLinuxOptions: {}
  runAsUser: 1001
  runAsGroup: 1001
  runAsNonRoot: true
  privileged: false
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  capabilities:
    drop: ["ALL"]
  seccompProfile:
    type: "RuntimeDefault"
## @param command Override default container command (useful when using custom images)
##
command: []
## @param args Override default container args (useful when using custom images)
##
args: []
## @param automountServiceAccountToken Mount Service Account token in pod
##
automountServiceAccountToken: false
## @param hostAliases ClickHouse pods host aliases
## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
##
hostAliases: []
## @param podLabels Extra labels for ClickHouse pods
## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
##
podLabels: {}
## @param podAnnotations Annotations for ClickHouse pods
## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
##
podAnnotations: {}
## @param podAffinityPreset Pod affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
##
podAffinityPreset: ""
## @param podAntiAffinityPreset Pod anti-affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
##
podAntiAffinityPreset: soft
## Node affinity preset
## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
##
nodeAffinityPreset:
  ## @param nodeAffinityPreset.type Node affinity preset type. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
  ##
  type: ""
  ## @param nodeAffinityPreset.key Node label key to match. Ignored if `affinity` is set
  ##
  key: ""
  ## @param nodeAffinityPreset.values Node label values to match. Ignored if `affinity` is set
  ## E.g.
  ## values:
  ##   - e2e-az1
  ##   - e2e-az2
  ##
  values: []
## @param affinity Affinity for ClickHouse pods assignment
## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
## NOTE: `podAffinityPreset`, `podAntiAffinityPreset`, and `nodeAffinityPreset` will be ignored when it's set
##
affinity: {}
## @param nodeSelector Node labels for ClickHouse pods assignment
## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/
##
nodeSelector: {}
## @param tolerations Tolerations for ClickHouse pods assignment
## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
##
tolerations: []
## @param updateStrategy.type ClickHouse StatefulSet strategy type
## @param updateStrategy.rollingUpdate ClickHouse StatefulSet rolling update configuration parameters
## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
##
updateStrategy:
  type: RollingUpdate
  rollingUpdate: {}
## @param podManagementPolicy Statefulset Pod management policy, it needs to be Parallel to be able to complete the cluster join
## Ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
##
podManagementPolicy: Parallel
## @param priorityClassName ClickHouse pods' priorityClassName
##
priorityClassName: ""
## @param topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains. Evaluated as a template
## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
##
topologySpreadConstraints: []
## @param schedulerName Name of the k8s scheduler (other than default) for ClickHouse pods
## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
##
schedulerName: ""
## @param terminationGracePeriodSeconds Seconds Redmine pod needs to terminate gracefully
## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods
##
terminationGracePeriodSeconds: ""
## @param lifecycleHooks for the ClickHouse container(s) to automate configuration before or after startup
##
lifecycleHooks: {}
## @param extraEnvVars Array with extra environment variables to add to ClickHouse nodes
## e.g:
## extraEnvVars:
##   - name: FOO
##     value: "bar"
##
extraEnvVars: []
## @param extraEnvVarsCM Name of existing ConfigMap containing extra env vars for ClickHouse nodes
##
extraEnvVarsCM: ""
## @param extraEnvVarsSecret Name of existing Secret containing extra env vars for ClickHouse nodes
##
extraEnvVarsSecret: ""
## @param extraVolumes Optionally specify extra list of additional volumes for the ClickHouse pod(s)
##
extraVolumes: []
## @param extraVolumeMounts Optionally specify extra list of additional volumeMounts for the ClickHouse container(s)
##
extraVolumeMounts: []
## @param extraVolumeClaimTemplates Optionally specify extra list of additional volumeClaimTemplates for the ClickHouse container(s)
##
extraVolumeClaimTemplates: []
## @param sidecars Add additional sidecar containers to the ClickHouse pod(s)
## e.g:
## sidecars:
##   - name: your-image-name
##     image: your-image
##     imagePullPolicy: Always
##     ports:
##       - name: portname
##         containerPort: 1234
##
sidecars: []
## @param initContainers Add additional init containers to the ClickHouse pod(s)
## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
## e.g:
## initContainers:
##  - name: your-image-name
##    image: your-image
##    imagePullPolicy: Always
##    command: ['sh', '-c', 'echo "hello world"']
##
initContainers: []
## Pod Disruption Budget configuration
## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb
## @param pdb.create Enable/disable a Pod Disruption Budget creation
## @param pdb.minAvailable Minimum number/percentage of pods that should remain scheduled
## @param pdb.maxUnavailable Maximum number/percentage of pods that may be made unavailable. Defaults to `1` if both `pdb.minAvailable` and `pdb.maxUnavailable` are empty.
##
pdb:
  create: true
  minAvailable: ""
  maxUnavailable: ""    
## ClickHouse Autoscaling configuration
## ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
##
autoscaling:
  vpa:
    ## @param autoscaling.vpa.enabled Enable VPA
    ##
    enabled: false
    ## @param autoscaling.vpa.annotations Annotations for VPA resource
    ##
    annotations: {}
    ## @param autoscaling.vpa.controlledResources VPA List of resources that the vertical pod autoscaler can control. Defaults to cpu and memory
    ##
    controlledResources: []
    ## @param autoscaling.vpa.maxAllowed VPA Max allowed resources for the pod
    ## cpu: 200m
    ## memory: 100Mi
    maxAllowed: {}
    ## @param autoscaling.vpa.minAllowed VPA Min allowed resources for the pod
    ## cpu: 200m
    ## memory: 100Mi
    minAllowed: {}
    updatePolicy:
      ## @param autoscaling.vpa.updatePolicy.updateMode Autoscaling update policy Specifies whether recommended updates are applied when a Pod is started and whether recommended updates are applied during the life of a Pod
      ## Possible values are "Off", "Initial", "Recreate", and "Auto".
      ##
      updateMode: Auto

## @section ClickHouse Traffic Exposure parameters

## ClickHouse service parameters
##
service:
  ## @param service.type ClickHouse service type
  ##
  type: ClusterIP
  ## @param service.perReplicaAccess Enable per-replica service creation
  ## This is useful for exposing individual replicas externally via LoadBalancer or NodePort
  ##
  perReplicaAccess: false
  ## @param service.ports.http ClickHouse service HTTP port
  ## @param service.ports.https ClickHouse service HTTPS port
  ## @param service.ports.tcp ClickHouse service TCP port
  ## @param service.ports.tcpSecure ClickHouse service TCP (secure) port
  ## @param service.ports.mysql ClickHouse service MySQL port
  ## @param service.ports.postgresql ClickHouse service PostgreSQL port
  ## @param service.ports.interserver ClickHouse service Interserver port
  ## @param service.ports.metrics ClickHouse service metrics port
  ##
  ports:
    http: 8123
    https: 443
    tcp: 9000
    tcpSecure: 9440
    mysql: 9004
    postgresql: 9005
    interserver: 9009
    metrics: 8001
  ## Node ports to expose
  ## @param service.nodePorts.http Node port for HTTP
  ## @param service.nodePorts.https Node port for HTTPS
  ## @param service.nodePorts.tcp Node port for TCP
  ## @param service.nodePorts.tcpSecure Node port for TCP (with TLS)
  ## @param service.nodePorts.mysql Node port for MySQL
  ## @param service.nodePorts.postgresql Node port for PostgreSQL
  ## @param service.nodePorts.interserver Node port for Interserver
  ## @param service.nodePorts.metrics Node port for metrics
  ## NOTE: choose port between <30000-32767>
  ##
  nodePorts:
    http: ""
    https: ""
    tcp: ""
    tcpSecure: ""
    mysql: ""
    postgresql: ""
    interserver: ""
    metrics: ""
  ## @param service.clusterIP ClickHouse service Cluster IP
  ## e.g.:
  ## clusterIP: None
  ##
  clusterIP: ""
  ## @param service.loadBalancerIP ClickHouse service Load Balancer IP (only if per-replica access is disabled)
  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer
  ##
  loadBalancerIP: ""
  ## @param service.loadBalancerIPs Array of ClickHouse service Load Balancer IPs (only if per-replica access is enabled). Length must be the same as shards multiplied by replicaCount
  ## e.g:
  ## loadBalancerIPs:
  ##   - X.X.X.X
  ##   - Y.Y.Y.Y
  ##
  loadBalancerIPs: []
  ## @param service.loadBalancerAnnotations Array of ClickHouse service Load Balancer annotations (only if per-replica access is enabled). Length must be the same as shards multiplied by replicaCount
  ## e.g:
  ## loadBalancerAnnotations:
  ##   - external-dns.alpha.kubernetes.io/hostname: 1.external.example.com.
  ##   - external-dns.alpha.kubernetes.io/hostname: 2.external.example.com.
  ##
  loadBalancerAnnotations: []
  ## @param service.loadBalancerSourceRanges ClickHouse service Load Balancer sources
  ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
  ## e.g:
  ## loadBalancerSourceRanges:
  ##   - 10.10.10.0/24
  ##
  loadBalancerSourceRanges: []
  ## @param service.externalTrafficPolicy ClickHouse service external traffic policy
  ## ref http://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
  ##
  externalTrafficPolicy: Cluster
  ## @param service.annotations Additional custom annotations for ClickHouse service
  ##
  annotations: {}
  ## @param service.extraPorts Extra ports to expose in ClickHouse service (normally used with the `sidecars` value)
  ##
  extraPorts: []
  ## @param service.sessionAffinity Control where client requests go, to the same pod or round-robin
  ## Values: ClientIP or None
  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/
  ##
  sessionAffinity: None
  ## @param service.sessionAffinityConfig Additional settings for the sessionAffinity
  ## sessionAffinityConfig:
  ##   clientIP:
  ##     timeoutSeconds: 300
  ##
  sessionAffinityConfig: {}
  ## Headless service properties
  ##
  headless:
    ## @param service.headless.annotations Annotations for the headless service.
    ##
    annotations: {}
    ## @param service.headless.extraPorts Optionally specify extra ports to expose for the headless service.
    ##
    extraPorts: []
## ClickHouse Ingress parameters
## ref: http://kubernetes.io/docs/concepts/services-networking/ingress/
##
ingress:
  ## @param ingress.enabled Enable ingress record generation for ClickHouse
  ##
  enabled: false
  ## @param ingress.pathType Ingress path type
  ##
  pathType: ImplementationSpecific
  ## @param ingress.apiVersion Force Ingress API version (automatically detected if not set)
  ##
  apiVersion: ""
  ## @param ingress.hostname Default host for the ingress record
  ##
  hostname: clickhouse.local
  ## @param ingress.ingressClassName IngressClass that will be be used to implement the Ingress (Kubernetes 1.18+)
  ## This is supported in Kubernetes 1.18+ and required if you have more than one IngressClass marked as the default for your cluster .
  ## ref: https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/
  ##
  ingressClassName: ""
  ## @param ingress.path Default path for the ingress record
  ## NOTE: You may need to set this to '/*' in order to use this with ALB ingress controllers
  ##
  path: /
  ## @param ingress.annotations Additional annotations for the Ingress resource. To enable certificate autogeneration, place here your cert-manager annotations.
  ## Use this parameter to set the required annotations for cert-manager, see
  ## ref: https://cert-manager.io/docs/usage/ingress/#supported-annotations
  ## e.g:
  ## annotations:
  ##   kubernetes.io/ingress.class: nginx
  ##   cert-manager.io/cluster-issuer: cluster-issuer-name
  ##
  annotations: {}
  ## @param ingress.tls Enable TLS configuration for the host defined at `ingress.hostname` parameter
  ## TLS certificates will be retrieved from a TLS secret with name: `{{- printf "%s-tls" .Values.ingress.hostname }}`
  ## You can:
  ##   - Use the `ingress.secrets` parameter to create this TLS secret
  ##   - Rely on cert-manager to create it by setting the corresponding annotations
  ##   - Rely on Helm to create self-signed certificates by setting `ingress.selfSigned=true`
  ##
  tls: false
  ## @param ingress.selfSigned Create a TLS secret for this ingress record using self-signed certificates generated by Helm
  ##
  selfSigned: false
  ## @param ingress.extraHosts An array with additional hostname(s) to be covered with the ingress record
  ## e.g:
  ## extraHosts:
  ##   - name: clickhouse.local
  ##     path: /
  ##
  extraHosts: []
  ## @param ingress.extraPaths An array with additional arbitrary paths that may need to be added to the ingress under the main host
  ## e.g:
  ## extraPaths:
  ## - path: /*
  ##   backend:
  ##     serviceName: ssl-redirect
  ##     servicePort: use-annotation
  ##
  extraPaths: []
  ## @param ingress.extraTls TLS configuration for additional hostname(s) to be covered with this ingress record
  ## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/#tls
  ## e.g:
  ## extraTls:
  ## - hosts:
  ##     - clickhouse.local
  ##   secretName: clickhouse.local-tls
  ##
  extraTls: []
  ## @param ingress.secrets Custom TLS certificates as secrets
  ## NOTE: 'key' and 'certificate' are expected in PEM format
  ## NOTE: 'name' should line up with a 'secretName' set further up
  ## If it is not set and you're using cert-manager, this is unneeded, as it will create a secret for you with valid certificates
  ## If it is not set and you're NOT using cert-manager either, self-signed certificates will be created valid for 365 days
  ## It is also possible to create and manage the certificates outside of this helm chart
  ## Please see README.md for more information
  ## e.g:
  ## secrets:
  ##   - name: clickhouse.local-tls
  ##     key: |-
  ##       -----BEGIN RSA PRIVATE KEY-----
  ##       ...
  ##       -----END RSA PRIVATE KEY-----
  ##     certificate: |-
  ##       -----BEGIN CERTIFICATE-----
  ##       ...
  ##       -----END CERTIFICATE-----
  ##
  secrets: []
  ## @param ingress.extraRules Additional rules to be covered with this ingress record
  ## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-rules
  ## e.g:
  ## extraRules:
  ## - host: example.local
  ##     http:
  ##       path: /
  ##       backend:
  ##         service:
  ##           name: example-svc
  ##           port:
  ##             name: http
  ##
  extraRules: []
## ClickHouse Network Policies
## Ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/
##
networkPolicy:
  ## @param networkPolicy.enabled Specifies whether a NetworkPolicy should be created
  ##
  enabled: true
  ## @param networkPolicy.allowExternal Don't require client label for connections
  ## The Policy model to apply. When set to false, only pods with the correct
  ## client label will have network access to the ports ClickHouse is listening
  ## on. When true, ClickHouse will accept connections from any source
  ## (with the correct destination port).
  ##
  allowExternal: true
  ## @param networkPolicy.allowExternalEgress Allow the pod to access any range of port and all destinations.
  ##
  allowExternalEgress: true
  ## @param networkPolicy.addExternalClientAccess Allow access from pods with client label set to "true". Ignored if `networkPolicy.allowExternal` is true.
  ##
  addExternalClientAccess: true
  ## @param networkPolicy.extraIngress [array] Add extra ingress rules to the NetworkPolicy
  ## e.g:
  ## extraIngress:
  ##   - ports:
  ##       - port: 1234
  ##     from:
  ##       - podSelector:
  ##           - matchLabels:
  ##               - role: frontend
  ##       - podSelector:
  ##           - matchExpressions:
  ##               - key: role
  ##                 operator: In
  ##                 values:
  ##                   - frontend
  extraIngress: []
  ## @param networkPolicy.extraEgress [array] Add extra ingress rules to the NetworkPolicy
  ## e.g:
  ## extraEgress:
  ##   - ports:
  ##       - port: 1234
  ##     to:
  ##       - podSelector:
  ##           - matchLabels:
  ##               - role: frontend
  ##       - podSelector:
  ##           - matchExpressions:
  ##               - key: role
  ##                 operator: In
  ##                 values:
  ##                   - frontend
  ##
  extraEgress: []
  ## @param networkPolicy.ingressNSMatchLabels [object] Labels to match to allow traffic from other namespaces
  ## @param networkPolicy.ingressNSPodMatchLabels [object] Pod labels to match to allow traffic from other namespaces
  ##
  ingressNSMatchLabels: {}
  ingressNSPodMatchLabels: {}

## @section ClickHouse Persistence parameters

## persistentVolumeClaimRetentionPolicy
## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#persistentvolumeclaim-retention
## @param persistentVolumeClaimRetentionPolicy.enabled Controls if and how PVCs are deleted during the lifecycle of a StatefulSet
## @param persistentVolumeClaimRetentionPolicy.whenScaled Volume retention behavior when the replica count of the StatefulSet is reduced
## @param persistentVolumeClaimRetentionPolicy.whenDeleted Volume retention behavior that applies when the StatefulSet is deleted
##
persistentVolumeClaimRetentionPolicy:
  enabled: false
  whenScaled: Retain
  whenDeleted: Retain
## Enable persistence using Persistent Volume Claims
## ref: https://kubernetes.io/docs/concepts/storage/persistent-volumes/
##
persistence:
  ## @param persistence.enabled Enable persistence using Persistent Volume Claims
  ##
  enabled: true
  ## @param persistence.existingClaim Name of an existing PVC to use
  ##
  existingClaim: ""
  ## @param persistence.storageClass Storage class of backing PVC
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  storageClass: ""
  ## @param persistence.labels Persistent Volume Claim labels
  ##
  labels: {}
  ## @param persistence.annotations Persistent Volume Claim annotations
  ##
  annotations: {}
  ## @param persistence.accessModes Persistent Volume Access Modes
  ##
  accessModes:
    - ReadWriteOnce
  ## @param persistence.size Size of data volume
  ##
  size: 8Gi
  ## @param persistence.selector Selector to match an existing Persistent Volume for ClickHouse data PVC
  ## If set, the PVC can't have a PV dynamically provisioned for it
  ## E.g.
  ## selector:
  ##   matchLabels:
  ##     app: my-app
  ##
  selector: {}
  ## @param persistence.dataSource Custom PVC data source
  ##
  dataSource: {}
  ## @param persistence.mountPath Mount path of the ClickHouse data volume
  ##
  mountPath: /bitnami/clickhouse

## @section ClickHouse Keeper parameters

keeper:
  ## @param keeper.enabled Deploy ClickHouse Keeper to provide coordination capabilities
  ##
  enabled: true
  ## Bitnami ClickHouse Keeper image
  ## ref: https://hub.docker.com/r/bitnami/clickhouse-keeper/tags/
  ## @param keeper.image.registry [default: REGISTRY_NAME] ClickHouse Keeper image registry
  ## @param keeper.image.repository [default: REPOSITORY_NAME/clickhouse-keeper] ClickHouse Keeper image repository
  ## @skip keeper.image.tag ClickHouse Keeper image tag (immutable tags are recommended)
  ## @param keeper.image.digest ClickHouse Keeper image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag image tag (immutable tags are recommended)
  ## @param keeper.image.pullPolicy ClickHouse Keeper image pull policy
  ## @param keeper.image.pullSecrets ClickHouse Keeper image pull secrets
  ## @param keeper.image.debug Enable ClickHouse image debug mode
  ##
  image:
    registry: docker.io
    repository: bitnami/clickhouse-keeper
    tag: 25.4.2-debian-12-r0
    digest: ""
    ## Specify a imagePullPolicy
    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
    ## ref: https://kubernetes.io/docs/concepts/containers/images/#pre-pulled-images
    ##
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ## e.g:
    ## pullSecrets:
    ##   - myRegistryKeySecretName
    ##
    pullSecrets: []
    ## Set to true if you would like to see extra information on logs
    ##
    debug: false
  ## @param keeper.replicaCount Number of ClickHouse Keeper replicas to deploy
  ##
  replicaCount: 3
  ## @param keeper.configuration Specify content for ClickHouse Keeper configuration (basic one auto-generated based on other values otherwise)
  ##
  configuration: {}
  ## @param keeper.existingConfigmap The name of an existing ConfigMap with your custom configuration for ClickHouse Keeper
  ##
  existingConfigmap: ""
  ## @param keeper.configdFiles Extra configuration files to be mounted at keeper_config.d
  ## ref: https://clickhouse.com/docs/operations/configuration-files
  ##
  configdFiles: {}
  ## @param keeper.existingConfigdConfigmap The name of an existing ConfigMap with extra configuration files for ClickHouse Keeper
  ##
  existingConfigdConfigmap: ""
  ## @param keeper.usersdFiles Extra users configuration files to be mounted at users.d
  ## ref: https://clickhouse.com/docs/operations/configuration-files#user-settings
  ##
  usersdFiles: {}
  ## @param keeper.existingUsersdConfigmap The name of an existing ConfigMap with extra users configuration files for ClickHouse Keeper
  ##
  existingUsersdConfigmap: ""
  ## @param keeper.existingUsersdSecret The name of an existing Secret with extra users configuration files for ClickHouse Keeper
  ##
  existingUsersdSecret: ""
  ## @param keeper.containerPorts.tcp ClickHouse Keeper TCP container port
  ## @param keeper.containerPorts.tcpSecure ClickHouse TCP (secure) container port
  ## @param keeper.containerPorts.raft ClickHouse Keeper Raft container port
  ##
  containerPorts:
    tcp: 9181
    tcpSecure: 9281
    raft: 9234
  ## @param keeper.extraContainerPorts ClickHouse Keeper extra containerPorts
  ##
  extraContainerPorts: []
  ## Configure extra options for ClickHouse Keeper containers' liveness and readiness probes
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
  ## @param keeper.livenessProbe.enabled Enable livenessProbe on ClickHouse Keeper containers
  ## @param keeper.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
  ## @param keeper.livenessProbe.periodSeconds Period seconds for livenessProbe
  ## @param keeper.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
  ## @param keeper.livenessProbe.failureThreshold Failure threshold for livenessProbe
  ## @param keeper.livenessProbe.successThreshold Success threshold for livenessProbe
  ##
  livenessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 10
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param keeper.readinessProbe.enabled Enable readinessProbe on ClickHouse Keeper containers
  ## @param keeper.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
  ## @param keeper.readinessProbe.periodSeconds Period seconds for readinessProbe
  ## @param keeper.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
  ## @param keeper.readinessProbe.failureThreshold Failure threshold for readinessProbe
  ## @param keeper.readinessProbe.successThreshold Success threshold for readinessProbe
  ##
  readinessProbe:
    enabled: true
    failureThreshold: 3
    initialDelaySeconds: 10
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param keeper.startupProbe.enabled Enable startupProbe on ClickHouse Keeper containers
  ## @param keeper.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe
  ## @param keeper.startupProbe.periodSeconds Period seconds for startupProbe
  ## @param keeper.startupProbe.timeoutSeconds Timeout seconds for startupProbe
  ## @param keeper.startupProbe.failureThreshold Failure threshold for startupProbe
  ## @param keeper.startupProbe.successThreshold Success threshold for startupProbe
  ##
  startupProbe:
    enabled: false
    failureThreshold: 3
    initialDelaySeconds: 10
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 1
  ## @param keeper.customLivenessProbe Custom livenessProbe that overrides the default one
  ##
  customLivenessProbe: {}
  ## @param keeper.customReadinessProbe Custom readinessProbe that overrides the default one
  ##
  customReadinessProbe: {}
  ## @param keeper.customStartupProbe Custom startupProbe that overrides the default one
  ##
  customStartupProbe: {}
  ## ClickHouse Keeper resource requests and limits
  ## ref: http://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param keeper.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if keeper.resources is set (keeper.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "small"
  ## @param keeper.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
  ## Configure ClickHouse Keeper pods Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param keeper.podSecurityContext.enabled Enabled ClickHouse Keeper pods' Security Context
  ## @param keeper.podSecurityContext.fsGroupChangePolicy Set filesystem group change policy
  ## @param keeper.podSecurityContext.sysctls Set kernel settings using the sysctl interface
  ## @param keeper.podSecurityContext.supplementalGroups Set filesystem extra groups
  ## @param keeper.podSecurityContext.fsGroup Set ClickHouse Keeper pod's Security Context fsGroup
  ##
  podSecurityContext:
    enabled: true
    fsGroupChangePolicy: Always
    sysctls: []
    supplementalGroups: []
    fsGroup: 1001
  ## Configure ClickHouse Keeper containers (only main one) Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
  ## @param keeper.containerSecurityContext.enabled Enabled ClickHouse Keeper containers' Security Context
  ## @param keeper.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in container
  ## @param keeper.containerSecurityContext.runAsUser Set ClickHouse Keeper containers' Security Context runAsUser
  ## @param keeper.containerSecurityContext.runAsGroup Set ClickHouse Keeper containers' Security Context runAsGroup
  ## @param keeper.containerSecurityContext.runAsNonRoot Set ClickHouse Keeper containers' Security Context runAsNonRoot
  ## @param keeper.containerSecurityContext.privileged Set web container's Security Context privileged
  ## @param keeper.containerSecurityContext.allowPrivilegeEscalation Set web container's Security Context allowPrivilegeEscalation
  ## @param keeper.containerSecurityContext.readOnlyRootFilesystem Set web container's Security Context readOnlyRootFilesystem
  ## @param keeper.containerSecurityContext.capabilities.drop List of capabilities to be dropped
  ## @param keeper.containerSecurityContext.seccompProfile.type Set container's Security Context seccomp profile
  ##
  containerSecurityContext:
    enabled: true
    seLinuxOptions: {}
    runAsUser: 1001
    runAsGroup: 1001
    runAsNonRoot: true
    privileged: false
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    capabilities:
      drop: ["ALL"]
    seccompProfile:
      type: "RuntimeDefault"
  ## @param keeper.command Override default container command (useful when using custom images)
  ##
  command: []
  ## @param keeper.args Override default container args (useful when using custom images)
  ##
  args: []
  ## @param keeper.extraEnvVars Array with extra environment variables to add to ClickHouse Keeper container(s)
  ## e.g:
  ## extraEnvVars:
  ##   - name: FOO
  ##     value: "bar"
  ##
  extraEnvVars: []
  ## @param keeper.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for ClickHouse Keeper container(s)
  ##
  extraEnvVarsCM: ""
  ## @param keeper.extraEnvVarsSecret Name of existing Secret containing extra env vars for ClickHouse Keeper container(s)
  ##
  extraEnvVarsSecret: ""
  ## @param keeper.automountServiceAccountToken Mount Service Account token in pod
  ##
  automountServiceAccountToken: false
  ## @param keeper.hostAliases ClickHouse Keeper pods host aliases
  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
  ##
  hostAliases: []
  ## @param keeper.podLabels Extra labels for ClickHouse Keeper pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  ##
  podLabels: {}
  ## @param keeper.podAnnotations Annotations for ClickHouse Keeper pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  ##
  podAnnotations: {}
  ## @param keeper.podAffinityPreset Pod affinity preset. Ignored if `keeper.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAffinityPreset: ""
  ## @param keeper.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `keeper.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAntiAffinityPreset: soft
  ## Node affinity preset
  ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ## @param keeper.nodeAffinityPreset.key Node label key to match. Ignored if `keeper.affinity` is set.
  ## @param keeper.nodeAffinityPreset.type Node affinity preset type. Ignored if `keeper.affinity` is set. Allowed values: `soft` or `hard`
  ## @param keeper.nodeAffinityPreset.values Node label values to match. Ignored if `keeper.affinity` is set.
  ##
  nodeAffinityPreset:
    ## e.g:
    ## key: "kubernetes.io/e2e-az-name"
    ##
    key: ""
    type: ""
    ## e.g:
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []
  ## @param keeper.affinity Affinity for ClickHouse Keeper pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## NOTE: `keeper.podAffinityPreset`, `keeper.podAntiAffinityPreset`, and `keeper.nodeAffinityPreset` will be ignored when it's set
  ##
  affinity: {}
  ## @param keeper.nodeSelector Node labels for ClickHouse Keeper pods assignment
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/
  ##
  nodeSelector: {}
  ## @param keeper.tolerations Tolerations for ClickHouse Keeper pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  ## @param keeper.updateStrategy.type ClickHouse Keeper StatefulSet strategy type
  ## @param keeper.updateStrategy.rollingUpdate ClickHouse Keeper StatefulSet rolling update configuration parameters
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  ##
  updateStrategy:
    type: RollingUpdate
    rollingUpdate: {}
  ## @param keeper.podManagementPolicy StatefulSet Pod management policy, it needs to be Parallel to be able to complete the cluster join
  ## Ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies
  ##
  podManagementPolicy: Parallel
  ## @param keeper.priorityClassName ClickHouse Keeper pods' priorityClassName
  ##
  priorityClassName: ""
  ## @param keeper.topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains. Evaluated as a template
  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
  ##
  topologySpreadConstraints: []
  ## @param keeper.schedulerName Name of the k8s scheduler (other than default) for ClickHouse pods
  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  schedulerName: ""
  ## @param keeper.terminationGracePeriodSeconds Seconds Redmine pod needs to terminate gracefully
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods
  ##
  terminationGracePeriodSeconds: ""
  ## @param keeper.lifecycleHooks for the ClickHouse Keeper container(s) to automate configuration before or after startup
  ##
  lifecycleHooks: {}
  ## @param keeper.extraVolumes Optionally specify extra list of additional volumes for the ClickHouse Keeper pod(s)
  ##
  extraVolumes: []
  ## @param keeper.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the ClickHouse Keeper container(s)
  ##
  extraVolumeMounts: []
  ## @param keeper.sidecars Add additional sidecar containers to the ClickHouse Keeper pod(s)
  ## e.g:
  ## sidecars:
  ##   - name: your-image-name
  ##     image: your-image
  ##     imagePullPolicy: Always
  ##     ports:
  ##       - name: portname
  ##         containerPort: 1234
  ##
  sidecars: []
  ## @param keeper.initContainers Add additional init containers to the ClickHouse Keeper pod(s)
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  ## e.g:
  ## initContainers:
  ##  - name: your-image-name
  ##    image: your-image
  ##    imagePullPolicy: Always
  ##    command: ['sh', '-c', 'echo "hello world"']
  ##
  initContainers: []
  ## ClickHouse Keeper Pod Disruption Budget
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/disruptions/
  ## @param keeper.pdb.create Deploy a pdb object for the ClickHouse Keeper pods
  ## @param keeper.pdb.minAvailable Maximum number/percentage of unavailable ClickHouse Keeper replicas
  ## @param keeper.pdb.maxUnavailable Maximum number/percentage of unavailable ClickHouse Keeper replicas
  ##
  pdb:
    create: true
    minAvailable: ""
    maxUnavailable: ""
  ## ClickHouse Keeper Autoscaling configuration
  ## ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
  ##
  autoscaling:
    vpa:
      ## @param keeper.autoscaling.vpa.enabled Enable VPA
      ##
      enabled: false
      ## @param keeper.autoscaling.vpa.annotations Annotations for VPA resource
      ##
      annotations: {}
      ## @param keeper.autoscaling.vpa.controlledResources VPA List of resources that the vertical pod autoscaler can control. Defaults to cpu and memory
      ##
      controlledResources: []
      ## @param keeper.autoscaling.vpa.maxAllowed VPA Max allowed resources for the pod
      ## cpu: 200m
      ## memory: 100Mi
      maxAllowed: {}
      ## @param keeper.autoscaling.vpa.minAllowed VPA Min allowed resources for the pod
      ## cpu: 200m
      ## memory: 100Mi
      minAllowed: {}
      updatePolicy:
        ## @param keeper.autoscaling.vpa.updatePolicy.updateMode Autoscaling update policy Specifies whether recommended updates are applied when a Pod is started and whether recommended updates are applied during the life of a Pod
        ## Possible values are "Off", "Initial", "Recreate", and "Auto".
        ##
        updateMode: Auto

  ## @section ClickHouse Keeper Traffic Exposure parameters

  ## ClickHouse Keeper service parameters
  ##
  service:
    ## @param keeper.service.type ClickHouse Keeper service type
    ##
    type: ClusterIP
    ## @param keeper.service.ports.tcp ClickHouse Keeper service TCP port
    ## @param keeper.service.ports.tcpSecure ClickHouse Keeper service TCP (secure) port
    ## @param keeper.service.ports.raft ClickHouse Keeper service Raft port
    ##
    ports:
      tcp: 9181
      tcpSecure: 9281
      raft: 9234
    ## Node ports to expose
    ## @param keeper.service.nodePorts.tcp Node port for ClickHouse Keeper service TCP port
    ## @param keeper.service.nodePorts.tcpSecure Node port for ClickHouse Keeper service TCP (secure) port
    ## @param keeper.service.nodePorts.raft Node port for ClickHouse Keeper service Raft port
    ## NOTE: choose port between <30000-32767>
    ##
    nodePorts:
      tcp: ""
      tcpSecure: ""
      raft: ""
    ## @param keeper.service.clusterIP ClickHouse Keeper service Cluster IP
    ## e.g.:
    ## clusterIP: None
    ##
    clusterIP: ""
    ## @param keeper.service.loadBalancerIP ClickHouse Keeper service Load Balancer IP
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer
    ##
    loadBalancerIP: ""
    ## @param keeper.service.loadBalancerSourceRanges ClickHouse Keeper service Load Balancer sources
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
    ## e.g:
    ## loadBalancerSourceRanges:
    ##   - 10.10.10.0/24
    ##
    loadBalancerSourceRanges: []
    ## @param keeper.service.externalTrafficPolicy ClickHouse Keeper service external traffic policy
    ## ref http://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    externalTrafficPolicy: Cluster
    ## @param keeper.service.annotations Additional custom annotations for ClickHouse Keeper service
    ##
    annotations: {}
    ## @param keeper.service.extraPorts Extra ports to expose in ClickHouse Keeper service (normally used with the `sidecars` value)
    ##
    extraPorts: []
    ## @param keeper.service.sessionAffinity Control where client requests go, to the same pod or round-robin
    ## Values: ClientIP or None
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/
    ##
    sessionAffinity: None
    ## @param keeper.service.sessionAffinityConfig Additional settings for the sessionAffinity
    ## sessionAffinityConfig:
    ##   clientIP:
    ##     timeoutSeconds: 300
    ##
    sessionAffinityConfig: {}
    ## Headless service properties
    ##
    headless:
      ## @param keeper.service.headless.annotations Annotations for the headless service.
      ##
      annotations: {}
      ## @param keeper.service.headless.extraPorts Optionally specify extra ports to expose for the headless service.
      ##
      extraPorts: []
  ## ClickHouse Keeper Network Policies
  ## Ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/
  ##
  networkPolicy:
    ## @param keeper.networkPolicy.enabled Specifies whether a NetworkPolicy should be created
    ##
    enabled: true
    ## @param keeper.networkPolicy.allowExternal Don't require client label for connections
    ## The Policy model to apply. When set to false, only pods with the correct
    ## client label will have network access to the ports ClickHouse Keeper is listening
    ## on. When true, ClickHouse Keeper will accept connections from any source
    ## (with the correct destination port).
    ##
    allowExternal: true
    ## @param keeper.networkPolicy.allowExternalEgress Allow the pod to access any range of port and all destinations.
    ##
    allowExternalEgress: true
    ## @param keeper.networkPolicy.addExternalClientAccess Allow access from pods with client label set to "true". Ignored if `keeper.networkPolicy.allowExternal` is true.
    ##
    addExternalClientAccess: true
    ## @param keeper.networkPolicy.extraIngress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraIngress:
    ##   - ports:
    ##       - port: 1234
    ##     from:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    extraIngress: []
    ## @param keeper.networkPolicy.extraEgress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraEgress:
    ##   - ports:
    ##       - port: 1234
    ##     to:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    ##
    extraEgress: []
    ## @param keeper.networkPolicy.ingressNSMatchLabels [object] Labels to match to allow traffic from other namespaces
    ## @param keeper.networkPolicy.ingressNSPodMatchLabels [object] Pod labels to match to allow traffic from other namespaces
    ##
    ingressNSMatchLabels: {}
    ingressNSPodMatchLabels: {}

  ## @section ClickHouse Keeper Persistence parameters

  ## persistentVolumeClaimRetentionPolicy
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#persistentvolumeclaim-retention
  ## @param keeper.persistentVolumeClaimRetentionPolicy.enabled Controls if and how PVCs are deleted during the lifecycle of a StatefulSet
  ## @param keeper.persistentVolumeClaimRetentionPolicy.whenScaled Volume retention behavior when the replica count of the StatefulSet is reduced
  ## @param keeper.persistentVolumeClaimRetentionPolicy.whenDeleted Volume retention behavior that applies when the StatefulSet is deleted
  ##
  persistentVolumeClaimRetentionPolicy:
    enabled: false
    whenScaled: Retain
    whenDeleted: Retain
  ## Enable persistence using Persistent Volume Claims
  ## ref: https://kubernetes.io/docs/concepts/storage/persistent-volumes/
  ##
  persistence:
    ## @param keeper.persistence.enabled Enable ClickHouse Keeper data persistence using PVC
    ##
    enabled: true
    ## @param keeper.persistence.existingClaim A manually managed Persistent Volume and Claim
    ## If defined, PVC must be created manually before volume will be bound
    ## The value is evaluated as a template
    ##
    existingClaim: ""
    ## @param keeper.persistence.storageClass PVC Storage Class for ClickHouse Keeper data volume
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ## set, choosing the default provisioner.
    ##
    storageClass: ""
    ## @param keeper.persistence.accessModes Persistent Volume Access Modes
    ##
    accessModes:
      - ReadWriteOnce
    ## @param keeper.persistence.size PVC Storage Request for ClickHouse Keeper data volume
    ##
    size: 8Gi
    ## @param keeper.persistence.annotations Annotations for the PVC
    ##
    annotations: {}
    ## @param keeper.persistence.labels Labels for the PVC
    ##
    labels: {}
    ## @param keeper.persistence.selector Selector to match an existing Persistent Volume for ClickHouse Keeper data PVC. If set, the PVC can't have a PV dynamically provisioned for it
    ## selector:
    ##   matchLabels:
    ##     app: my-app
    ##
    selector: {}
    ## @param keeper.persistence.dataSource Custom PVC data source
    ##
    dataSource: {}
    ## @param keeper.persistence.mountPath Mount path of the ClickHouse Keeper data volume
    ##
    mountPath: /bitnami/clickhouse-keeper

## @section Other Parameters

## ServiceAccount configuration
##
serviceAccount:
  ## @param serviceAccount.create Specifies whether a ServiceAccount should be created
  ##
  create: true
  ## @param serviceAccount.name The name of the ServiceAccount to use.
  ## If not set and create is true, a name is generated using the common.names.fullname template
  ##
  name: ""
  ## @param serviceAccount.annotations Additional Service Account annotations (evaluated as a template)
  ##
  annotations: {}
  ## @param serviceAccount.automountServiceAccountToken Automount service account token for the server service account
  ##
  automountServiceAccountToken: false

## @section Prometheus metrics parameters

metrics:
  ## @param metrics.enabled Enable the export of Prometheus metrics
  ##
  enabled: false
  ## @param metrics.podAnnotations Pod annotations for enabling Prometheus to access the metrics endpoint
  ##
  podAnnotations: {}
  ## Prometheus Operator ServiceMonitor configuration
  ##
  serviceMonitor:
    ## @param metrics.serviceMonitor.enabled if `true`, creates a Prometheus Operator ServiceMonitor (also requires `metrics.enabled` to be `true`)
    ##
    enabled: false
    ## @param metrics.serviceMonitor.namespace Namespace in which Prometheus is running
    ##
    namespace: ""
    ## @param metrics.serviceMonitor.annotations Additional custom annotations for the ServiceMonitor
    ##
    annotations: {}
    ## @param metrics.serviceMonitor.labels Extra labels for the ServiceMonitor
    ##
    labels: {}
    ## @param metrics.serviceMonitor.jobLabel The name of the label on the target service to use as the job name in Prometheus
    ##
    jobLabel: ""
    ## @param metrics.serviceMonitor.honorLabels honorLabels chooses the metric's labels on collisions with target labels
    ##
    honorLabels: false
    ## @param metrics.serviceMonitor.interval Interval at which metrics should be scraped.
    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ## e.g:
    ## interval: 10s
    ##
    interval: ""
    ## @param metrics.serviceMonitor.scrapeTimeout Timeout after which the scrape is ended
    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ## e.g:
    ## scrapeTimeout: 10s
    ##
    scrapeTimeout: ""
    ## @param metrics.serviceMonitor.metricRelabelings Specify additional relabeling of metrics
    ##
    metricRelabelings: []
    ## @param metrics.serviceMonitor.relabelings Specify general relabeling
    ##
    relabelings: []
    ## @param metrics.serviceMonitor.selector Prometheus instance selector labels
    ## ref: https://github.com/bitnami/charts/tree/main/bitnami/prometheus-operator#prometheus-configuration
    ## selector:
    ##   prometheus: my-prometheus
    ##
    selector: {}
  ## Prometheus Operator PrometheusRule configuration
  ##
  prometheusRule:
    ## @param metrics.prometheusRule.enabled Create a PrometheusRule for Prometheus Operator
    ##
    enabled: false
    ## @param metrics.prometheusRule.namespace Namespace for the PrometheusRule Resource (defaults to the Release Namespace)
    ##
    namespace: ""
    ## @param metrics.prometheusRule.additionalLabels Additional labels that can be used so PrometheusRule will be discovered by Prometheus
    ##
    additionalLabels: {}
    ## @param metrics.prometheusRule.rules PrometheusRule definitions
    ##  - alert: ClickHouseServerRestart
    ##    annotations:
    ##      message: ClickHouse server started recently
    ##    expr: ClickHouseAsyncMetrics_Uptime > 1 < 180
    ##    for: 5m
    ##    labels:
    ##      severity: warning
    rules: []

## @section External ClickHouse Keeper / Zookeeper parameters
##
externalZookeeper:
  ## @param externalZookeeper.servers List of external ClickHouse Keeper / Zookeeper servers to use
  ## @param externalZookeeper.port Port of the ClickHouse Keeper / Zookeeper servers
  ##
  servers: []
  port: 2888

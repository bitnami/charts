# Copyright Broadcom, Inc. All Rights Reserved.
# SPDX-License-Identifier: APACHE-2.0

## @section Global parameters
## Global Docker image parameters
## Please, note that this will override the image parameters, including dependencies, configured to use the global value
## Current available global Docker image parameters: imageRegistry, imagePullSecrets and storageClass
##

## @param global.imageRegistry Global Docker image registry
## @param global.imagePullSecrets Global Docker registry secret names as an array
## @param global.defaultStorageClass Global default StorageClass for Persistent Volume(s)
## @param global.storageClass DEPRECATED: use global.defaultStorageClass instead
##
global:
  imageRegistry: ""
  ## E.g.
  ## imagePullSecrets:
  ##   - myRegistryKeySecretName
  ##
  imagePullSecrets: []
  defaultStorageClass: ""
  storageClass: ""
  ## Security parameters
  ##
  security:
    ## @param global.security.allowInsecureImages Allows skipping image verification
    allowInsecureImages: false
  ## Compatibility adaptations for Kubernetes platforms
  ##
  compatibility:
    ## Compatibility adaptations for Openshift
    ##
    openshift:
      ## @param global.compatibility.openshift.adaptSecurityContext Adapt the securityContext sections of the deployment to make them compatible with Openshift restricted-v2 SCC: remove runAsUser, runAsGroup and fsGroup and let the platform use their allowed default IDs. Possible values: auto (apply if the detected running cluster is Openshift), force (perform the adaptation always), disabled (do not perform adaptation)
      ##
      adaptSecurityContext: auto
## @section Common parameters
##

## @param kubeVersion Override Kubernetes version
##
kubeVersion: ""
## @param nameOverride String to partially override common.names.name
##
nameOverride: ""
## @param fullnameOverride String to fully override common.names.fullname
##
fullnameOverride: ""
## @param namespaceOverride String to fully override common.names.namespace
##
namespaceOverride: ""
## @param commonLabels Labels to add to all deployed objects
##
commonLabels: {}
## @param commonAnnotations Annotations to add to all deployed objects
##
commonAnnotations: {}
## @param clusterDomain Kubernetes cluster domain name
##
clusterDomain: cluster.local
## @param extraDeploy Array of extra objects to deploy with the release
##
extraDeploy: []
## Enable diagnostic mode in the deployment
##
diagnosticMode:
  ## @param diagnosticMode.enabled Enable diagnostic mode (all probes will be disabled and the command will be overridden)
  ##
  enabled: false
  ## @param diagnosticMode.command Command to override all containers in the deployment
  ##
  command:
    - sleep
  ## @param diagnosticMode.args Args to override all containers in the deployment
  ##
  args:
    - infinity
## Bitnami Ray Image
## ref: https://hub.docker.com/r/bitnami/ray/tags/
## @param rayImage.registry [default: REGISTRY_NAME] Ray registry
## @param rayImage.repository [default: REPOSITORY_NAME/ray] Ray repository
## @skip rayImage.tag Kuberay Ray tag (immutable tags are recommended)
## @param rayImage.digest Kuberay Ray digest in the way sha256:aa.... Please note this parameter, if set, will override the tag image tag (immutable tags are recommended)
## @param rayImage.pullPolicy Kuberay Ray pull policy
## @param rayImage.pullSecrets Kuberay Ray pull secrets
## @param rayImage.debug Enable Kuberay Ray debug mode
##
rayImage:
  registry: docker.io
  repository: bitnami/ray
  tag: 2.40.0-debian-12-r1
  digest: ""
  ## Specify a imagePullPolicy
  ## ref: https://kubernetes.io/docs/concepts/containers/images/#pre-pulled-images
  ##
  pullPolicy: IfNotPresent
  ## Optionally specify an array of imagePullSecrets.
  ## Secrets must be manually created in the namespace.
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  ## e.g:
  ## pullSecrets:
  ##   - myRegistryKeySecretName
  ##
  pullSecrets: []
  ## Enable debug mode
  ##
  debug: false
## @section Kuberay Operator Parameters
##
operator:
  ## @param operator.enabled Enable Kuberay Operator
  ##
  enabled: true
  ## Bitnami Kuberay Operator image
  ## ref: https://hub.docker.com/r/bitnami/kuberay-operator/tags/
  ## @param operator.image.registry [default: REGISTRY_NAME] Kuberay Operator image registry
  ## @param operator.image.repository [default: REPOSITORY_NAME/kuberay-operator] Kuberay Operator image repository
  ## @skip operator.image.tag Kuberay Operator image tag (immutable tags are recommended)
  ## @param operator.image.digest Kuberay Operator image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag image tag (immutable tags are recommended)
  ## @param operator.image.pullPolicy Kuberay Operator image pull policy
  ## @param operator.image.pullSecrets Kuberay Operator image pull secrets
  ## @param operator.image.debug Enable Kuberay Operator image debug mode
  ##
  image:
    registry: docker.io
    repository: bitnami/kuberay-operator
    tag: 1.2.2-debian-12-r7
    digest: ""
    ## Specify a imagePullPolicy
    ## ref: https://kubernetes.io/docs/concepts/containers/images/#pre-pulled-images
    ##
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ## e.g:
    ## pullSecrets:
    ##   - myRegistryKeySecretName
    ##
    pullSecrets: []
    ## Enable debug mode
    ##
    debug: false
  ## @param operator.replicaCount Number of Kuberay Operator replicas to deploy
  ##
  replicaCount: 1
  ## @param operator.containerPorts.metrics Kuberay Operator metrics container port
  ## @param operator.containerPorts.health Kuberay Operator health container port
  ##
  containerPorts:
    metrics: 8080
    health: 8082
  ## Configure extra options for Kuberay Operator containers' liveness and readiness probes
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
  ## @param operator.livenessProbe.enabled Enable livenessProbe on Kuberay Operator containers
  ## @param operator.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
  ## @param operator.livenessProbe.periodSeconds Period seconds for livenessProbe
  ## @param operator.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
  ## @param operator.livenessProbe.failureThreshold Failure threshold for livenessProbe
  ## @param operator.livenessProbe.successThreshold Success threshold for livenessProbe
  ##
  livenessProbe:
    enabled: true
    initialDelaySeconds: 5
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 5
    successThreshold: 1
  ## @param operator.readinessProbe.enabled Enable readinessProbe on Kuberay Operator containers
  ## @param operator.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
  ## @param operator.readinessProbe.periodSeconds Period seconds for readinessProbe
  ## @param operator.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
  ## @param operator.readinessProbe.failureThreshold Failure threshold for readinessProbe
  ## @param operator.readinessProbe.successThreshold Success threshold for readinessProbe
  ##
  readinessProbe:
    enabled: true
    initialDelaySeconds: 5
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 5
    successThreshold: 1
  ## @param operator.startupProbe.enabled Enable startupProbe on Kuberay Operator containers
  ## @param operator.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe
  ## @param operator.startupProbe.periodSeconds Period seconds for startupProbe
  ## @param operator.startupProbe.timeoutSeconds Timeout seconds for startupProbe
  ## @param operator.startupProbe.failureThreshold Failure threshold for startupProbe
  ## @param operator.startupProbe.successThreshold Success threshold for startupProbe
  ##
  startupProbe:
    enabled: false
    initialDelaySeconds: 5
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 5
    successThreshold: 1
  ## @param operator.customLivenessProbe Custom livenessProbe that overrides the default one
  ##
  customLivenessProbe: {}
  ## @param operator.customReadinessProbe Custom readinessProbe that overrides the default one
  ##
  customReadinessProbe: {}
  ## @param operator.customStartupProbe Custom startupProbe that overrides the default one
  ##
  customStartupProbe: {}
  ## @param operator.watchAllNamespaces Watch for KubeRay resources in all namespaces
  ##
  watchAllNamespaces: true
  ## @param operator.watchNamespaces [array] Watch for KubeRay resources in the given namespaces
  ##
  watchNamespaces: []
  ## @param operator.enableBatchScheduler Enable batch scheduler component
  ##
  enableBatchScheduler: false
  ## Kuberay Operator resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  ## @param operator.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if operator.resources is set (operator.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "nano"
  ## @param operator.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
  ## Configure Pods Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param operator.podSecurityContext.enabled Enabled Kuberay Operator pods' Security Context
  ## @param operator.podSecurityContext.fsGroupChangePolicy Set filesystem group change policy
  ## @param operator.podSecurityContext.sysctls Set kernel settings using the sysctl interface
  ## @param operator.podSecurityContext.supplementalGroups Set filesystem extra groups
  ## @param operator.podSecurityContext.fsGroup Set Kuberay Operator pod's Security Context fsGroup
  ##
  podSecurityContext:
    enabled: true
    fsGroupChangePolicy: Always
    sysctls: []
    supplementalGroups: []
    fsGroup: 1001
  ## Configure Container Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
  ## @param operator.containerSecurityContext.enabled Enabled containers' Security Context
  ## @param operator.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in container
  ## @param operator.containerSecurityContext.runAsUser Set containers' Security Context runAsUser
  ## @param operator.containerSecurityContext.runAsGroup Set containers' Security Context runAsGroup
  ## @param operator.containerSecurityContext.runAsNonRoot Set container's Security Context runAsNonRoot
  ## @param operator.containerSecurityContext.privileged Set container's Security Context privileged
  ## @param operator.containerSecurityContext.readOnlyRootFilesystem Set container's Security Context readOnlyRootFilesystem
  ## @param operator.containerSecurityContext.allowPrivilegeEscalation Set container's Security Context allowPrivilegeEscalation
  ## @param operator.containerSecurityContext.capabilities.drop List of capabilities to be dropped
  ## @param operator.containerSecurityContext.seccompProfile.type Set container's Security Context seccomp profile
  ##
  containerSecurityContext:
    enabled: true
    seLinuxOptions: {}
    runAsUser: 1001
    runAsGroup: 1001
    runAsNonRoot: true
    privileged: false
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
    seccompProfile:
      type: "RuntimeDefault"
  ## @param operator.command Override default container command (useful when using custom images)
  ##
  command: []
  ## @param operator.args Override default container args (useful when using custom images)
  ##
  args: []
  ## @param operator.automountServiceAccountToken Mount Service Account token in pod
  ##
  automountServiceAccountToken: true
  ## @param operator.hostAliases Kuberay Operator pods host aliases
  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
  ##
  hostAliases: []
  ## @param operator.podLabels Extra labels for Kuberay Operator pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  ##
  podLabels: {}
  ## @param operator.podAnnotations Annotations for Kuberay Operator pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  ##
  podAnnotations: {}
  ## @param operator.podAffinityPreset Pod affinity preset. Ignored if `server.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAffinityPreset: ""
  ## @param operator.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `server.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAntiAffinityPreset: soft
  ## Pod Disruption Budget configuration
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb
  ## @param operator.pdb.create Enable/disable a Pod Disruption Budget creation
  ## @param operator.pdb.minAvailable Minimum number/percentage of pods that should remain scheduled
  ## @param operator.pdb.maxUnavailable Maximum number/percentage of pods that may be made unavailable
  ##
  pdb:
    create: true
    minAvailable: ""
    maxUnavailable: ""
  ## Node server.affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ##
  nodeAffinityPreset:
    ## @param operator.nodeAffinityPreset.type Node affinity preset type. Ignored if `server.affinity` is set. Allowed values: `soft` or `hard`
    ##
    type: ""
    ## @param operator.nodeAffinityPreset.key Node label key to match. Ignored if `server.affinity` is set
    ##
    key: ""
    ## @param operator.nodeAffinityPreset.values Node label values to match. Ignored if `server.affinity` is set
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []
  ## @param operator.affinity Affinity for Kuberay Operator pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## NOTE: `server.podAffinityPreset`, `server.podAntiAffinityPreset`, and `server.nodeAffinityPreset` will be ignored when it's set
  ##
  affinity: {}
  ## @param operator.nodeSelector Node labels for Kuberay Operator pods assignment
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes/
  ##
  nodeSelector: {}
  ## @param operator.tolerations Tolerations for Kuberay Operator pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  ## @param operator.updateStrategy.type Kuberay Operator statefulset strategy type
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  ##
  updateStrategy:
    ## StrategyType
    ## Can be set to RollingUpdate or OnDelete
    ##
    type: RollingUpdate
  ## @param operator.priorityClassName Kuberay Operator pods' priorityClassName
  ##
  priorityClassName: ""
  ## @param operator.topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains. Evaluated as a template
  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
  ##
  topologySpreadConstraints: []
  ## @param operator.schedulerName Name of the k8s scheduler (other than default) for Kuberay Operator pods
  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  schedulerName: ""
  ## @param operator.terminationGracePeriodSeconds Seconds Redmine pod needs to terminate gracefully
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods
  ##
  terminationGracePeriodSeconds: ""
  ## @param operator.lifecycleHooks for the Kuberay Operator container(s) to automate configuration before or after startup
  ##
  lifecycleHooks: {}
  ## @param operator.extraEnvVars Array with extra environment variables to add to Kuberay Operator nodes
  ## e.g:
  ## extraEnvVars:
  ##   - name: FOO
  ##     value: "bar"
  ##
  extraEnvVars: []
  ## @param operator.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for Kuberay Operator nodes
  ##
  extraEnvVarsCM: ""
  ## @param operator.extraEnvVarsSecret Name of existing Secret containing extra env vars for Kuberay Operator nodes
  ##
  extraEnvVarsSecret: ""
  ## @param operator.extraVolumes Optionally specify extra list of additional volumes for the Kuberay Operator pod(s)
  ##
  extraVolumes: []
  ## @param operator.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the Kuberay Operator container(s)
  ##
  extraVolumeMounts: []
  ## @param operator.sidecars Add additional sidecar containers to the Kuberay Operator pod(s)
  ## e.g:
  ## sidecars:
  ##   - name: your-image-name
  ##     image: your-image
  ##     imagePullPolicy: Always
  ##     ports:
  ##       - name: portname
  ##         containerPort: 1234
  ##
  sidecars: []
  ## @param operator.initContainers Add additional init containers to the Kuberay Operator pod(s)
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  ## e.g:
  ## initContainers:
  ##  - name: your-image-name
  ##    image: your-image
  ##    imagePullPolicy: Always
  ##    command: ['sh', '-c', 'echo "hello world"']
  ##
  initContainers: []
  ## Autoscaling configuration
  ## ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
  ##
  autoscaling:
    vpa:
      ## @param operator.autoscaling.vpa.enabled Enable VPA
      ##
      enabled: false
      ## @param operator.autoscaling.vpa.annotations Annotations for VPA resource
      ##
      annotations: {}
      ## @param operator.autoscaling.vpa.controlledResources VPA List of resources that the vertical pod autoscaler can control. Defaults to cpu and memory
      ##
      controlledResources: []
      ## @param operator.autoscaling.vpa.maxAllowed VPA Max allowed resources for the pod
      ## cpu: 200m
      ## memory: 100Mi
      maxAllowed: {}
      ## @param operator.autoscaling.vpa.minAllowed VPA Min allowed resources for the pod
      ## cpu: 200m
      ## memory: 100Mi
      minAllowed: {}
      updatePolicy:
        ## @param operator.autoscaling.vpa.updatePolicy.updateMode Autoscaling update policy Specifies whether recommended updates are applied when a Pod is started and whether recommended updates are applied during the life of a Pod
        ## Possible values are "Off", "Initial", "Recreate", and "Auto".
        ##
        updateMode: Auto
    hpa:
      ## @param operator.autoscaling.hpa.enabled Enable autoscaling for operator
      ##
      enabled: false
      ## @param operator.autoscaling.hpa.minReplicas Minimum number of operator replicas
      ##
      minReplicas: ""
      ## @param operator.autoscaling.hpa.maxReplicas Maximum number of operator replicas
      ##
      maxReplicas: ""
      ## @param operator.autoscaling.hpa.targetCPU Target CPU utilization percentage
      ##
      targetCPU: ""
      ## @param operator.autoscaling.hpa.targetMemory Target Memory utilization percentage
      ##
      targetMemory: ""
  ## @section Kuberay Operator Traffic Exposure Parameters
  ##
  service:
    ## @param operator.service.type Kuberay Operator service type
    ##
    type: ClusterIP
    ## @param operator.service.ports.metrics Kuberay Operator service HTTP port
    ##
    ports:
      metrics: 80
    ## Node ports to expose
    ## @param operator.service.nodePorts.metrics Node port for HTTP
    ## NOTE: choose port between <30000-32767>
    ##
    nodePorts:
      metrics: ""
    ## @param operator.service.clusterIP Kuberay Operator service Cluster IP
    ## e.g.:
    ## clusterIP: None
    ##
    clusterIP: ""
    ## @param operator.service.loadBalancerIP Kuberay Operator service Load Balancer IP
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer
    ##
    loadBalancerIP: ""
    ## @param operator.service.loadBalancerSourceRanges Kuberay Operator service Load Balancer sources
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
    ## e.g:
    ## loadBalancerSourceRanges:
    ##   - 10.10.10.0/24
    ##
    loadBalancerSourceRanges: []
    ## @param operator.service.externalTrafficPolicy Kuberay Operator service external traffic policy
    ## ref http://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-web-source-ip
    ##
    externalTrafficPolicy: Cluster
    ## @param operator.service.annotations Additional custom annotations for Kuberay Operator service
    ##
    annotations: {}
    ## @param operator.service.extraPorts Extra ports to expose in Kuberay Operator service (normally used with the `sidecars` value)
    ##
    extraPorts: []
    ## @param operator.service.sessionAffinity Control where web requests go, to the same pod or round-robin
    ## Values: WebIP or None
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/
    ##
    sessionAffinity: None
    ## @param operator.service.sessionAffinityConfig Additional settings for the sessionAffinity
    ## sessionAffinityConfig:
    ##   webIP:
    ##     timeoutSeconds: 300
    ##
    sessionAffinityConfig: {}
  ## Network Policies
  ## Ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/
  ##
  networkPolicy:
    ## @param operator.networkPolicy.enabled Specifies whether a NetworkPolicy should be created
    ##
    enabled: true
    ## @param operator.networkPolicy.kubeAPIServerPorts [array] List of possible endpoints to kube-apiserver (limit to your cluster settings to increase security)
    ##
    kubeAPIServerPorts: [443, 6443, 8443]
    ## @param operator.networkPolicy.allowExternal Don't require server label for connections
    ## The Policy model to apply. When set to false, only pods with the correct
    ## server label will have network access to the ports server is listening
    ## on. When true, server will accept connections from any source
    ## (with the correct destination port).
    ##
    allowExternal: true
    ## @param operator.networkPolicy.allowExternalEgress Allow the pod to access any range of port and all destinations.
    ##
    allowExternalEgress: true
    ## @param operator.networkPolicy.extraIngress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraIngress:
    ##   - ports:
    ##       - port: 1234
    ##     from:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    extraIngress: []
    ## @param operator.networkPolicy.extraEgress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraEgress:
    ##   - ports:
    ##       - port: 1234
    ##     to:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    ##
    extraEgress: []
    ## @param operator.networkPolicy.ingressNSMatchLabels [object] Labels to match to allow traffic from other namespaces
    ## @param operator.networkPolicy.ingressNSPodMatchLabels [object] Pod labels to match to allow traffic from other namespaces
    ##
    ingressNSMatchLabels: {}
    ingressNSPodMatchLabels: {}
  ## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/
  ##
  ingress:
    ## @param operator.ingress.enabled Enable ingress record generation for Kuberay
    ##
    enabled: false
    ## @param operator.ingress.pathType Ingress path type
    ##
    pathType: ImplementationSpecific
    ## @param operator.ingress.apiVersion Force Ingress API version (automatically detected if not set)
    ##
    apiVersion: ""
    ## @param operator.ingress.hostname Default host for the ingress record
    ##
    hostname: kuberay-operator.local
    ## @param operator.ingress.ingressClassName IngressClass that will be be used to implement the Ingress (Kubernetes 1.18+)
    ## This is supported in Kubernetes 1.18+ and required if you have more than one IngressClass marked as the default for your cluster .
    ## ref: https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/
    ##
    ingressClassName: ""
    ## @param operator.ingress.path Default path for the ingress record
    ## NOTE: You may need to set this to '/*' in order to use this with ALB ingress controllers
    ##
    path: /
    ## @param operator.ingress.annotations Additional annotations for the Ingress resource. To enable certificate autogeneration, place here your cert-manager annotations.
    ## Use this parameter to set the required annotations for cert-manager, see
    ## ref: https://cert-manager.io/docs/usage/ingress/#supported-annotations
    ## e.g:
    ## annotations:
    ##   kubernetes.io/ingress.class: nginx
    ##   cert-manager.io/cluster-issuer: cluster-issuer-name
    ##
    annotations: {}
    ## @param operator.ingress.tls Enable TLS configuration for the host defined at `client.ingress.hostname` parameter
    ## TLS certificates will be retrieved from a TLS secret with name: `{{- printf "%s-tls" .Values.ingress.hostname }}`
    ## You can:
    ##   - Use the `client.ingress.secrets` parameter to create this TLS secret
    ##   - Rely on cert-manager to create it by setting the corresponding annotations
    ##   - Rely on Helm to create self-signed certificates by setting `client.ingress.selfSigned=true`
    ##
    tls: false
    ## @param operator.ingress.selfSigned Create a TLS secret for this ingress record using self-signed certificates generated by Helm
    ##
    selfSigned: false
    ## @param operator.ingress.extraHosts An array with additional hostname(s) to be covered with the ingress record
    ## e.g:
    ## extraHosts:
    ##   - name: vault.local
    ##     path: /
    ##
    extraHosts: []
    ## @param operator.ingress.extraPaths An array with additional arbitrary paths that may need to be added to the ingress under the main host
    ## e.g:
    ## extraPaths:
    ## - path: /*
    ##   backend:
    ##     serviceName: ssl-redirect
    ##     servicePort: use-annotation
    ##
    extraPaths: []
    ## @param operator.ingress.extraTls TLS configuration for additional hostname(s) to be covered with this ingress record
    ## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/#tls
    ## e.g:
    ## extraTls:
    ## - hosts:
    ##     - vault.local
    ##   secretName: vault.local-tls
    ##
    extraTls: []
    ## @param operator.ingress.secrets Custom TLS certificates as secrets
    ## NOTE: 'key' and 'certificate' are expected in PEM format
    ## NOTE: 'name' should line up with a 'secretName' set further up
    ## If it is not set and you're using cert-manager, this is unneeded, as it will create a secret for you with valid certificates
    ## If it is not set and you're NOT using cert-manager either, self-signed certificates will be created valid for 365 days
    ## It is also possible to create and manage the certificates outside of this helm chart
    ## Please see README.md for more information
    ## e.g:
    ## secrets:
    ##   - name: vault.local-tls
    ##     key: |-
    ##       -----BEGIN RSA PRIVATE KEY-----
    ##       ...
    ##       -----END RSA PRIVATE KEY-----
    ##     certificate: |-
    ##       -----BEGIN CERTIFICATE-----
    ##       ...
    ##       -----END CERTIFICATE-----
    ##
    secrets: []
    ## @param operator.ingress.extraRules Additional rules to be covered with this ingress record
    ## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-rules
    ## e.g:
    ## extraRules:
    ## - host: example.local
    ##     http:
    ##       path: /
    ##       backend:
    ##         service:
    ##           name: example-svc
    ##           port:
    ##             name: http
    ##
    extraRules: []
  ## @section Kuberay Operator RBAC Parameters
  ##

  ## RBAC configuration
  ##
  rbac:
    ## @param operator.rbac.create Specifies whether RBAC resources should be created
    ##
    create: true
    ## @param operator.rbac.rules Custom RBAC rules to set
    ## e.g:
    ## rules:
    ##   - apiGroups:
    ##       - ""
    ##     resources:
    ##       - pods
    ##     verbs:
    ##       - get
    ##       - list
    ##
    rules: []
  ## ServiceAccount configuration
  ##
  serviceAccount:
    ## @param operator.serviceAccount.create Specifies whether a ServiceAccount should be created
    ##
    create: true
    ## @param operator.serviceAccount.name The name of the ServiceAccount to use.
    ## If not set and create is true, a name is generated using the common.names.fullname template
    ##
    name: ""
    ## @param operator.serviceAccount.annotations Additional Service Account annotations (evaluated as a template)
    ##
    annotations: {}
    ## @param operator.serviceAccount.automountServiceAccountToken Automount service account token for the server service account
    ##
    automountServiceAccountToken: false
  ## @section Kuberay Operator Metrics Parameters
  ##

  ## Prometheus metrics
  ##
  metrics:
    ## @param operator.metrics.enabled Enable the export of Prometheus metrics
    ##
    enabled: false
    ## @param operator.metrics.annotations [object] Annotations for the server service in order to scrape metrics
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "{{ .Values.operator.service.ports.metrics }}"
    ## Prometheus Operator ServiceMonitor configuration
    ##
    serviceMonitor:
      ## @param operator.metrics.serviceMonitor.enabled if `true`, creates a Prometheus Operator ServiceMonitor (also requires `metrics.enabled` to be `true`)
      ##
      enabled: false
      ## @param operator.metrics.serviceMonitor.namespace Namespace in which Prometheus is running
      ##
      namespace: ""
      ## @param operator.metrics.serviceMonitor.annotations Additional custom annotations for the ServiceMonitor
      ##
      annotations: {}
      ## @param operator.metrics.serviceMonitor.labels Extra labels for the ServiceMonitor
      ##
      labels: {}
      ## @param operator.metrics.serviceMonitor.jobLabel The name of the label on the target service to use as the job name in Prometheus
      ##
      jobLabel: ""
      ## @param operator.metrics.serviceMonitor.honorLabels honorLabels chooses the metric's labels on collisions with target labels
      ##
      honorLabels: false
      ## @param operator.metrics.serviceMonitor.interval Interval at which metrics should be scraped.
      ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
      ## e.g:
      ## interval: 10s
      ##
      interval: ""
      ## @param operator.metrics.serviceMonitor.scrapeTimeout Timeout after which the scrape is ended
      ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
      ## e.g:
      ## scrapeTimeout: 10s
      ##
      scrapeTimeout: ""
      ## @param operator.metrics.serviceMonitor.metricRelabelings Specify additional relabeling of metrics
      ##
      metricRelabelings: []
      ## @param operator.metrics.serviceMonitor.relabelings Specify general relabeling
      ##
      relabelings: []
      ## @param operator.metrics.serviceMonitor.selector Prometheus instance selector labels
      ## ref: https://github.com/bitnami/charts/tree/main/bitnami/prometheus-operator#prometheus-configuration
      ## selector:
      ##   prometheus: my-prometheus
      ##
      selector: {}
## @section Kuberay API Server Parameters
##
apiserver:
  ## @param apiserver.enabled Enable Kuberay API Server
  ##
  enabled: true
  ## Bitnami Kuberay API Server image
  ## ref: https://hub.docker.com/r/bitnami/vault/tags/
  ## @param apiserver.image.registry [default: REGISTRY_NAME] Kuberay API Server image registry
  ## @param apiserver.image.repository [default: REPOSITORY_NAME/kuberay-apiserver] Kuberay API Server image repository
  ## @skip apiserver.image.tag Kuberay API Server image tag (immutable tags are recommended)
  ## @param apiserver.image.digest Kuberay API Server image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag image tag (immutable tags are recommended)
  ## @param apiserver.image.pullPolicy Kuberay API Server image pull policy
  ## @param apiserver.image.pullSecrets Kuberay API Server image pull secrets
  ## @param apiserver.image.debug Enable Kuberay API Server image debug mode
  ##
  image:
    registry: docker.io
    repository: bitnami/kuberay-apiserver
    tag: 1.2.2-debian-12-r6
    digest: ""
    ## Specify a imagePullPolicy
    ## ref: https://kubernetes.io/docs/concepts/containers/images/#pre-pulled-images
    ##
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ## e.g:
    ## pullSecrets:
    ##   - myRegistryKeySecretName
    ##
    pullSecrets: []
    ## Enable debug mode
    ##
    debug: false
  ## @param apiserver.replicaCount Number of Kuberay API Server replicas to deploy
  ##
  replicaCount: 1
  ## @param apiserver.containerPorts.http Kuberay API Server http container port
  ## @param apiserver.containerPorts.grpc Kuberay API Server internal (HTTPS) container port
  ##
  containerPorts:
    http: 8888
    grpc: 8887
  ## Configure extra options for Kuberay API Server containers' liveness and readiness probes
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
  ## @param apiserver.livenessProbe.enabled Enable livenessProbe on Kuberay API Server containers
  ## @param apiserver.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
  ## @param apiserver.livenessProbe.periodSeconds Period seconds for livenessProbe
  ## @param apiserver.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
  ## @param apiserver.livenessProbe.failureThreshold Failure threshold for livenessProbe
  ## @param apiserver.livenessProbe.successThreshold Success threshold for livenessProbe
  ##
  livenessProbe:
    enabled: true
    initialDelaySeconds: 5
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 5
    successThreshold: 1
  ## @param apiserver.readinessProbe.enabled Enable readinessProbe on Kuberay API Server containers
  ## @param apiserver.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
  ## @param apiserver.readinessProbe.periodSeconds Period seconds for readinessProbe
  ## @param apiserver.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
  ## @param apiserver.readinessProbe.failureThreshold Failure threshold for readinessProbe
  ## @param apiserver.readinessProbe.successThreshold Success threshold for readinessProbe
  ##
  readinessProbe:
    enabled: true
    initialDelaySeconds: 5
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 5
    successThreshold: 1
  ## @param apiserver.startupProbe.enabled Enable startupProbe on Kuberay API Server containers
  ## @param apiserver.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe
  ## @param apiserver.startupProbe.periodSeconds Period seconds for startupProbe
  ## @param apiserver.startupProbe.timeoutSeconds Timeout seconds for startupProbe
  ## @param apiserver.startupProbe.failureThreshold Failure threshold for startupProbe
  ## @param apiserver.startupProbe.successThreshold Success threshold for startupProbe
  ##
  startupProbe:
    enabled: false
    initialDelaySeconds: 5
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 5
    successThreshold: 1
  ## @param apiserver.customLivenessProbe Custom livenessProbe that overrides the default one
  ##
  customLivenessProbe: {}
  ## @param apiserver.customReadinessProbe Custom readinessProbe that overrides the default one
  ##
  customReadinessProbe: {}
  ## @param apiserver.customStartupProbe Custom startupProbe that overrides the default one
  ##
  customStartupProbe: {}
  ## @param apiserver.watchAllNamespaces Watch for KubeRay resources in all namespaces
  ##
  watchAllNamespaces: true
  ## @param apiserver.watchNamespaces [array] Watch for KubeRay resources in the given namespaces
  ##
  watchNamespaces: []
  ## Kuberay API Server resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
  ## @param apiserver.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if apiserver.resources is set (apiserver.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "nano"
  ## @param apiserver.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
  ## Configure Pods Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param apiserver.podSecurityContext.enabled Enabled Kuberay API Server pods' Security Context
  ## @param apiserver.podSecurityContext.fsGroupChangePolicy Set filesystem group change policy
  ## @param apiserver.podSecurityContext.sysctls Set kernel settings using the sysctl interface
  ## @param apiserver.podSecurityContext.supplementalGroups Set filesystem extra groups
  ## @param apiserver.podSecurityContext.fsGroup Set Kuberay API Server pod's Security Context fsGroup
  ##
  podSecurityContext:
    enabled: true
    fsGroupChangePolicy: Always
    sysctls: []
    supplementalGroups: []
    fsGroup: 1001
  ## Configure Container Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
  ## @param apiserver.containerSecurityContext.enabled Enabled containers' Security Context
  ## @param apiserver.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in container
  ## @param apiserver.containerSecurityContext.runAsUser Set containers' Security Context runAsUser
  ## @param apiserver.containerSecurityContext.runAsGroup Set containers' Security Context runAsGroup
  ## @param apiserver.containerSecurityContext.runAsNonRoot Set container's Security Context runAsNonRoot
  ## @param apiserver.containerSecurityContext.privileged Set container's Security Context privileged
  ## @param apiserver.containerSecurityContext.readOnlyRootFilesystem Set container's Security Context readOnlyRootFilesystem
  ## @param apiserver.containerSecurityContext.allowPrivilegeEscalation Set container's Security Context allowPrivilegeEscalation
  ## @param apiserver.containerSecurityContext.capabilities.drop List of capabilities to be dropped
  ## @param apiserver.containerSecurityContext.seccompProfile.type Set container's Security Context seccomp profile
  ##
  containerSecurityContext:
    enabled: true
    seLinuxOptions: {}
    runAsUser: 1001
    runAsGroup: 1001
    runAsNonRoot: true
    privileged: false
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
    seccompProfile:
      type: "RuntimeDefault"
  ## @param apiserver.command Override default container command (useful when using custom images)
  ##
  command: []
  ## @param apiserver.args Override default container args (useful when using custom images)
  ##
  args: []
  ## @param apiserver.automountServiceAccountToken Mount Service Account token in pod
  ##
  automountServiceAccountToken: true
  ## @param apiserver.hostAliases Kuberay API Server pods host aliases
  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
  ##
  hostAliases: []
  ## @param apiserver.podLabels Extra labels for Kuberay API Server pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  ##
  podLabels: {}
  ## @param apiserver.podAnnotations Annotations for Kuberay API Server pods
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  ##
  podAnnotations: {}
  ## @param apiserver.podAffinityPreset Pod affinity preset. Ignored if `server.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAffinityPreset: ""
  ## @param apiserver.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `server.affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAntiAffinityPreset: soft
  ## Pod Disruption Budget configuration
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb
  ## @param apiserver.pdb.create Enable/disable a Pod Disruption Budget creation
  ## @param apiserver.pdb.minAvailable Minimum number/percentage of pods that should remain scheduled
  ## @param apiserver.pdb.maxUnavailable Maximum number/percentage of pods that may be made unavailable
  ##
  pdb:
    create: true
    minAvailable: ""
    maxUnavailable: ""
  ## Node server.affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ##
  nodeAffinityPreset:
    ## @param apiserver.nodeAffinityPreset.type Node affinity preset type. Ignored if `server.affinity` is set. Allowed values: `soft` or `hard`
    ##
    type: ""
    ## @param apiserver.nodeAffinityPreset.key Node label key to match. Ignored if `server.affinity` is set
    ##
    key: ""
    ## @param apiserver.nodeAffinityPreset.values Node label values to match. Ignored if `server.affinity` is set
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []
  ## @param apiserver.affinity Affinity for Kuberay API Server pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## NOTE: `server.podAffinityPreset`, `server.podAntiAffinityPreset`, and `server.nodeAffinityPreset` will be ignored when it's set
  ##
  affinity: {}
  ## @param apiserver.nodeSelector Node labels for Kuberay API Server pods assignment
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes/
  ##
  nodeSelector: {}
  ## @param apiserver.tolerations Tolerations for Kuberay API Server pods assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  ## @param apiserver.updateStrategy.type Kuberay API Server statefulset strategy type
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  ##
  updateStrategy:
    ## StrategyType
    ## Can be set to RollingUpdate or OnDelete
    ##
    type: RollingUpdate
  ## @param apiserver.priorityClassName Kuberay API Server pods' priorityClassName
  ##
  priorityClassName: ""
  ## @param apiserver.topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains. Evaluated as a template
  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
  ##
  topologySpreadConstraints: []
  ## @param apiserver.schedulerName Name of the k8s scheduler (other than default) for Kuberay API Server pods
  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  schedulerName: ""
  ## @param apiserver.terminationGracePeriodSeconds Seconds Redmine pod needs to terminate gracefully
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods
  ##
  terminationGracePeriodSeconds: ""
  ## @param apiserver.lifecycleHooks for the Kuberay API Server container(s) to automate configuration before or after startup
  ##
  lifecycleHooks: {}
  ## @param apiserver.extraEnvVars Array with extra environment variables to add to Kuberay API Server nodes
  ## e.g:
  ## extraEnvVars:
  ##   - name: FOO
  ##     value: "bar"
  ##
  extraEnvVars: []
  ## @param apiserver.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for Kuberay API Server nodes
  ##
  extraEnvVarsCM: ""
  ## @param apiserver.extraEnvVarsSecret Name of existing Secret containing extra env vars for Kuberay API Server nodes
  ##
  extraEnvVarsSecret: ""
  ## @param apiserver.extraVolumes Optionally specify extra list of additional volumes for the Kuberay API Server pod(s)
  ##
  extraVolumes: []
  ## @param apiserver.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the Kuberay API Server container(s)
  ##
  extraVolumeMounts: []
  ## @param apiserver.sidecars Add additional sidecar containers to the Kuberay API Server pod(s)
  ## e.g:
  ## sidecars:
  ##   - name: your-image-name
  ##     image: your-image
  ##     imagePullPolicy: Always
  ##     ports:
  ##       - name: portname
  ##         containerPort: 1234
  ##
  sidecars: []
  ## @param apiserver.initContainers Add additional init containers to the Kuberay API Server pod(s)
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  ## e.g:
  ## initContainers:
  ##  - name: your-image-name
  ##    image: your-image
  ##    imagePullPolicy: Always
  ##    command: ['sh', '-c', 'echo "hello world"']
  ##
  initContainers: []
  ## Autoscaling configuration
  ## ref: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
  ##
  autoscaling:
    vpa:
      ## @param apiserver.autoscaling.vpa.enabled Enable VPA
      ##
      enabled: false
      ## @param apiserver.autoscaling.vpa.annotations Annotations for VPA resource
      ##
      annotations: {}
      ## @param apiserver.autoscaling.vpa.controlledResources VPA List of resources that the vertical pod autoscaler can control. Defaults to cpu and memory
      ##
      controlledResources: []
      ## @param apiserver.autoscaling.vpa.maxAllowed VPA Max allowed resources for the pod
      ## cpu: 200m
      ## memory: 100Mi
      maxAllowed: {}
      ## @param apiserver.autoscaling.vpa.minAllowed VPA Min allowed resources for the pod
      ## cpu: 200m
      ## memory: 100Mi
      minAllowed: {}
      updatePolicy:
        ## @param apiserver.autoscaling.vpa.updatePolicy.updateMode Autoscaling update policy Specifies whether recommended updates are applied when a Pod is started and whether recommended updates are applied during the life of a Pod
        ## Possible values are "Off", "Initial", "Recreate", and "Auto".
        ##
        updateMode: Auto
    hpa:
      ## @param apiserver.autoscaling.hpa.enabled Enable autoscaling for apiserver
      ##
      enabled: false
      ## @param apiserver.autoscaling.hpa.minReplicas Minimum number of apiserver replicas
      ##
      minReplicas: ""
      ## @param apiserver.autoscaling.hpa.maxReplicas Maximum number of apiserver replicas
      ##
      maxReplicas: ""
      ## @param apiserver.autoscaling.hpa.targetCPU Target CPU utilization percentage
      ##
      targetCPU: ""
      ## @param apiserver.autoscaling.hpa.targetMemory Target Memory utilization percentage
      ##
      targetMemory: ""
  ## @section Kuberay API Server Traffic Exposure Parameters
  ##
  service:
    ## @param apiserver.service.type Kuberay API Server service type
    ##
    type: ClusterIP
    ## @param apiserver.service.ports.http Kuberay API Server service HTTP port
    ## @param apiserver.service.ports.grpc Kuberay API Server service HTTP port
    ##
    ports:
      http: 80
      grpc: 8887
    ## Node ports to expose
    ## @param apiserver.service.nodePorts.http Node port for HTTP
    ## @param apiserver.service.nodePorts.grpc Node port for GRPC
    ## NOTE: choose port between <30000-32767>
    ##
    nodePorts:
      http: ""
      grpc: ""
    ## @param apiserver.service.clusterIP Kuberay API Server service Cluster IP
    ## e.g.:
    ## clusterIP: None
    ##
    clusterIP: ""
    ## @param apiserver.service.loadBalancerIP Kuberay API Server service Load Balancer IP
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-loadbalancer
    ##
    loadBalancerIP: ""
    ## @param apiserver.service.loadBalancerSourceRanges Kuberay API Server service Load Balancer sources
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
    ## e.g:
    ## loadBalancerSourceRanges:
    ##   - 10.10.10.0/24
    ##
    loadBalancerSourceRanges: []
    ## @param apiserver.service.externalTrafficPolicy Kuberay API Server service external traffic policy
    ## ref http://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-web-source-ip
    ##
    externalTrafficPolicy: Cluster
    ## @param apiserver.service.annotations Additional custom annotations for Kuberay API Server service
    ##
    annotations: {}
    ## @param apiserver.service.extraPorts Extra ports to expose in Kuberay API Server service (normally used with the `sidecars` value)
    ##
    extraPorts: []
    ## @param apiserver.service.sessionAffinity Control where web requests go, to the same pod or round-robin
    ## Values: WebIP or None
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/
    ##
    sessionAffinity: None
    ## @param apiserver.service.sessionAffinityConfig Additional settings for the sessionAffinity
    ## sessionAffinityConfig:
    ##   webIP:
    ##     timeoutSeconds: 300
    ##
    sessionAffinityConfig: {}
  ## Network Policies
  ## Ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/
  ##
  networkPolicy:
    ## @param apiserver.networkPolicy.enabled Specifies whether a NetworkPolicy should be created
    ##
    enabled: true
    ## @param apiserver.networkPolicy.kubeAPIServerPorts [array] List of possible endpoints to kube-apiserver (limit to your cluster settings to increase security)
    ##
    kubeAPIServerPorts: [443, 6443, 8443]
    ## @param apiserver.networkPolicy.allowExternal Don't require server label for connections
    ## The Policy model to apply. When set to false, only pods with the correct
    ## server label will have network access to the ports server is listening
    ## on. When true, server will accept connections from any source
    ## (with the correct destination port).
    ##
    allowExternal: true
    ## @param apiserver.networkPolicy.allowExternalEgress Allow the pod to access any range of port and all destinations.
    ##
    allowExternalEgress: true
    ## @param apiserver.networkPolicy.extraIngress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraIngress:
    ##   - ports:
    ##       - port: 1234
    ##     from:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    extraIngress: []
    ## @param apiserver.networkPolicy.extraEgress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraEgress:
    ##   - ports:
    ##       - port: 1234
    ##     to:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    ##
    extraEgress: []
    ## @param apiserver.networkPolicy.ingressNSMatchLabels [object] Labels to match to allow traffic from other namespaces
    ## @param apiserver.networkPolicy.ingressNSPodMatchLabels [object] Pod labels to match to allow traffic from other namespaces
    ##
    ingressNSMatchLabels: {}
    ingressNSPodMatchLabels: {}
  ## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/
  ##
  ingress:
    ## @param apiserver.ingress.enabled Enable ingress record generation for Kuberay
    ##
    enabled: false
    ## @param apiserver.ingress.pathType Ingress path type
    ##
    pathType: ImplementationSpecific
    ## @param apiserver.ingress.apiVersion Force Ingress API version (automatically detected if not set)
    ##
    apiVersion: ""
    ## @param apiserver.ingress.hostname Default host for the ingress record
    ##
    hostname: kuberay-apiserver.local
    ## @param apiserver.ingress.ingressClassName IngressClass that will be be used to implement the Ingress (Kubernetes 1.18+)
    ## This is supported in Kubernetes 1.18+ and required if you have more than one IngressClass marked as the default for your cluster .
    ## ref: https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/
    ##
    ingressClassName: ""
    ## @param apiserver.ingress.path Default path for the ingress record
    ## NOTE: You may need to set this to '/*' in order to use this with ALB ingress controllers
    ##
    path: /
    ## @param apiserver.ingress.annotations Additional annotations for the Ingress resource. To enable certificate autogeneration, place here your cert-manager annotations.
    ## Use this parameter to set the required annotations for cert-manager, see
    ## ref: https://cert-manager.io/docs/usage/ingress/#supported-annotations
    ## e.g:
    ## annotations:
    ##   kubernetes.io/ingress.class: nginx
    ##   cert-manager.io/cluster-issuer: cluster-issuer-name
    ##
    annotations: {}
    ## @param apiserver.ingress.tls Enable TLS configuration for the host defined at `client.ingress.hostname` parameter
    ## TLS certificates will be retrieved from a TLS secret with name: `{{- printf "%s-tls" .Values.ingress.hostname }}`
    ## You can:
    ##   - Use the `client.ingress.secrets` parameter to create this TLS secret
    ##   - Rely on cert-manager to create it by setting the corresponding annotations
    ##   - Rely on Helm to create self-signed certificates by setting `client.ingress.selfSigned=true`
    ##
    tls: false
    ## @param apiserver.ingress.selfSigned Create a TLS secret for this ingress record using self-signed certificates generated by Helm
    ##
    selfSigned: false
    ## @param apiserver.ingress.extraHosts An array with additional hostname(s) to be covered with the ingress record
    ## e.g:
    ## extraHosts:
    ##   - name: vault.local
    ##     path: /
    ##
    extraHosts: []
    ## @param apiserver.ingress.extraPaths An array with additional arbitrary paths that may need to be added to the ingress under the main host
    ## e.g:
    ## extraPaths:
    ## - path: /*
    ##   backend:
    ##     serviceName: ssl-redirect
    ##     servicePort: use-annotation
    ##
    extraPaths: []
    ## @param apiserver.ingress.extraTls TLS configuration for additional hostname(s) to be covered with this ingress record
    ## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/#tls
    ## e.g:
    ## extraTls:
    ## - hosts:
    ##     - vault.local
    ##   secretName: vault.local-tls
    ##
    extraTls: []
    ## @param apiserver.ingress.secrets Custom TLS certificates as secrets
    ## NOTE: 'key' and 'certificate' are expected in PEM format
    ## NOTE: 'name' should line up with a 'secretName' set further up
    ## If it is not set and you're using cert-manager, this is unneeded, as it will create a secret for you with valid certificates
    ## If it is not set and you're NOT using cert-manager either, self-signed certificates will be created valid for 365 days
    ## It is also possible to create and manage the certificates outside of this helm chart
    ## Please see README.md for more information
    ## e.g:
    ## secrets:
    ##   - name: vault.local-tls
    ##     key: |-
    ##       -----BEGIN RSA PRIVATE KEY-----
    ##       ...
    ##       -----END RSA PRIVATE KEY-----
    ##     certificate: |-
    ##       -----BEGIN CERTIFICATE-----
    ##       ...
    ##       -----END CERTIFICATE-----
    ##
    secrets: []
    ## @param apiserver.ingress.extraRules Additional rules to be covered with this ingress record
    ## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-rules
    ## e.g:
    ## extraRules:
    ## - host: example.local
    ##     http:
    ##       path: /
    ##       backend:
    ##         service:
    ##           name: example-svc
    ##           port:
    ##             name: http
    ##
    extraRules: []
  ## @section Kuberay API Server RBAC Parameters
  ##

  ## RBAC configuration
  ##
  rbac:
    ## @param apiserver.rbac.create Specifies whether RBAC resources should be created
    ##
    create: true
    ## @param apiserver.rbac.rules Custom RBAC rules to set
    ## e.g:
    ## rules:
    ##   - apiGroups:
    ##       - ""
    ##     resources:
    ##       - pods
    ##     verbs:
    ##       - get
    ##       - list
    ##
    rules: []
  ## ServiceAccount configuration
  ##
  serviceAccount:
    ## @param apiserver.serviceAccount.create Specifies whether a ServiceAccount should be created
    ##
    create: true
    ## @param apiserver.serviceAccount.name The name of the ServiceAccount to use.
    ## If not set and create is true, a name is generated using the common.names.fullname template
    ##
    name: ""
    ## @param apiserver.serviceAccount.annotations Additional Service Account annotations (evaluated as a template)
    ##
    annotations: {}
    ## @param apiserver.serviceAccount.automountServiceAccountToken Automount service account token for the server service account
    ##
    automountServiceAccountToken: false
  ## @section Kuberay API Server Metrics Parameters
  ##

  ## Prometheus metrics
  ##
  metrics:
    ## @param apiserver.metrics.enabled Enable the export of Prometheus metrics
    ##
    enabled: false
    ## @param apiserver.metrics.annotations [object] Annotations for the server service in order to scrape metrics
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "{{ .Values.apiserver.service.ports.http }}"
    ## Prometheus API Server ServiceMonitor configuration
    ##
    serviceMonitor:
      ## @param apiserver.metrics.serviceMonitor.enabled if `true`, creates a Prometheus API Server ServiceMonitor (also requires `metrics.enabled` to be `true`)
      ##
      enabled: false
      ## @param apiserver.metrics.serviceMonitor.namespace Namespace in which Prometheus is running
      ##
      namespace: ""
      ## @param apiserver.metrics.serviceMonitor.annotations Additional custom annotations for the ServiceMonitor
      ##
      annotations: {}
      ## @param apiserver.metrics.serviceMonitor.labels Extra labels for the ServiceMonitor
      ##
      labels: {}
      ## @param apiserver.metrics.serviceMonitor.jobLabel The name of the label on the target service to use as the job name in Prometheus
      ##
      jobLabel: ""
      ## @param apiserver.metrics.serviceMonitor.honorLabels honorLabels chooses the metric's labels on collisions with target labels
      ##
      honorLabels: false
      ## @param apiserver.metrics.serviceMonitor.interval Interval at which metrics should be scraped.
      ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
      ## e.g:
      ## interval: 10s
      ##
      interval: ""
      ## @param apiserver.metrics.serviceMonitor.scrapeTimeout Timeout after which the scrape is ended
      ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
      ## e.g:
      ## scrapeTimeout: 10s
      ##
      scrapeTimeout: ""
      ## @param apiserver.metrics.serviceMonitor.metricRelabelings Specify additional relabeling of metrics
      ##
      metricRelabelings: []
      ## @param apiserver.metrics.serviceMonitor.relabelings Specify general relabeling
      ##
      relabelings: []
      ## @param apiserver.metrics.serviceMonitor.selector Prometheus instance selector labels
      ## ref: https://github.com/bitnami/charts/tree/main/bitnami/prometheus-operator#prometheus-configuration
      ## selector:
      ##   prometheus: my-prometheus
      ##
      selector: {}
## @section Ray Cluster Parameters
##
cluster:
  ## @param cluster.enabled Deploy Ray Cluster
  ##
  enabled: true
  ## @param cluster.serviceType Set cluster service type
  ##
  serviceType: LoadBalancer
  ## @section Ray Cluster Head Parameters
  ##
  head:
    ## @param cluster.head.rayStartParams Set Ray start parameters
    ##
    rayStartParams: {}
    ## Ray Cluster Worker (common) resource requests and limits
    ## ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
    ## @param cluster.head.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if cluster.head.resources is set (cluster.head.resources is recommended for production).
    ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
    ##
    resourcesPreset: "medium"
    ## @param cluster.head.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
    ## Example:
    ## resources:
    ##   requests:
    ##     cpu: 2
    ##     memory: 512Mi
    ##   limits:
    ##     cpu: 3
    ##     memory: 1024Mi
    ##
    resources: {}
    ## Configure Pods Security Context
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
    ## @param cluster.head.podSecurityContext.enabled Enabled Ray Cluster Worker (common) pods' Security Context
    ## @param cluster.head.podSecurityContext.fsGroupChangePolicy Set filesystem group change policy
    ## @param cluster.head.podSecurityContext.sysctls Set kernel settings using the sysctl interface
    ## @param cluster.head.podSecurityContext.supplementalGroups Set filesystem extra groups
    ## @param cluster.head.podSecurityContext.fsGroup Set Ray Cluster Worker (common) pod's Security Context fsGroup
    ##
    podSecurityContext:
      enabled: true
      fsGroupChangePolicy: Always
      sysctls: []
      supplementalGroups: []
      fsGroup: 1001
    ## Configure Container Security Context
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
    ## @param cluster.head.containerSecurityContext.enabled Enabled containers' Security Context
    ## @param cluster.head.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in container
    ## @param cluster.head.containerSecurityContext.runAsUser Set containers' Security Context runAsUser
    ## @param cluster.head.containerSecurityContext.runAsGroup Set containers' Security Context runAsGroup
    ## @param cluster.head.containerSecurityContext.runAsNonRoot Set container's Security Context runAsNonRoot
    ## @param cluster.head.containerSecurityContext.privileged Set container's Security Context privileged
    ## @param cluster.head.containerSecurityContext.readOnlyRootFilesystem Set container's Security Context readOnlyRootFilesystem
    ## @param cluster.head.containerSecurityContext.allowPrivilegeEscalation Set container's Security Context allowPrivilegeEscalation
    ## @param cluster.head.containerSecurityContext.capabilities.drop List of capabilities to be dropped
    ## @param cluster.head.containerSecurityContext.seccompProfile.type Set container's Security Context seccomp profile
    ##
    containerSecurityContext:
      enabled: true
      seLinuxOptions: {}
      runAsUser: 1001
      runAsGroup: 1001
      runAsNonRoot: true
      privileged: false
      readOnlyRootFilesystem: true
      allowPrivilegeEscalation: false
      capabilities:
        drop: ["ALL"]
      seccompProfile:
        type: "RuntimeDefault"
    ## @param cluster.head.command Override default container command (useful when using custom images)
    ##
    command: []
    ## @param cluster.head.args Override default container args (useful when using custom images)
    ##
    args: []
    ## @param cluster.head.automountServiceAccountToken Mount Service Account token in pod
    ##
    automountServiceAccountToken: false
    ## @param cluster.head.hostAliases Ray Cluster Worker (common) pods host aliases
    ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
    ##
    hostAliases: []
    ## @param cluster.head.podLabels Extra labels for Ray Cluster Worker (common) pods
    ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
    ##
    podLabels: {}
    ## @param cluster.head.podAnnotations Annotations for Ray Cluster Worker (common) pods
    ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
    ##
    podAnnotations: {}
    ## @param cluster.head.podAffinityPreset Pod affinity preset. Ignored if `server.affinity` is set. Allowed values: `soft` or `hard`
    ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
    ##
    podAffinityPreset: ""
    ## @param cluster.head.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `server.affinity` is set. Allowed values: `soft` or `hard`
    ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
    ##
    podAntiAffinityPreset: soft
    ## Node server.affinity preset
    ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
    ##
    nodeAffinityPreset:
      ## @param cluster.head.nodeAffinityPreset.type Node affinity preset type. Ignored if `server.affinity` is set. Allowed values: `soft` or `hard`
      ##
      type: ""
      ## @param cluster.head.nodeAffinityPreset.key Node label key to match. Ignored if `server.affinity` is set
      ##
      key: ""
      ## @param cluster.head.nodeAffinityPreset.values Node label values to match. Ignored if `server.affinity` is set
      ## E.g.
      ## values:
      ##   - e2e-az1
      ##   - e2e-az2
      ##
      values: []
    ## @param cluster.head.affinity Affinity for Ray Cluster Worker (common) pods assignment
    ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
    ## NOTE: `server.podAffinityPreset`, `server.podAntiAffinityPreset`, and `server.nodeAffinityPreset` will be ignored when it's set
    ##
    affinity: {}
    ## @param cluster.head.nodeSelector Node labels for Ray Cluster Worker (common) pods assignment
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes/
    ##
    nodeSelector: {}
    ## @param cluster.head.tolerations Tolerations for Ray Cluster Worker (common) pods assignment
    ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
    ##
    tolerations: []
    ## @param cluster.head.priorityClassName Ray Cluster Worker (common) pods' priorityClassName
    ##
    priorityClassName: ""
    ## @param cluster.head.topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains. Evaluated as a template
    ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
    ##
    topologySpreadConstraints: []
    ## @param cluster.head.schedulerName Name of the k8s scheduler (other than default) for Ray Cluster Worker (common) pods
    ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
    ##
    schedulerName: ""
    ## @param cluster.head.terminationGracePeriodSeconds Seconds Redmine pod needs to terminate gracefully
    ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods
    ##
    terminationGracePeriodSeconds: ""
    ## @param cluster.head.lifecycleHooks for the Ray Cluster Worker (common) container(s) to automate configuration before or after startup
    ##
    lifecycleHooks: {}
    ## @param cluster.head.extraEnvVars Array with extra environment variables to add to Ray Cluster Worker (common) nodes
    ## e.g:
    ## extraEnvVars:
    ##   - name: FOO
    ##     value: "bar"
    ##
    extraEnvVars: []
    ## @param cluster.head.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for Ray Cluster Worker (common) nodes
    ##
    extraEnvVarsCM: ""
    ## @param cluster.head.extraEnvVarsSecret Name of existing Secret containing extra env vars for Ray Cluster Worker (common) nodes
    ##
    extraEnvVarsSecret: ""
    ## @param cluster.head.extraVolumes Optionally specify extra list of additional volumes for the Ray Cluster Worker (common) pod(s)
    ##
    extraVolumes: []
    ## @param cluster.head.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the Ray Cluster Worker (common) container(s)
    ##
    extraVolumeMounts: []
    ## @param cluster.head.sidecars Add additional sidecar containers to the Ray Cluster Worker (common) pod(s)
    ## e.g:
    ## sidecars:
    ##   - name: your-image-name
    ##     image: your-image
    ##     imagePullPolicy: Always
    ##     ports:
    ##       - name: portname
    ##         containerPort: 1234
    ##
    sidecars: []
    ## @param cluster.head.initContainers Add additional init containers to the Ray Cluster Worker (common) pod(s)
    ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
    ## e.g:
    ## initContainers:
    ##  - name: your-image-name
    ##    image: your-image
    ##    imagePullPolicy: Always
    ##    command: ['sh', '-c', 'echo "hello world"']
    ##
    initContainers: []
    ## @param cluster.head.customLivenessProbe Custom livenessProbe that overrides the default one
    ##
    customLivenessProbe: {}
    ## @param cluster.head.customReadinessProbe Custom readinessProbe that overrides the default one
    ##
    customReadinessProbe: {}
    ## @param cluster.head.customStartupProbe Custom startupProbe that overrides the default one
    ##
    customStartupProbe: {}
  ## @section Ray Cluster Worker Parameters
  ##
  worker:
    common:
      ## @param cluster.worker.common.rayStartParams Set Ray start parameters
      ##
      rayStartParams: {}
      ## @param cluster.worker.common.replicaCount Number of Ray Cluster Worker (common) replicas to deploy
      ##
      replicaCount: 1
      ## @param cluster.worker.common.customLivenessProbe Custom livenessProbe that overrides the default one
      ##
      customLivenessProbe: {}
      ## @param cluster.worker.common.customReadinessProbe Custom readinessProbe that overrides the default one
      ##
      customReadinessProbe: {}
      ## @param cluster.worker.common.customStartupProbe Custom startupProbe that overrides the default one
      ##
      customStartupProbe: {}
      ## Ray Cluster Worker (common) resource requests and limits
      ## ref: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/
      ## @param cluster.worker.common.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if cluster.worker.common.resources is set (cluster.worker.common.resources is recommended for production).
      ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
      ##
      resourcesPreset: "small"
      ## @param cluster.worker.common.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
      ## Example:
      ## resources:
      ##   requests:
      ##     cpu: 2
      ##     memory: 512Mi
      ##   limits:
      ##     cpu: 3
      ##     memory: 1024Mi
      ##
      resources: {}
      ## Configure Pods Security Context
      ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
      ## @param cluster.worker.common.podSecurityContext.enabled Enabled Ray Cluster Worker (common) pods' Security Context
      ## @param cluster.worker.common.podSecurityContext.fsGroupChangePolicy Set filesystem group change policy
      ## @param cluster.worker.common.podSecurityContext.sysctls Set kernel settings using the sysctl interface
      ## @param cluster.worker.common.podSecurityContext.supplementalGroups Set filesystem extra groups
      ## @param cluster.worker.common.podSecurityContext.fsGroup Set Ray Cluster Worker (common) pod's Security Context fsGroup
      ##
      podSecurityContext:
        enabled: true
        fsGroupChangePolicy: Always
        sysctls: []
        supplementalGroups: []
        fsGroup: 1001
      ## Configure Container Security Context
      ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
      ## @param cluster.worker.common.containerSecurityContext.enabled Enabled containers' Security Context
      ## @param cluster.worker.common.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in container
      ## @param cluster.worker.common.containerSecurityContext.runAsUser Set containers' Security Context runAsUser
      ## @param cluster.worker.common.containerSecurityContext.runAsGroup Set containers' Security Context runAsGroup
      ## @param cluster.worker.common.containerSecurityContext.runAsNonRoot Set container's Security Context runAsNonRoot
      ## @param cluster.worker.common.containerSecurityContext.privileged Set container's Security Context privileged
      ## @param cluster.worker.common.containerSecurityContext.readOnlyRootFilesystem Set container's Security Context readOnlyRootFilesystem
      ## @param cluster.worker.common.containerSecurityContext.allowPrivilegeEscalation Set container's Security Context allowPrivilegeEscalation
      ## @param cluster.worker.common.containerSecurityContext.capabilities.drop List of capabilities to be dropped
      ## @param cluster.worker.common.containerSecurityContext.seccompProfile.type Set container's Security Context seccomp profile
      ##
      containerSecurityContext:
        enabled: true
        seLinuxOptions: {}
        runAsUser: 1001
        runAsGroup: 1001
        runAsNonRoot: true
        privileged: false
        readOnlyRootFilesystem: true
        allowPrivilegeEscalation: false
        capabilities:
          drop: ["ALL"]
        seccompProfile:
          type: "RuntimeDefault"
      ## @param cluster.worker.common.command Override default container command (useful when using custom images)
      ##
      command: []
      ## @param cluster.worker.common.args Override default container args (useful when using custom images)
      ##
      args: []
      ## @param cluster.worker.common.automountServiceAccountToken Mount Service Account token in pod
      ##
      automountServiceAccountToken: false
      ## @param cluster.worker.common.hostAliases Ray Cluster Worker (common) pods host aliases
      ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
      ##
      hostAliases: []
      ## @param cluster.worker.common.podLabels Extra labels for Ray Cluster Worker (common) pods
      ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
      ##
      podLabels: {}
      ## @param cluster.worker.common.podAnnotations Annotations for Ray Cluster Worker (common) pods
      ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
      ##
      podAnnotations: {}
      ## @param cluster.worker.common.podAffinityPreset Pod affinity preset. Ignored if `server.affinity` is set. Allowed values: `soft` or `hard`
      ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
      ##
      podAffinityPreset: ""
      ## @param cluster.worker.common.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `server.affinity` is set. Allowed values: `soft` or `hard`
      ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
      ##
      podAntiAffinityPreset: soft
      ## Node server.affinity preset
      ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
      ##
      nodeAffinityPreset:
        ## @param cluster.worker.common.nodeAffinityPreset.type Node affinity preset type. Ignored if `server.affinity` is set. Allowed values: `soft` or `hard`
        ##
        type: ""
        ## @param cluster.worker.common.nodeAffinityPreset.key Node label key to match. Ignored if `server.affinity` is set
        ##
        key: ""
        ## @param cluster.worker.common.nodeAffinityPreset.values Node label values to match. Ignored if `server.affinity` is set
        ## E.g.
        ## values:
        ##   - e2e-az1
        ##   - e2e-az2
        ##
        values: []
      ## @param cluster.worker.common.affinity Affinity for Ray Cluster Worker (common) pods assignment
      ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
      ## NOTE: `server.podAffinityPreset`, `server.podAntiAffinityPreset`, and `server.nodeAffinityPreset` will be ignored when it's set
      ##
      affinity: {}
      ## @param cluster.worker.common.nodeSelector Node labels for Ray Cluster Worker (common) pods assignment
      ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes/
      ##
      nodeSelector: {}
      ## @param cluster.worker.common.tolerations Tolerations for Ray Cluster Worker (common) pods assignment
      ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
      ##
      tolerations: []
      ## @param cluster.worker.common.priorityClassName Ray Cluster Worker (common) pods' priorityClassName
      ##
      priorityClassName: ""
      ## @param cluster.worker.common.topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains. Evaluated as a template
      ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
      ##
      topologySpreadConstraints: []
      ## @param cluster.worker.common.schedulerName Name of the k8s scheduler (other than default) for Ray Cluster Worker (common) pods
      ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
      ##
      schedulerName: ""
      ## @param cluster.worker.common.terminationGracePeriodSeconds Seconds Redmine pod needs to terminate gracefully
      ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods
      ##
      terminationGracePeriodSeconds: ""
      ## @param cluster.worker.common.lifecycleHooks for the Ray Cluster Worker (common) container(s) to automate configuration before or after startup
      ##
      lifecycleHooks: {}
      ## @param cluster.worker.common.extraEnvVars Array with extra environment variables to add to Ray Cluster Worker (common) nodes
      ## e.g:
      ## extraEnvVars:
      ##   - name: FOO
      ##     value: "bar"
      ##
      extraEnvVars: []
      ## @param cluster.worker.common.extraEnvVarsCM Name of existing ConfigMap containing extra env vars for Ray Cluster Worker (common) nodes
      ##
      extraEnvVarsCM: ""
      ## @param cluster.worker.common.extraEnvVarsSecret Name of existing Secret containing extra env vars for Ray Cluster Worker (common) nodes
      ##
      extraEnvVarsSecret: ""
      ## @param cluster.worker.common.extraVolumes Optionally specify extra list of additional volumes for the Ray Cluster Worker (common) pod(s)
      ##
      extraVolumes: []
      ## @param cluster.worker.common.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the Ray Cluster Worker (common) container(s)
      ##
      extraVolumeMounts: []
      ## @param cluster.worker.common.sidecars Add additional sidecar containers to the Ray Cluster Worker (common) pod(s)
      ## e.g:
      ## sidecars:
      ##   - name: your-image-name
      ##     image: your-image
      ##     imagePullPolicy: Always
      ##     ports:
      ##       - name: portname
      ##         containerPort: 1234
      ##
      sidecars: []
      ## @param cluster.worker.common.initContainers Add additional init containers to the Ray Cluster Worker (common) pod(s)
      ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
      ## e.g:
      ## initContainers:
      ##  - name: your-image-name
      ##    image: your-image
      ##    imagePullPolicy: Always
      ##    command: ['sh', '-c', 'echo "hello world"']
      ##
      initContainers: []
    ## @param cluster.worker.groupSpecs [array] Set worker groupspec parameters
    ##
    groupSpecs:
      - groupName: default
  ## ServiceAccount configuration
  ##
  serviceAccount:
    ## @param cluster.serviceAccount.create Specifies whether a ServiceAccount should be created
    ##
    create: true
    ## @param cluster.serviceAccount.name The name of the ServiceAccount to use.
    ## If not set and create is true, a name is generated using the common.names.fullname template
    ##
    name: ""
    ## @param cluster.serviceAccount.annotations Additional Service Account annotations (evaluated as a template)
    ##
    annotations: {}
    ## @param cluster.serviceAccount.automountServiceAccountToken Automount service account token for the server service account
    ##
    automountServiceAccountToken: false

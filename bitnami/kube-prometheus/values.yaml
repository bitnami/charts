## Global Docker image parameters
## Please, note that this will override the image parameters, including dependencies, configured to use the global value
## Current available global Docker image parameters: imageRegistry and imagePullSecrets
##
global:
  #   imageRegistry: myRegistryName
  #   imagePullSecrets:
  #     - myRegistryKeySecretName
  #   storageClass: myStorageClass

  labels: {}
  # foo: bar

## String to partially override prometheus.fullname template (will maintain the release name)
##
# nameOverride:

## String to fully override prometheus.fullname template
##
# fullnameOverride:

## Role Based Access
## ref: https://kubernetes.io/docs/admin/authorization/rbac/
##
rbac:
  create: true

  ## RBAC API version
  ##
  apiVersion: v1beta1

  ## Podsecuritypolicy
  ##
  pspEnabled: true

operator:
  enabled: true

  ## Bitnami Prometheus Operator image version
  ## ref: https://hub.docker.com/r/bitnami/prometheus-operator/tags/
  ##
  image:
    registry: docker.io
    repository: bitnami/prometheus-operator
    tag: 0.46.0-debian-10-r21
    ## Specify a imagePullPolicy
    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
    ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
    ##
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ##
    # pullSecrets:
    #   - myRegistryKeySecretName

  ## Deployment pod host aliases
  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
  ##
  hostAliases: []

  ## Service account for Prometheus Operator to use.
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
  ##
  serviceAccount:
    ## Specifies whether a ServiceAccount should be created
    ##
    create: true
    ## The name of the ServiceAccount to use.
    ## If not set and create is true, a name is generated using the kube-prometheus.operator.fullname template
    # name:

  ## Use an alternate scheduler, e.g. "stork".
  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  # schedulerName:

  ## SecurityContext configuration
  ##
  securityContext:
    enabled: true
    runAsUser: 1001
    fsGroup: 1001

  ## Prometheus Operator Service
  ##
  service:
    ## Kubernetes service type and port number
    ##
    type: ClusterIP
    port: 8080
    # clusterIP: None

    ## Specify the nodePort value for the LoadBalancer and NodePort service types.
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport
    ##
    # nodePort: 30080

    ## Set the LoadBalancer service type to internal only.
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer
    ##
    # loadBalancerIP:

    ## Load Balancer sources
    ## https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
    ##
    # loadBalancerSourceRanges:
    # - 10.10.10.0/24

    ## Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints.
    ## There are two available options: Cluster (default) and Local.
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    externalTrafficPolicy: Cluster

    ## Specifies the health check node port (numeric port number) for the service
    ## if externalTrafficPolicy is set to Local.
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    # healthCheckNodePort:

    ## Provide any additional annotations which may be required.
    ##
    annotations: {}

  ## Create a servicemonitor for the operator
  ##
  serviceMonitor:
    ## Creates a ServiceMonitor to monitor Prometheus Operator
    ##
    enabled: true

    ## Scrape interval. If not set, the Prometheus default scrape interval is used.
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ##
    interval: ""

    ## Metric relabeling
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
    ##
    metricRelabelings: []

    ## Relabel configs
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
    ##
    relabelings: []

  ## Configure resource requests and limits
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  ##
  resources: {}

  ## Pod affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ## Allowed values: soft, hard
  ##
  podAffinityPreset: ""

  ## Pod anti-affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ## Allowed values: soft, hard
  ##
  podAntiAffinityPreset: soft

  ## Node affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ## Allowed values: soft, hard
  ##
  nodeAffinityPreset:
    ## Node affinity type
    ## Allowed values: soft, hard
    ##
    type: ""
    ## Node label key to match
    ## E.g.
    ## key: "kubernetes.io/e2e-az-name"
    ##
    key: ""
    ## Node label values to match
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []

  ## Affinity for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## Note: operator.podAffinityPreset, operator.podAntiAffinityPreset, and operator.nodeAffinityPreset will be ignored when it's set
  ##
  affinity: {}

  ## Node labels for pod assignment
  ## ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}

  ## Tolerations for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []

  ## Priority class assigned to the Pods
  ##
  priorityClassName: ""

  ## Configure extra options for liveness and readiness probes
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes)
  ##
  livenessProbe:
    initialDelaySeconds: 120
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    successThreshold: 1

  readinessProbe:
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    successThreshold: 1

  ## Log level for Prometheus Operator
  ##
  logLevel: info

  ## Log format for Prometheus Operator
  ##
  logFormat: logfmt

  ## Set the prometheus config reloader side-car CPU limit. If unset, uses the prometheus-operator project default
  ##
  # configReloaderCpu: 100m

  ## Set the prometheus config reloader side-car memory limit. If unset, uses the prometheus-operator project default
  ##
  # configReloaderMemory: 25Mi

  ## If true, the operator will create and maintain a service for scraping kubelets
  ##
  kubeletService:
    enabled: true
    namespace: kube-system

  ## Prometheus Configmap-reload image to use for reloading configmaps
  ## defaults to Bitnami Prometheus Operator (ref: https://hub.docker.com/r/bitnami/prometheus-operator/tags/)
  ##
  prometheusConfigReloader:
    image: {}
    # registry:
    # repository:
    # tag:
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ##
    # pullSecrets:
    #   - myRegistryKeySecretName

## Deploy a Prometheus instance
##
prometheus:
  enabled: true

  ## Bitnami Prometheus image version
  ## ref: https://hub.docker.com/r/bitnami/prometheus/tags/
  ##
  image:
    registry: docker.io
    repository: bitnami/prometheus
    tag: 2.25.2-debian-10-r7
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ##
    # pullSecrets:
    #   - myRegistryKeySecretName

  ## Service account for Prometheus to use.
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
  ##
  serviceAccount:
    ## Specifies whether a ServiceAccount should be created
    ##
    create: true
    ## The name of the ServiceAccount to use.
    ## If not set and create is true, a name is generated using the kube-prometheus.prometheus.fullname template
    # name:

    ## Annotations to add to the ServiceAccount (evaluated as a template)
    # annotations:
    #   eks.amazonaws.com/role-arn: arn:aws:iam::ACCOUNT:role/prometheus

  ## SecurityContext configuration
  ##
  securityContext:
    enabled: true
    runAsUser: 1001
    fsGroup: 1001

  ## Configure pod disruption budgets for Prometheus
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/#specifying-a-poddisruptionbudget
  ##
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
    # maxUnavailable:

  ## Prometheus Service
  ##
  service:
    ## Kubernetes service type and port number
    ##
    type: ClusterIP
    port: 9090
    # clusterIP: None

    ## Specify the nodePort value for the LoadBalancer and NodePort service types.
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport
    ##
    # nodePort: 30090

    ## Set the LoadBalancer service type to internal only.
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer
    ##
    # loadBalancerIP:

    ## Load Balancer sources
    ## https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
    ##
    # loadBalancerSourceRanges:
    # - 10.10.10.0/24

    ## Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints.
    ## There are two available options: Cluster (default) and Local.
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    externalTrafficPolicy: Cluster

    ## Specifies the health check node port (numeric port number) for the service
    ## if externalTrafficPolicy is set to Local.
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    # healthCheckNodePort:

    ## Session Affinity
    ## Set stickySessions to true to enable Session Affinity
    # stickySessions: true

    ## Provide any additional annotations which may be required.
    ##
    annotations: {}

  serviceMonitor:
    ## Creates a ServiceMonitor to monitor Prometheus itself
    ##
    enabled: true

    ## Scrape interval. If not set, the Prometheus default scrape interval is used.
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ##
    interval: ""

    ## Metric relabeling
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
    ##
    metricRelabelings: []

    ## Relabel configs
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
    ##
    relabelings: []

  ## Configure the ingress resource that allows you to access the
  ## Alertmanager installation. Set up the URL
  ## ref: http://kubernetes.io/docs/user-guide/ingress/
  ##
  ingress:
    ## Set to true to enable ingress record generation
    ##
    enabled: false

    ## Set this to true in order to add the corresponding annotations for cert-manager
    ##
    certManager: false

    ## Ingress Path type
    ##
    pathType: ImplementationSpecific

    ## Override API Version (automatically detected if not set)
    ##
    apiVersion: ""

    ## When the ingress is enabled, a host pointing to this will be created
    ##
    hostname: prometheus.local

    ## The Path to Prometheus. You may need to set this to '/*' in order to use this
    ## with ALB ingress controllers.
    ##
    path: /

    ## Ingress annotations done as key:value pairs
    ## For a full list of possible ingress annotations, please see
    ## ref: https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/nginx-configuration/annotations.md
    ##
    ## If tls is set to true, annotation ingress.kubernetes.io/secure-backends: "true" will automatically be set
    ## If certManager is set to true, annotation kubernetes.io/tls-acme: "true" will automatically be set
    ##
    annotations: {}
    #  kubernetes.io/ingress.class: nginx

    ## Enable TLS configuration for the hostname defined at prometheus.ingress.hostname parameter
    ## TLS certificates will be retrieved from a TLS secret with name: {{- printf "%s-tls" .Values.prometheus.ingress.hostname }}
    ## You can use the prometheus.ingress.secrets parameter to create this TLS secret or relay on cert-manager to create it
    ##
    tls: false

    ## The list of additional hostnames to be covered with this ingress record.
    ## Most likely the hostname above will be enough, but in the event more hosts are needed, this is an array
    ## extraHosts:
    ## - name: prometheus.local
    ##   path: /
    ##

    ## Any additional arbitrary paths that may need to be added to the ingress under the main host.
    ## For example: The ALB ingress controller requires a special rule for handling SSL redirection.
    ## extraPaths:
    ## - path: /*
    ##   backend:
    ##     serviceName: ssl-redirect
    ##     servicePort: use-annotation
    ##

    ## The tls configuration for additional hostnames to be covered with this ingress record.
    ## see: https://kubernetes.io/docs/concepts/services-networking/ingress/#tls
    ## extraTls:
    ## - hosts:
    ##     - prometheus.local
    ##   secretName: prometheus.local-tls
    ##

    ## If you're providing your own certificates, please use this to add the certificates as secrets
    ## key and certificate should start with -----BEGIN CERTIFICATE----- or
    ## -----BEGIN RSA PRIVATE KEY-----
    ##
    ## name should line up with a tlsSecret set further up
    ## If you're using cert-manager, this is unneeded, as it will create the secret for you if it is not set
    ##
    ## It is also possible to create and manage the certificates outside of this helm chart
    ## Please see README.md for more information
    ##
    secrets: []
    ## - name: prometheus.local-tls
    ##   key:
    ##   certificate:
    ##

  ## If not creating an ingress but still exposing the service some other way (like a proxy)
  ## let Prometheus know what its external URL is so that it can properly create links
  #
  # externalUrl: https://prometheus.example.com

  ## Configure resource requests and limits
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  ##
  resources: {}

  ## Pod affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ## Allowed values: soft, hard
  ##
  podAffinityPreset: ""

  ## Pod anti-affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ## Allowed values: soft, hard
  ##
  podAntiAffinityPreset: soft

  ## Node affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ## Allowed values: soft, hard
  ##
  nodeAffinityPreset:
    ## Node affinity type
    ## Allowed values: soft, hard
    ##
    type: ""
    ## Node label key to match
    ## E.g.
    ## key: "kubernetes.io/e2e-az-name"
    ##
    key: ""
    ## Node label values to match
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []

  ## Affinity for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## Note: prometheus.podAffinityPreset, prometheus.podAntiAffinityPreset, and prometheus.nodeAffinityPreset will be ignored when it's set
  ##
  affinity: {}

  ## Node labels for pod assignment
  ## ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}

  ## Tolerations for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []

  ## Interval between consecutive scrapes.
  ##
  scrapeInterval: ""

  ## Interval between consecutive evaluations.
  ##
  evaluationInterval: ""

  ## ListenLocal makes the Prometheus server listen on loopback, so that it does not bind against the Pod IP.
  ##
  listenLocal: false

  ## Enable Prometheus adminitrative API
  ## ref: https://prometheus.io/docs/prometheus/latest/querying/api/#tsdb-admin-apis
  ##
  enableAdminAPI: false

  ## Alertmanagers to which alerts will be sent
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#alertmanagerendpoints
  ##
  alertingEndpoints: []

  ## External labels to add to any time series or alerts when communicating with external systems
  ##
  externalLabels: {}

  ## Name of the external label used to denote replica name
  ##
  replicaExternalLabelName: ""

  ## If true, the Operator won't add the external label used to denote replica name
  ##
  replicaExternalLabelNameClear: false

  ## Prefix used to register routes, overriding externalUrl route.
  ## Useful for proxies that rewrite URLs.
  ##
  routePrefix: /

  ## Name of the external label used to denote Prometheus instance name
  ##
  prometheusExternalLabelName: ""

  ## If true, the Operator won't add the external label used to denote Prometheus instance name
  ##
  prometheusExternalLabelNameClear: false

  ## Secrets that should be mounted into the Prometheus Pods
  ##
  secrets: []

  ## ConfigMaps that should be mounted into the Prometheus Pods
  ##
  configMaps: []

  ## The query command line flags when starting Prometheus
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#queryspec
  ##
  querySpec: {}

  ## Namespaces to be selected for PrometheusRules discovery
  ## See https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#namespaceselector for usage
  ##
  ruleNamespaceSelector: {}

  ## PrometheusRules to be selected for target discovery.
  ## If {}, select all ServiceMonitors
  ##
  ruleSelector: {}

  ## ServiceMonitors to be selected for target discovery.
  ## If {}, select all ServiceMonitors
  ##
  serviceMonitorSelector: {}
  # matchLabels:
  #   foo: bar

  ## Namespaces to be selected for ServiceMonitor discovery.
  ## See https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#namespaceselector for usage
  ##
  serviceMonitorNamespaceSelector: {}

  ## PodMonitors to be selected for target discovery.
  ## If {}, select all PodMonitors
  ##
  podMonitorSelector: {}

  ## Namespaces to be selected for PodMonitor discovery
  ## See https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#namespaceselector for usage
  ##
  podMonitorNamespaceSelector: {}

  ## Probes to be selected for target discovery.
  ## If {}, select all Probes
  ##
  probeSelector: {}

  ## Namespaces to be selected for Probe discovery
  ## See https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#namespaceselector for usage
  ##
  probeNamespaceSelector: {}

  ## How long to retain metrics
  ##
  retention: 10d

  ## Maximum size of metrics
  ##
  retentionSize: ""

  ## Disable the compaction of the Prometheus TSDB
  ## See https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#prometheusspec
  ## ref: https://prometheus.io/docs/prometheus/latest/storage/#compaction
  ##
  disableCompaction: false

  ## Enable compression of the write-ahead log using Snappy.
  ##
  walCompression: false

  ## If true, the Operator won't process any Prometheus configuration changes
  ##
  paused: false

  ## Desired number of Prometheus nodes
  ##
  replicaCount: 1

  ## Log level for Prometheus
  ##
  logLevel: info

  ## Log format for Prometheus
  ##
  logFormat: logfmt

  ## Standard objectâ€™s metadata
  ## ref: https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#metadata
  ##
  podMetadata:
    labels: {}
    # app: prometheus
    # k8s-app: prometheus
    annotations: {}

  ## The remote_read spec configuration for Prometheus.
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#remotereadspec
  ##
  remoteRead: []
  # - url: http://remote1/read

  ## The remote_write spec configuration for Prometheus.
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#remotewritespec
  ##
  remoteWrite: []
  # - url: http://remote1/push

  ## Prometheus StorageSpec for persistent data
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/user-guides/storage.md
  ##
  storageSpec: {}

  ## Prometheus persistence parameters
  ##
  persistence:
    ## The storageSpec takes precedence before this persistence configuration.
    ## If you want to use this configuration make sure the storageSpec is not provided.
    ##
    enabled: false
    ## Persistent Volume Storage Class
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ## set, choosing the default provisioner.
    ##
    # storageClass: "-"
    ## Persistent Volume Access Mode
    ##
    accessModes:
      - ReadWriteOnce
    ## Persistent Volume Claim size
    ##
    size: 8Gi

  ## Priority class assigned to the Pods
  ##
  priorityClassName: ""

  ## Containers allows injecting additional containers
  ##
  containers: []

  ## Volumes allows configuration of additional volumes
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#prometheusspec
  ##
  volumes: []

  ## VolumeMounts allows configuration of additional VolumeMounts. Evaluated as a template
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#prometheusspec
  ##
  volumeMounts: []

  ## PrometheusRule defines recording and alerting rules for a Prometheus instance.
  ##
  additionalPrometheusRules: []
  # - name: custom-recording-rules
  #   groups:
  #     - name: sum_node_by_job
  #       rules:
  #         - record: job:kube_node_labels:sum
  #           expr: sum(kube_node_labels) by (job)
  #     - name: sum_prometheus_config_reload_by_pod
  #       rules:
  #         - record: job:prometheus_config_last_reload_successful:sum
  #           expr: sum(prometheus_config_last_reload_successful) by (pod)
  # - name: custom-alerting-rules
  #   groups:
  #     - name: prometheus-config
  #       rules:
  #         - alert: PrometheusConfigurationReload
  #           expr: prometheus_config_last_reload_successful > 0
  #           for: 1m
  #           labels:
  #             severity: error
  #           annotations:
  #             summary: "Prometheus configuration reload (instance {{ $labels.instance }})"
  #             description: "Prometheus configuration reload error\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"
  #     - name: custom-node-exporter-alerting-rules
  #       rules:
  #         - alert: PhysicalComponentTooHot
  #           expr: node_hwmon_temp_celsius > 75
  #           for: 5m
  #           labels:
  #             severity: warning
  #           annotations:
  #             summary: "Physical component too hot (instance {{ $labels.instance }})"
  #             description: "Physical hardware component too hot\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"
  #         - alert: NodeOvertemperatureAlarm
  #           expr: node_hwmon_temp_alarm == 1
  #           for: 5m
  #           labels:
  #             severity: critical
  #           annotations:
  #             summary: "Node overtemperature alarm (instance {{ $labels.instance }})"
  #             description: "Physical node temperature alarm triggered\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

  ## Enable additional scrape configs that are managed externally to this chart
  ## Note that the prometheus will fail to provision if the correct secret does not exist.
  ##
  additionalScrapeConfigs:
    enabled: false
    type: external
    external:
      ## Name of the secret that Prometheus should use for the additional scrape configuration
      ##
      name: ""
      ## Name of the key inside the secret to be used for the additional scrape configuration.
      ##
      key: ""
    internal:
      jobList: []

  ## NOTE additionalScrapeConfigsExternal is deprecated. Please see README.md
  ##
  additionalScrapeConfigsExternal:
    enabled: false
    ## Name of the secret that Prometheus should use for the additional scrape configuration
    ##
    # name:
    ## Name of the key inside the secret to be used for the additional scrape configuration.
    ##
    # key:

  ## Enable additional Prometheus alert relabel configs that are managed externally to this chart
  ## Note that the prometheus will fail to provision if the correct secret does not exist.
  ##
  additionalAlertRelabelConfigsExternal:
    enabled: false
    ## Name of the secret that Prometheus should use for the additional alert relabel configuration.
    ##
    # name:
    ## Name of the key inside the secret to be used for the additional alert relabel configuration.
    ##
    # key:

  ## Thanos sidecar container configuration
  ##
  thanos:
    ## Create a Thanos Sidecar container
    ##
    create: false
    ## Bitnami Thanos image
    ## ref: https://hub.docker.com/r/bitnami/thanos/tags/
    ##
    image:
      registry: docker.io
      repository: bitnami/thanos
      tag: 0.18.0-scratch-r5
      ## Specify a imagePullPolicy. Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
      ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
      ##
      pullPolicy: IfNotPresent
      ## Optionally specify an array of imagePullSecrets (secrets must be manually created in the namespace)
      ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
      ##
      # pullSecrets:
      #   - myRegistryKeySecretName


    ## Override default prometheus url "http://localhost:9090"
    ##
    prometheusUrl: ""

    ## Extra arguments passed to thanos sidecar 'args' section
    ##
    extraArgs: []
    # - --log.level=debug
    # - --tsdb.path=/data/

    ## Support mounting a Secret for the objectStorageConfig of the sideCar container.
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/thanos.md
    ##
    objectStorageConfig: {}
    #   secretName: thanos-objstore-config
    #   secretKey: thanos.yaml

    ## Thanos sidecar container resource requests and limits.
    ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
    ##
    resources:
      ## We usually recommend not to specify default resources and to leave this as a conscious
      ## choice for the user. This also increases chances charts run on environments with little
      ## resources, such as Minikube. If you do want to specify resources, uncomment the following
      ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.
      ##
      limits: {}
      #   cpu: 100m
      #   memory: 128Mi
      requests: {}
      #   cpu: 100m
      #   memory: 128Mi

    ## Thanos Sidecar Service
    ##
    service:
      ## Kubernetes service type and port number
      ##
      type: ClusterIP
      port: 10901
      ## Use a "headless" service by default so it returns every pod's IP
      ## instead of loadbalancing requests.
      ##
      clusterIP: None

      ## Specify the nodePort value for the LoadBalancer and NodePort service types.
      ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport
      ##
      # nodePort: 30901

      ## Set the LoadBalancer service type to internal only.
      ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer
      ##
      # loadBalancerIP:

      ## Load Balancer sources
      ## https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
      ##
      # loadBalancerSourceRanges:
      # - 10.10.10.0/24

      ## Provide any additional annotations which may be required.
      ##
      annotations: {}

      ## Extra ports to expose from the Thanos sidecar container
      ##
      # extraPorts:
      #   - name: http
      #     port: 10902
      #     targetPort: http
      #     protocol: TCP
      extraPorts: []

    ## Configure the ingress resource that allows you to access the
    ## Thanos Sidecar installation. Set up the URL
    ## ref: http://kubernetes.io/docs/user-guide/ingress/
    ##
    ingress:
      ## Set to true to enable ingress record generation
      ##
      enabled: false

      ## Set this to true in order to add the corresponding annotations for cert-manager
      ##
      certManager: false

      ## Ingress annotations done as key:value pairs
      ## For a full list of possible ingress annotations, please see
      ## ref: https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/nginx-configuration/annotations.md
      ##
      ## If tls is set to true, annotation ingress.kubernetes.io/secure-backends: "true" will automatically be set
      ## If certManager is set to true, annotation kubernetes.io/tls-acme: "true" will automatically be set
      ##
      annotations: {}
      #  kubernetes.io/ingress.class: nginx
      #  nginx.ingress.kubernetes.io/backend-protocol: "GRPCS"

      ## The list of hostnames to be covered with this ingress record.
      ## Most likely this will be just one host, but in the event more hosts are needed, this is an array
      ##
      hosts:
        - name: thanos.prometheus.local
          path: /

      ## The tls configuration for the ingress
      ## see: https://kubernetes.io/docs/concepts/services-networking/ingress/#tls
      ## tls:
      ## - hosts:
      ##     - thanos.prometheus.local
      ##   secretName: thanos.prometheus.local-tls
      ##
      tls: {}

  ## Port name used for the pods and governing service. This defaults to web
  ##
  portName: web

## Configuration for alertmanager
## ref: https://prometheus.io/docs/alerting/alertmanager/
##
alertmanager:
  enabled: true

  ## Bitnami Alertmanager image version
  ## ref: https://hub.docker.com/r/bitnami/prometheus-operator/tags/
  ##
  image:
    registry: docker.io
    repository: bitnami/alertmanager
    tag: 0.21.0-debian-10-r261
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ##
    # pullSecrets:
    #   - myRegistryKeySecretName

  ## Service account for Alertmanager to use.
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
  ##
  serviceAccount:
    ## Specifies whether a ServiceAccount should be created
    ##
    create: true
    ## The name of the ServiceAccount to use.
    ## If not set and create is true, a name is generated using the kube-prometheus.alertmanager.fullname template
    # name:

  ## SecurityContext configuration
  ##
  securityContext:
    enabled: true
    runAsUser: 1001
    fsGroup: 1001

  ## Configure pod disruption budgets for Alertmanager
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/#specifying-a-poddisruptionbudget
  ##
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
    # maxUnavailable:

  ## Alertmanager Service
  ##
  service:
    ## Kubernetes service type and port number
    ##
    type: ClusterIP
    port: 9093
    # clusterIP: None

    ## Specify the nodePort value for the LoadBalancer and NodePort service types.
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport
    ##
    # nodePort: 30093

    ## Set the LoadBalancer service type to internal only.
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer
    ##
    # loadBalancerIP:

    ## Load Balancer sources
    ## https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
    ##
    # loadBalancerSourceRanges:
    # - 10.10.10.0/24

    ## Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints.
    ## There are two available options: Cluster (default) and Local.
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    externalTrafficPolicy: Cluster

    ## Specifies the health check node port (numeric port number) for the service
    ## if externalTrafficPolicy is set to Local.
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    # healthCheckNodePort:

    ## Session Affinity
    ## Set stickySessions to true to enable Session Affinity
    # stickySessions: true

    ## Provide any additional annotations which may be required.
    ##
    annotations: {}

  ## If true, create a serviceMonitor for alertmanager
  ##
  serviceMonitor:
    ## Creates a ServiceMonitor to monitor Alertmanager
    ##
    enabled: true

    ## Scrape interval. If not set, the Prometheus default scrape interval is used.
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ##
    interval: ""

    ## Metric relabeling
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
    ##
    metricRelabelings: []

    ## Relabel configs
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
    ##
    relabelings: []

  ## Configure the ingress resource that allows you to access the
  ## Alertmanager installation. Set up the URL
  ## ref: http://kubernetes.io/docs/user-guide/ingress/
  ##
  ingress:
    ## Set to true to enable ingress record generation
    enabled: false

    ## Set this to true in order to add the corresponding annotations for cert-manager
    certManager: false

    ## Ingress Path type
    ##
    pathType: ImplementationSpecific

    ## Override API Version (automatically detected if not set)
    ##
    apiVersion:

    ## When the ingress is enabled, a host pointing to this will be created
    ##
    hostname: alertmanager.local

    ## The Path to Alert Manager. You may need to set this to '/*' in order to use this
    ## with ALB ingress controllers.
    ##
    path: /

    ## Ingress annotations done as key:value pairs
    ## For a full list of possible ingress annotations, please see
    ## ref: https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/nginx-configuration/annotations.md
    ##
    ## If tls is set to true, annotation ingress.kubernetes.io/secure-backends: "true" will automatically be set
    ## If certManager is set to true, annotation kubernetes.io/tls-acme: "true" will automatically be set
    ##
    annotations: {}
    #  kubernetes.io/ingress.class: nginx

    ## Enable TLS configuration for the hostname defined at alertmanager.ingress.hostname parameter
    ## TLS certificates will be retrieved from a TLS secret with name: {{- printf "%s-tls" .Values.alertmanager.ingress.hostname }}
    ## You can use the alertmanager.ingress.secrets parameter to create this TLS secret or relay on cert-manager to create it
    ##
    tls: false

    ## The list of additional hostnames to be covered with this ingress record.
    ## Most likely the hostname above will be enough, but in the event more hosts are needed, this is an array
    ## extraHosts:
    ## - name: alertmanager.local
    ##   path: /
    ##

    ## Any additional arbitrary paths that may need to be added to the ingress under the main host.
    ## For example: The ALB ingress controller requires a special rule for handling SSL redirection.
    ## extraPaths:
    ## - path: /*
    ##   backend:
    ##     serviceName: ssl-redirect
    ##     servicePort: use-annotation
    ##

    ## The tls configuration for additional hostnames to be covered with this ingress record.
    ## see: https://kubernetes.io/docs/concepts/services-networking/ingress/#tls
    ## extraTls:
    ## - hosts:
    ##     - alertmanager.local
    ##   secretName: alertmanager.local-tls
    ##

    ## If you're providing your own certificates, please use this to add the certificates as secrets
    ## key and certificate should start with -----BEGIN CERTIFICATE----- or
    ## -----BEGIN RSA PRIVATE KEY-----
    ##
    ## name should line up with a tlsSecret set further up
    ## If you're using cert-manager, this is unneeded, as it will create the secret for you if it is not set
    ##
    ## It is also possible to create and manage the certificates outside of this helm chart
    ## Please see README.md for more information
    ##
    secrets: []
    ## - name: alertmanager.local-tls
    ##   key:
    ##   certificate:
    ##

  ## If not creating an ingress but still exposing the service some other way (like a proxy)
  ## let Alertmanager know what its external URL is so that it can properly create links
  #
  # externalUrl: https://alertmanager.example.com

  ## Configure resource requests and limits
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  ##
  resources: {}

  ## Pod affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ## Allowed values: soft, hard
  ##
  podAffinityPreset: ""

  ## Pod anti-affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ## Allowed values: soft, hard
  ##
  podAntiAffinityPreset: soft

  ## Node affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ## Allowed values: soft, hard
  ##
  nodeAffinityPreset:
    ## Node affinity type
    ## Allowed values: soft, hard
    ##
    type: ""
    ## Node label key to match
    ## E.g.
    ## key: "kubernetes.io/e2e-az-name"
    ##
    key: ""
    ## Node label values to match
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []

  ## Affinity for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## Note: alertmanager.podAffinityPreset, alertmanager.podAntiAffinityPreset, and alertmanager.nodeAffinityPreset will be ignored when it's set
  ##
  affinity: {}

  ## Node labels for pod assignment
  ## ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}

  ## Tolerations for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []

  ## Alertmanager configuration
  ## ref: https://prometheus.io/docs/alerting/configuration/#configuration-file
  ##
  config:
    global:
      resolve_timeout: 5m
    route:
      group_by: ['job']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 12h
      receiver: 'null'
      routes:
        - match:
            alertname: Watchdog
          receiver: 'null'
    receivers:
      - name: 'null'

  ## Alertmanager configuration is created externally
  ## If true, `alertmanager.config` is ignored, and a secret will not be created.
  ##
  ## Alertmanager requires a secret named `alertmanager-{{ template "kube-prometheus.alertmanager.fullname" . }}`
  ## It must contain:
  ##     alertmanager.yaml: <config>
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/user-guides/alerting.md#alerting
  ##
  externalConfig: false

  ## Desired number of Alertmanager nodes
  ##
  replicaCount: 1

  ## Log level for Alertmanager
  ##
  logLevel: info

  ## Log format for Alertmanager
  ##
  logFormat: logfmt

  ## Standard object's metadata.
  ## ref: https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#metadata
  ##
  podMetadata:
    labels: {}
    annotations: {}

  ## Secrets that should be mounted into the Alertmanager Pods
  ##
  secrets: []

  ## ConfigMaps that should be mounted into the Alertmanager Pods
  ##
  configMaps: []

  ## Metrics retention
  ##
  retention: 120h

  ## Alertmanager StorageSpec for persistent data
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/user-guides/storage.md
  ##
  storageSpec: {}

  ## Alertmanager persistence parameters
  ##
  persistence:
    ## The storageSpec takes precedence before this persistence configuration.
    ## If you want to use this configuration make sure the storageSpec is not provided.
    ##
    enabled: false
    ## Persistent Volume Storage Class
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ## set, choosing the default provisioner.
    ##
    # storageClass: "-"
    ## Persistent Volume Access Mode
    ##
    accessModes:
      - ReadWriteOnce
    ## Persistent Volume Claim size
    ##
    size: 8Gi

  ## If true, the Operator won't process any Alertmanager configuration changes
  ##
  paused: false

  ## ListenLocal makes the Alertmanager server listen on loopbac
  ##
  listenLocal: false

  ## Containers allows injecting additional containers
  ##
  containers: []

  ## Volumes allows configuration of additional volumes. Evaluated as a template
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#alertmanagerspec
  ##
  volumes: []

  ## VolumeMounts allows configuration of additional VolumeMounts. Evaluated as a template
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/pi.md#alertmanagerspec
  ##
  volumeMounts: []

  ## Priority class assigned to the Pods
  ##
  priorityClassName: ""

  ## AdditionalPeers allows injecting a set of additional Alertmanagers to peer with to form a highly available cluster.
  ##
  additionalPeers: []

  ## Prefix used to register routes, overriding externalUrl route.
  ## Useful for proxies that rewrite URLs.
  ##
  routePrefix: /

  ## Port name used for the pods and governing service. This defaults to web
  ##
  portName: web

## Exporters
##
exporters:
  node-exporter:
    ## Enable node-exporter
    ##
    enabled: true

  kube-state-metrics:
    ## Enable kube-state-metrics
    ##
    enabled: true

## Node Exporter deployment configuration
##
node-exporter:
  service:
    labels:
      jobLabel: node-exporter

  serviceMonitor:
    enabled: true
    jobLabel: jobLabel

  extraArgs:
    collector.filesystem.ignored-mount-points: "^/(dev|proc|sys|var/lib/docker/.+)($|/)"
    collector.filesystem.ignored-fs-types: "^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$"

kube-state-metrics:
  serviceMonitor:
    enabled: true

## Component scraping the kube-apiserver
##
kubeApiServer:
  ## Create a ServiceMonitor to scrape kube-apiserver service
  ##
  enabled: true

  serviceMonitor:
    ## Scrape interval. If not set, the Prometheus default scrape interval is used.
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ##
    interval: ""

    ## Metric relabeling
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
    ##
    metricRelabelings: []

    ## Relabel configs
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
    ##
    relabelings: []

## Component scraping the kube-controller-manager
##
kubeControllerManager:
  ## Create a ServiceMonitor to scrape kube-controller-manager service
  ##
  enabled: true

  ## If your kube controller manager is not deployed as a pod, specify IPs it can be found on
  ##
  endpoints: []
  # - 10.141.4.22
  # - 10.141.4.23
  # - 10.141.4.24

  ## Namespace where kube-controller-manager service is deployed
  ##
  namespace: kube-system

  ## Service ports and selector information
  ##
  service:
    enabled: true
    port: 10252
    targetPort: 10252
    # selector:
    #   component: kube-controller-manager

  serviceMonitor:
    ## Scrape interval. If not set, the Prometheus default scrape interval is used.
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ##
    interval: ""

    ## Enable scraping kube-controller-manager over https.
    ## Requires proper certs (not self-signed) and delegated authentication/authorization checks
    ##
    https: false

    # Skip TLS certificate validation when scraping
    insecureSkipVerify: null

    # Name of the server to use when validating TLS certificate
    serverName: null

    ## Metric relabeling
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
    ##
    metricRelabelings: []

    ## Relabel configs
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
    ##
    relabelings: []

## Component scraping kube scheduler
##
kubeScheduler:
  ## Create a ServiceMonitor to scrape kube-scheduler service
  ##
  enabled: true

  ## If your kube scheduler is not deployed as a pod, specify IPs it can be found on
  ##
  endpoints: []
  # - 10.141.4.22
  # - 10.141.4.23
  # - 10.141.4.24

  ## Namespace where kube-scheduler service is deployed
  ##
  namespace: kube-system

  ## If using kubeScheduler.endpoints only the port and targetPort are used
  ##
  service:
    enabled: true
    port: 10251
    targetPort: 10251
    # selector:
    #   component: kube-scheduler

  serviceMonitor:
    ## Scrape interval. If not set, the Prometheus default scrape interval is used.
    ##
    interval: ""
    ## Enable scraping kube-scheduler over https.
    ## Requires proper certs (not self-signed) and delegated authentication/authorization checks
    ##
    https: false

    ## Skip TLS certificate validation when scraping
    ##
    insecureSkipVerify: null

    ## Name of the server to use when validating TLS certificate
    ##
    serverName: null

    ##  metric relabel configs to apply to samples before ingestion.
    ##
    metricRelabelings: []
    # - action: keep
    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'
    #   sourceLabels: [__name__]

    #   relabel configs to apply to samples before ingestion.
    ##
    relabelings: []
    # - sourceLabels: [__meta_kubernetes_pod_node_name]
    #   separator: ;
    #   regex: ^(.*)$
    #   targetLabel: nodename
    #   replacement: $1
    #   action: replace

## Component scraping coreDns
##
coreDns:
  enabled: true

  ## Namespace where coreDns service is deployed
  ##
  namespace: kube-system

  ## Create a ServiceMonitor to scrape coredns service
  ##
  service:
    enabled: true
    port: 9153
    targetPort: 9153
    # selector:
    #   k8s-app: kube-dns

  serviceMonitor:
    ## Scrape interval. If not set, the Prometheus default scrape interval is used.
    ##
    interval: ""

    ##  metric relabel configs to apply to samples before ingestion.
    ##
    metricRelabelings: []
    # - action: keep
    #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'
    #   sourceLabels: [__name__]

    #   relabel configs to apply to samples before ingestion.
    ##
    relabelings: []
    # - sourceLabels: [__meta_kubernetes_pod_node_name]
    #   separator: ;
    #   regex: ^(.*)$
    #   targetLabel: nodename
    #   replacement: $1
    #   action: replace

## Component scraping the kube-proxy
##
kubeProxy:
  ## Create a ServiceMonitor to scrape kube-proxy service
  ##
  enabled: true

  ## If your kube-proxy is not deployed as a pod, specify IPs it can be found on
  ##
  endpoints: []
  # - 10.141.4.22
  # - 10.141.4.23
  # - 10.141.4.24

  ## Namespace where kube-proxy service is deployed
  ##
  namespace: kube-system

  ## Service ports and selector information
  ##
  service:
    enabled: true
    port: 10249
    targetPort: 10249
    # selector:
    #   k8s-app: kube-proxy

  serviceMonitor:
    ## Enable scraping kube-proxy over https.
    ## Requires proper certs (not self-signed) and delegated authentication/authorization checks
    ##
    https: false

    ## Scrape interval. If not set, the Prometheus default scrape interval is used.
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ##
    interval: ""

    ## Metric relabeling
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
    ##
    metricRelabelings: []

    ## Relabel configs
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
    ##
    relabelings: []

# Component scraping for kubelet and kubelet hosted cAdvisor
kubelet:
  ## Create a ServiceMonitor to scrape kubelet service
  ##
  enabled: true

  ## Namespace where kubelet service is deployed
  ##
  namespace: kube-system

  serviceMonitor:
    ## Scrape kubelet over https
    ##
    https: true

    ## Scrape interval. If not set, the Prometheus default scrape interval is used.
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ##
    interval: ""

    ## Metric relabeling
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
    ##
    metricRelabelings: []

    ## Relabel configs
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
    ##
    relabelings: []

    ## Metric relabeling for scraping cAdvisor
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
    ##
    cAdvisorMetricRelabelings: []

    ## Relabel configs for scraping cAdvisor
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
    ##
    cAdvisorRelabelings: []

## @section Global parameters
## Global Docker image parameters
## Please, note that this will override the image parameters, including dependencies, configured to use the global value
## Current available global Docker image parameters: imageRegistry, imagePullSecrets and storageClass

## @param global.imageRegistry Global Docker image registry
## @param global.imagePullSecrets Global Docker registry secret names as an array
## @param global.storageClass Global StorageClass for Persistent Volume(s)
## @param global.labels Additional labels to apply to all resources
##
global:
  imageRegistry:
  ## E.g.
  ## imagePullSecrets:
  ##   - myRegistryKeySecretName
  ##
  imagePullSecrets: []
  storageClass:
  labels: {}

## @section Common parameters

## @param nameOverride String to partially override `kube-prometheus.name` template with a string (will prepend the release name)
##
nameOverride:
## @param fullnameOverride String to fully override `kube-prometheus.fullname` template with a string
##
fullnameOverride:

## @section Prometheus Operator Parameters

operator:
  ## @param operator.enabled Deploy Prometheus Operator to the cluster
  ##
  enabled: true
  ## Bitnami Prometheus Operator image version
  ## ref: https://hub.docker.com/r/bitnami/prometheus-operator/tags/
  ## @param operator.image.registry Prometheus Operator image registry
  ## @param operator.image.repository Prometheus Operator image repository
  ## @param operator.image.tag Prometheus Operator Image tag (immutable tags are recommended)
  ## @param operator.image.pullPolicy Prometheus Operator image pull policy
  ## @param operator.image.pullSecrets Specify docker-registry secret names as an array
  ##
  image:
    registry: docker.io
    repository: bitnami/prometheus-operator
    tag: 0.48.1-debian-10-r25
    ## Specify a imagePullPolicy
    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
    ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
    ##
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ## Example:
    ## pullSecrets:
    ##   - myRegistryKeySecretName
    ##
    pullSecrets: []
  ## @param operator.hostAliases Add deployment host aliases
  ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/
  ##
  hostAliases: []
  ## Service account for Prometheus Operator to use.
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
  ##
  serviceAccount:
    ## @param operator.serviceAccount.create Specify whether to create a ServiceAccount for Prometheus Operator
    ##
    create: true
    ## @param operator.serviceAccount.name The name of the ServiceAccount to create
    ## If not set and create is true, a name is generated using the kube-prometheus.operator.fullname template
    name:
  ## @param operator.schedulerName Name of the Kubernetess scheduler (other than default)
  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  schedulerName:
  ## Prometheus Operator pods' Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param operator.podSecurityContext.enabled Enable pod security context
  ## @param operator.podSecurityContext.runAsUser User ID for the container
  ## @param operator.podSecurityContext.fsGroup Group ID for the container filesystem
  ##
  podSecurityContext:
    enabled: true
    runAsUser: 1001
    fsGroup: 1001
  ## Prometheus Operator containers' Security Context (only main container)
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
  ## @param operator.containerSecurityContext.enabled Enable container security context
  ## @param operator.containerSecurityContext.capabilities.drop [array] Linux Kernel capabilities which should be dropped
  ## @param operator.containerSecurityContext.runAsNonRoot Force the container to run as a non root user
  ## @param operator.containerSecurityContext.allowPrivilegeEscalation Switch privilegeEscalation possibility on or off
  ## @param operator.containerSecurityContext.readOnlyRootFilesystem Mount / (root) as a readonly filesystem
  ##
  containerSecurityContext:
    enabled: true
    capabilities:
      drop:
      - ALL
    runAsNonRoot: true
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: false
  ## Prometheus Operator Service
  ##
  service:
    ## @param operator.service.type Kubernetes service type
    ##
    type: ClusterIP
    ## @param operator.service.port Prometheus Operator service port
    ##
    port: 8080
    ## @param operator.service.clusterIP Specific cluster IP when service type is cluster IP. Use `None` for headless service
    ## e.g:
    ## clusterIP: None
    ##
    clusterIP:
    ## @param operator.service.nodePort Kubernetes Service nodePort
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport
    ## e.g:
    ## nodePort: 30080
    ##
    nodePort:
    ## @param operator.service.loadBalancerIP `loadBalancerIP` if service type is `LoadBalancer`
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer
    ##
    loadBalancerIP:
    ## @param operator.service.loadBalancerSourceRanges Address that are allowed when svc is `LoadBalancer`
    ## Set the LoadBalancer service type to internal only
    ## https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
    ## e.g:
    ## loadBalancerSourceRanges:
    ## - 10.10.10.0/24
    ##
    loadBalancerSourceRanges: []
    ## @param operator.service.externalTrafficPolicy Enable client source IP preservation
    ## Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints
    ## There are two available options: Cluster (default) and Local.
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    externalTrafficPolicy: Cluster
    ## @param operator.service.healthCheckNodePort Specifies the health check node port (numeric port number) for the service if `externalTrafficPolicy` is set to Local.
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    healthCheckNodePort:
    ## @param operator.service.annotations Additional annotations for Prometheus Operator service
    ##
    annotations: {}
  ## Create a servicemonitor for the operator
  ##
  serviceMonitor:
    ## @param operator.serviceMonitor.enabled Creates a ServiceMonitor to monitor Prometheus Operator
    ##
    enabled: true
    ## @param operator.serviceMonitor.interval Scrape interval (use by default, falling back to Prometheus' default)
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ##
    interval: ""
    ## @param operator.serviceMonitor.metricRelabelings Metric relabeling
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
    ##
    metricRelabelings: []
    ## @param operator.serviceMonitor.relabelings Relabel configs
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
    ##
    relabelings: []
  ## @param operator.resources Configure resource requests and limits
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  ##
  resources: {}
  ## @param operator.podAffinityPreset Pod affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAffinityPreset: ""
  ## @param operator.podAntiAffinityPreset Prometheus Operator Pod anti-affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAntiAffinityPreset: soft
  ## Node affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ##
  nodeAffinityPreset:
    ## @param operator.nodeAffinityPreset.type Prometheus Operator Node affinity preset type. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
    ##
    type: ""
    ## @param operator.nodeAffinityPreset.key Prometheus Operator Node label key to match Ignored if `affinity` is set.
    ## E.g.
    ## key: "kubernetes.io/e2e-az-name"
    ##
    key: ""
    ## @param operator.nodeAffinityPreset.values Prometheus Operator Node label values to match. Ignored if `affinity` is set.
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []
  ## @param operator.affinity Prometheus Operator Affinity for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## Note: operator.podAffinityPreset, operator.podAntiAffinityPreset, and operator.nodeAffinityPreset will be ignored when it's set
  ##
  affinity: {}
  ## @param operator.nodeSelector Prometheus Operator Node labels for pod assignment
  ## ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}
  ## @param operator.tolerations Prometheus Operator Tolerations for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  ## @param operator.priorityClassName Priority class assigned to the Pods
  ##
  priorityClassName: ""
  ## Configure extra options for liveness probe
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
  ## @param operator.livenessProbe.enabled Turn on and off liveness probe
  ## @param operator.livenessProbe.path Path of the HTTP service for checking the healthy state
  ## @param operator.livenessProbe.initialDelaySeconds Delay before liveness probe is initiated
  ## @param operator.livenessProbe.periodSeconds How often to perform the probe
  ## @param operator.livenessProbe.timeoutSeconds When the probe times out
  ## @param operator.livenessProbe.failureThreshold Minimum consecutive failures for the probe
  ## @param operator.livenessProbe.successThreshold Minimum consecutive successes for the probe
  ##
  livenessProbe:
    enabled: true
    path: /metrics
    initialDelaySeconds: 120
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    successThreshold: 1
  ## Configure extra options for readiness probe
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
  ## @param operator.readinessProbe.enabled Turn on and off readiness probe
  ## @param operator.readinessProbe.path Path of the HTTP service for checking the ready state
  ## @param operator.readinessProbe.initialDelaySeconds Delay before readiness probe is initiated
  ## @param operator.readinessProbe.periodSeconds How often to perform the probe
  ## @param operator.readinessProbe.timeoutSeconds When the probe times out
  ## @param operator.readinessProbe.failureThreshold Minimum consecutive failures for the probe
  ## @param operator.readinessProbe.successThreshold Minimum consecutive successes for the probe
  ##
  readinessProbe:
    enabled: true
    path: /metrics
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    successThreshold: 1
  ## @param operator.logLevel Log level for Prometheus Operator
  ##
  logLevel: info
  ## @param operator.logFormat Log format for Prometheus Operator
  ##
  logFormat: logfmt
  ## @param operator.configReloaderResources Set the prometheus config reloader side-car CPU and memory requests and limits.
  ## configReloaderResources:
  ##   limits:
  ##     cpu: 200m
  ##     memory: 100Mi
  ##   requests:
  ##     cpu: 100m
  ##     memory: 50Mi
  ##
  configReloaderResources: {}
  ## @param operator.kubeletService.enabled If true, the operator will create and maintain a service for scraping kubelets
  ## @param operator.kubeletService.namespace Namespace to deploy the kubelet service
  ##
  kubeletService:
    enabled: true
    namespace: kube-system
  ## Prometheus Configmap-reload image to use for reloading configmaps
  ## defaults to Bitnami Prometheus Operator (ref: https://hub.docker.com/r/bitnami/prometheus-operator/tags/)
  ##
  prometheusConfigReloader:
    ## @param operator.prometheusConfigReloader.image Prometheus Config Reloader image. If not set, the same as `operator.image.registry`
    ## registry:
    ## repository:
    ## tag:
    ## pullSecrets:
    ##
    image: {}
    ## Prometheus config reload container's securityContext
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
    ## @param operator.prometheusConfigReloader.containerSecurityContext.enabled Enable container security context
    ## @param operator.prometheusConfigReloader.containerSecurityContext.readOnlyRootFilesystem mount / (root) as a readonly filesystem
    ## @param operator.prometheusConfigReloader.containerSecurityContext.allowPrivilegeEscalation Switch privilegeEscalation possibility on or off
    ## @param operator.prometheusConfigReloader.containerSecurityContext.runAsNonRoot Force the container to run as a non root user
    ## @param operator.prometheusConfigReloader.containerSecurityContext.capabilities.drop [array] Linux Kernel capabilities which should be dropped
    ##
    containerSecurityContext:
      enabled: true
      readOnlyRootFilesystem: false
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      capabilities:
        drop:
          - ALL
    ## Configure extra options for liveness probe
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
    ## @param operator.prometheusConfigReloader.livenessProbe.enabled Turn on and off liveness probe
    ## @param operator.prometheusConfigReloader.livenessProbe.initialDelaySeconds Delay before liveness probe is initiated
    ## @param operator.prometheusConfigReloader.livenessProbe.periodSeconds How often to perform the probe
    ## @param operator.prometheusConfigReloader.livenessProbe.timeoutSeconds When the probe times out
    ## @param operator.prometheusConfigReloader.livenessProbe.failureThreshold Minimum consecutive failures for the probe
    ## @param operator.prometheusConfigReloader.livenessProbe.successThreshold Minimum consecutive successes for the probe
    ##
    livenessProbe:
      enabled: true
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 6
      successThreshold: 1
    ## Configure extra options for readiness probe
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
    ## @param operator.prometheusConfigReloader.readinessProbe.enabled Turn on and off readiness probe
    ## @param operator.prometheusConfigReloader.readinessProbe.initialDelaySeconds Delay before readiness probe is initiated
    ## @param operator.prometheusConfigReloader.readinessProbe.periodSeconds How often to perform the probe
    ## @param operator.prometheusConfigReloader.readinessProbe.timeoutSeconds When the probe times out
    ## @param operator.prometheusConfigReloader.readinessProbe.failureThreshold Minimum consecutive failures for the probe
    ## @param operator.prometheusConfigReloader.readinessProbe.successThreshold Minimum consecutive successes for the probe
    ##
    readinessProbe:
      enabled: true
      initialDelaySeconds: 15
      periodSeconds: 20
      timeoutSeconds: 5
      failureThreshold: 6
      successThreshold: 1

## @section Prometheus Parameters

## Deploy a Prometheus instance
##
prometheus:
  ## @param prometheus.enabled Deploy Prometheus to the cluster
  ##
  enabled: true
  ## Bitnami Prometheus image version
  ## ref: https://hub.docker.com/r/bitnami/prometheus/tags/
  ## @param prometheus.image.registry Prometheus image registry
  ## @param prometheus.image.repository Prometheus image repository
  ## @param prometheus.image.tag Prometheus Image tag (immutable tags are recommended)
  ## @param prometheus.image.pullSecrets Specify docker-registry secret names as an array
  ##
  image:
    registry: docker.io
    repository: bitnami/prometheus
    tag: 2.28.1-debian-10-r3
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ## Example:
    ## pullSecrets:
    ##   - myRegistryKeySecretName
    ##
    pullSecrets: []
  ## Service account for Prometheus to use.
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
  ##
  serviceAccount:
    ## @param prometheus.serviceAccount.create Specify whether to create a ServiceAccount for Prometheus
    ##
    create: true
    ## @param prometheus.serviceAccount.name The name of the ServiceAccount to create
    ## If not set and create is true, a name is generated using the kube-prometheus.prometheus.fullname template
    name:
    ## @param prometheus.serviceAccount.annotations Additional annotations for created Prometheus ServiceAccount
    ## annotations:
    ##   eks.amazonaws.com/role-arn: arn:aws:iam::ACCOUNT:role/prometheus
    ##
    annotations: {}
  ## Prometheus pods' Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param prometheus.podSecurityContext.enabled Enable security context
  ## @param prometheus.podSecurityContext.runAsUser User ID for the container
  ## @param prometheus.podSecurityContext.fsGroup Group ID for the container filesystem
  ##
  podSecurityContext:
    enabled: true
    runAsUser: 1001
    fsGroup: 1001
  ## Prometheus containers' Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
  ## @param prometheus.containerSecurityContext.enabled Enable container security context
  ## @param prometheus.containerSecurityContext.readOnlyRootFilesystem Mount / (root) as a readonly filesystem
  ## @param prometheus.containerSecurityContext.allowPrivilegeEscalation Switch privilegeEscalation possibility on or off
  ## @param prometheus.containerSecurityContext.runAsNonRoot Force the container to run as a non root user
  ## @param prometheus.containerSecurityContext.capabilities.drop [array] Linux Kernel capabilities which should be dropped
  ##
  containerSecurityContext:
    enabled: true
    readOnlyRootFilesystem: false
    allowPrivilegeEscalation: false
    runAsNonRoot: true
    capabilities:
      drop:
        - ALL
  ## Configure pod disruption budgets for Prometheus
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/#specifying-a-poddisruptionbudget
  ## @param prometheus.podDisruptionBudget.enabled Create a pod disruption budget for Prometheus
  ## @param prometheus.podDisruptionBudget.minAvailable Minimum number / percentage of pods that should remain scheduled
  ## @param prometheus.podDisruptionBudget.maxUnavailable Maximum number / percentage of pods that may be made unavailable
  ##
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
    maxUnavailable:
  ## Prometheus Service
  ##
  service:
    ## @param prometheus.service.type Kubernetes service type
    ##
    type: ClusterIP
    ## @param prometheus.service.port Prometheus service port
    ##
    port: 9090
    ## @param prometheus.service.clusterIP Specific cluster IP when service type is cluster IP. Use `None` for headless service
    ## e.g: clusterIP: None
    ##
    clusterIP:
    ## @param prometheus.service.nodePort Specify the nodePort value for the LoadBalancer and NodePort service types.
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport
    ## e.g:
    ## nodePort: 30090
    ##
    nodePort:
    ## @param prometheus.service.loadBalancerIP `loadBalancerIP` if service type is `LoadBalancer`
    ## Set the LoadBalancer service type to internal only
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer
    ##
    loadBalancerIP:
    ## @param prometheus.service.loadBalancerSourceRanges Address that are allowed when service is `LoadBalancer`
    ## https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
    ##
    ## loadBalancerSourceRanges:
    ## - 10.10.10.0/24
    ##
    loadBalancerSourceRanges: []
    ## @param prometheus.service.externalTrafficPolicy Enable client source IP preservation
    ## Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints
    ## There are two available options: Cluster (default) and Local
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    externalTrafficPolicy: Cluster
    ## @param prometheus.service.healthCheckNodePort Specifies the health check node port
    ## if externalTrafficPolicy is set to Local.
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    healthCheckNodePort:
    ## @param prometheus.service.stickySessions Set stickySessions to `true` to enable Session Affinity
    ##
    stickySessions:
    ## @param prometheus.service.annotations Additional annotations for Prometheus service  (this value is evaluated as a template)
    ##
    annotations: {}
  serviceMonitor:
    ## @param prometheus.serviceMonitor.enabled Creates a ServiceMonitor to monitor Prometheus itself
    ##
    enabled: true
    ## @param prometheus.serviceMonitor.interval Scrape interval (use by default, falling back to Prometheus' default)
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ##
    interval: ""
    ## @param prometheus.serviceMonitor.metricRelabelings Metric relabeling
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
    ##
    metricRelabelings: []
    ## @param prometheus.serviceMonitor.relabelings Relabel configs
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
    ##
    relabelings: []
  ## Configure the ingress resource that allows you to access the
  ## Alertmanager installation. Set up the URL
  ## ref: http://kubernetes.io/docs/user-guide/ingress/
  ##
  ingress:
    ## @param prometheus.ingress.enabled Enable ingress controller resource
    ##
    enabled: false
    ## @param prometheus.ingress.certManager Add annotations for cert-manager
    ##
    certManager: false
    ## @param prometheus.ingress.pathType Ingress Path type
    ##
    pathType: ImplementationSpecific
    ## @param prometheus.ingress.apiVersion Override API Version (automatically detected if not set)
    ##
    apiVersion: ""
    ## @param prometheus.ingress.hostname Default host for the ingress resource
    ##
    hostname: prometheus.local
    ## @param prometheus.ingress.path The Path to Prometheus. You may need to set this to '/*' in order to use this with ALB ingress controllers
    ##
    path: /
    ## @param prometheus.ingress.annotations Ingress annotations
    ## For a full list of possible ingress annotations, please see
    ## ref: https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/nginx-configuration/annotations.md
    ##
    ## If tls is set to true, annotation ingress.kubernetes.io/secure-backends: "true" will automatically be set
    ## If certManager is set to true, annotation kubernetes.io/tls-acme: "true" will automatically be set
    ## e.g:
    ## annotations:
    ##  kubernetes.io/ingress.class: nginx
    ##
    annotations: {}
    ## @param prometheus.ingress.tls Enable TLS configuration for the hostname defined at prometheus.ingress.hostname parameter
    ## TLS certificates will be retrieved from a TLS secret with name: {{- printf "%s-tls" .Values.prometheus.ingress.hostname }}
    ## You can use the prometheus.ingress.secrets parameter to create this TLS secret or relay on cert-manager to create it
    ##
    tls: false
    ## @param prometheus.ingress.extraHosts The list of additional hostnames to be covered with this ingress record.
    ## Most likely the hostname above will be enough, but in the event more hosts are needed, this is an array
    ## extraHosts:
    ## - name: prometheus.local
    ##   path: /
    ##
    extraHosts: []
    ## @param prometheus.ingress.extraPaths Additional arbitrary path/backend objects
    ## For example: The ALB ingress controller requires a special rule for handling SSL redirection.
    ## extraPaths:
    ## - path: /*
    ##   backend:
    ##     serviceName: ssl-redirect
    ##     servicePort: use-annotation
    ##
    extraPaths: []
    ## @param prometheus.ingress.extraTls The tls configuration for additional hostnames to be covered with this ingress record.
    ## see: https://kubernetes.io/docs/concepts/services-networking/ingress/#tls
    ## extraTls:
    ## - hosts:
    ##     - prometheus.local
    ##   secretName: prometheus.local-tls
    ##
    extraTls: []
    ## @param prometheus.ingress.secrets If you're providing your own certificates, please use this to add the certificates as secrets
    ## key and certificate should start with -----BEGIN CERTIFICATE----- or
    ## -----BEGIN RSA PRIVATE KEY-----
    ##
    ## name should line up with a tlsSecret set further up
    ## If you're using cert-manager, this is unneeded, as it will create the secret for you if it is not set
    ##
    ## It is also possible to create and manage the certificates outside of this helm chart
    ## Please see README.md for more information
    ## e.g:
    ## secrets:
    ## - name: prometheus.local-tls
    ##   key:
    ##   certificate:
    ##
    secrets: []
  ## @param prometheus.externalUrl External URL used to access Prometheus
  ## If not creating an ingress but still exposing the service some other way (like a proxy)
  ## let Prometheus know what its external URL is so that it can properly create links
  ## externalUrl: https://prometheus.example.com
  ##
  externalUrl:
  ## @param prometheus.resources CPU/Memory resource requests/limits for node
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  ##
  resources: {}
  ## @param prometheus.podAffinityPreset Prometheus Pod affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAffinityPreset: ""
  ## @param prometheus.podAntiAffinityPreset Prometheus Pod anti-affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAntiAffinityPreset: soft
  ## Node affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ##
  nodeAffinityPreset:
    ## @param prometheus.nodeAffinityPreset.type Prometheus Node affinity preset type. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
    ##
    type: ""
    ## @param prometheus.nodeAffinityPreset.key Prometheus Node label key to match Ignored if `affinity` is set.
    ## E.g.
    ## key: "kubernetes.io/e2e-az-name"
    ##
    key: ""
    ## @param prometheus.nodeAffinityPreset.values Prometheus Node label values to match. Ignored if `affinity` is set.
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []
  ## @param prometheus.affinity Prometheus Affinity for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## Note: prometheus.podAffinityPreset, prometheus.podAntiAffinityPreset, and prometheus.nodeAffinityPreset will be ignored when it's set
  ##
  affinity: {}
  ## @param prometheus.nodeSelector Prometheus Node labels for pod assignment
  ## ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}
  ## @param prometheus.tolerations Prometheus Tolerations for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  ## @param prometheus.scrapeInterval Interval between consecutive scrapes
  ##
  scrapeInterval: ""
  ## @param prometheus.evaluationInterval Interval between consecutive evaluations
  ##
  evaluationInterval: ""
  ## @param prometheus.listenLocal ListenLocal makes the Prometheus server listen on loopback
  ##
  listenLocal: false
  ## Configure extra options for liveness probe
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
  ## @param prometheus.livenessProbe.enabled Turn on and off liveness probe
  ## @param prometheus.livenessProbe.path Path of the HTTP service for checking the healthy state
  ## @param prometheus.livenessProbe.initialDelaySeconds Delay before liveness probe is initiated
  ## @param prometheus.livenessProbe.periodSeconds How often to perform the probe
  ## @param prometheus.livenessProbe.timeoutSeconds When the probe times out
  ## @param prometheus.livenessProbe.failureThreshold Minimum consecutive failures for the probe
  ## @param prometheus.livenessProbe.successThreshold Minimum consecutive successes for the probe
  ##
  livenessProbe:
    enabled: true
    path: /-/healthy
    initialDelaySeconds: 0
    failureThreshold: 10
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 3
  ## Configure extra options for readiness probe
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
  ## @param prometheus.readinessProbe.enabled Turn on and off readiness probe
  ## @param prometheus.readinessProbe.path Path of the HTTP service for checking the ready state
  ## @param prometheus.readinessProbe.initialDelaySeconds Delay before readiness probe is initiated
  ## @param prometheus.readinessProbe.periodSeconds How often to perform the probe
  ## @param prometheus.readinessProbe.timeoutSeconds When the probe times out
  ## @param prometheus.readinessProbe.failureThreshold Minimum consecutive failures for the probe
  ## @param prometheus.readinessProbe.successThreshold Minimum consecutive successes for the probe
  ##
  readinessProbe:
    enabled: true
    path: /-/ready
    initialDelaySeconds: 0
    failureThreshold: 10
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 3
  ## @param prometheus.enableAdminAPI Enable Prometheus adminitrative API
  ## ref: https://prometheus.io/docs/prometheus/latest/querying/api/#tsdb-admin-apis
  ##
  enableAdminAPI: false
  ## @param prometheus.alertingEndpoints Alertmanagers to which alerts will be sent
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#alertmanagerendpoints
  ##
  alertingEndpoints: []
  ## @param prometheus.externalLabels External labels to add to any time series or alerts when communicating with external systems
  ##
  externalLabels: {}
  ## @param prometheus.replicaExternalLabelName Name of the external label used to denote replica name
  ##
  replicaExternalLabelName: ""
  ## @param prometheus.replicaExternalLabelNameClear Clear external label used to denote replica name
  ##
  replicaExternalLabelNameClear: false
  ## @param prometheus.routePrefix Prefix used to register routes, overriding externalUrl route
  ## Useful for proxies that rewrite URLs.
  ##
  routePrefix: /
  ## @param prometheus.prometheusExternalLabelName Name of the external label used to denote Prometheus instance name
  ##
  prometheusExternalLabelName: ""
  ## @param prometheus.prometheusExternalLabelNameClear Clear external label used to denote Prometheus instance name
  ##
  prometheusExternalLabelNameClear: false
  ## @param prometheus.secrets Secrets that should be mounted into the Prometheus Pods
  ##
  secrets: []
  ## @param prometheus.configMaps ConfigMaps that should be mounted into the Prometheus Pods
  ##
  configMaps: []
  ## @param prometheus.querySpec The query command line flags when starting Prometheus
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#queryspec
  ##
  querySpec: {}
  ## @param prometheus.ruleNamespaceSelector Namespaces to be selected for PrometheusRules discovery
  ## See https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#namespaceselector for usage
  ##
  ruleNamespaceSelector: {}
  ## @param prometheus.ruleSelector PrometheusRules to be selected for target discovery
  ## If {}, select all ServiceMonitors
  ##
  ruleSelector: {}
  ## @param prometheus.serviceMonitorSelector ServiceMonitors to be selected for target discovery
  ## If {}, select all ServiceMonitors
  ##
  serviceMonitorSelector: {}
  ## @param prometheus.matchLabels Matchlabels
  ##
  matchLabels: {}
  ## @param prometheus.serviceMonitorNamespaceSelector Namespaces to be selected for ServiceMonitor discovery
  ## See https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#namespaceselector for usage
  ##
  serviceMonitorNamespaceSelector: {}
  ## @param prometheus.podMonitorSelector PodMonitors to be selected for target discovery.
  ## If {}, select all PodMonitors
  ##
  podMonitorSelector: {}
  ## @param prometheus.podMonitorNamespaceSelector Namespaces to be selected for PodMonitor discovery
  ## See https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#namespaceselector for usage
  ##
  podMonitorNamespaceSelector: {}
  ## @param prometheus.probeSelector Probes to be selected for target discovery.
  ## If {}, select all Probes
  ##
  probeSelector: {}
  ## @param prometheus.probeNamespaceSelector Namespaces to be selected for Probe discovery
  ## See https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#namespaceselector for usage
  ##
  probeNamespaceSelector: {}
  ## @param prometheus.retention Metrics retention days
  ##
  retention: 10d
  ## @param prometheus.retentionSize Maximum size of metrics
  ##
  retentionSize: ""
  ## @param prometheus.disableCompaction Disable the compaction of the Prometheus TSDB
  ## See https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#prometheusspec
  ## ref: https://prometheus.io/docs/prometheus/latest/storage/#compaction
  ##
  disableCompaction: false
  ## @param prometheus.walCompression Enable compression of the write-ahead log using Snappy
  ##
  walCompression: false
  ## @param prometheus.paused If true, the Operator won't process any Prometheus configuration changes
  ##
  paused: false
  ## @param prometheus.replicaCount Number of Prometheus replicas desired
  ##
  replicaCount: 1
  ## @param prometheus.logLevel Log level for Prometheus
  ##
  logLevel: info
  ## @param prometheus.logFormat Log format for Prometheus
  ##
  logFormat: logfmt
  ## @param prometheus.podMetadata [object] Standard object's metadata
  ## ref: https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#metadata
  ##
  podMetadata:
    ## labels:
    ##   app: prometheus
    ##   k8s-app: prometheus
    ##
    labels: {}
    annotations: {}
  ## @param prometheus.remoteRead The remote_read spec configuration for Prometheus
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#remotereadspec
  ## remoteRead:
  ## - url: http://remote1/read
  ##
  remoteRead: []
  ## @param prometheus.remoteWrite The remote_write spec configuration for Prometheus
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#remotewritespec
  ## remoteWrite:
  ## - url: http://remote1/push
  ##
  remoteWrite: []
  ## @param prometheus.storageSpec Prometheus StorageSpec for persistent data
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/user-guides/storage.md
  ##
  storageSpec: {}
  ## Prometheus persistence parameters
  ##
  persistence:
    ## @param prometheus.persistence.enabled Use PVCs to persist data. If the storageSpec is provided this will not take effect.
    ##
    enabled: false
    ## @param prometheus.persistence.storageClass Persistent Volume Storage Class
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ## set, choosing the default provisioner.
    ##
    storageClass:
    ## @param prometheus.persistence.accessModes Persistent Volume Access Modes
    ##
    accessModes:
      - ReadWriteOnce
    ## @param prometheus.persistence.size Persistent Volume Size
    ##
    size: 8Gi
  ## @param prometheus.priorityClassName Priority class assigned to the Pods
  ##
  priorityClassName: ""
  ## @param prometheus.containers Containers allows injecting additional containers
  ##
  containers: []
  ## @param prometheus.volumes Volumes allows configuration of additional volumes
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#prometheusspec
  ##
  volumes: []
  ## @param prometheus.volumeMounts VolumeMounts allows configuration of additional VolumeMounts. Evaluated as a template
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#prometheusspec
  ##
  volumeMounts: []
  ## @param prometheus.additionalPrometheusRules PrometheusRule defines recording and alerting rules for a Prometheus instance.
  ## - name: custom-recording-rules
  ##   groups:
  ##     - name: sum_node_by_job
  ##       rules:
  ##         - record: job:kube_node_labels:sum
  ##           expr: sum(kube_node_labels) by (job)
  ##     - name: sum_prometheus_config_reload_by_pod
  ##       rules:
  ##         - record: job:prometheus_config_last_reload_successful:sum
  ##           expr: sum(prometheus_config_last_reload_successful) by (pod)
  ## - name: custom-alerting-rules
  ##   groups:
  ##     - name: prometheus-config
  ##       rules:
  ##         - alert: PrometheusConfigurationReload
  ##           expr: prometheus_config_last_reload_successful > 0
  ##           for: 1m
  ##           labels:
  ##             severity: error
  ##           annotations:
  ##             summary: "Prometheus configuration reload (instance {{ $labels.instance }})"
  ##             description: "Prometheus configuration reload error\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"
  ##     - name: custom-node-exporter-alerting-rules
  ##       rules:
  ##         - alert: PhysicalComponentTooHot
  ##           expr: node_hwmon_temp_celsius > 75
  ##           for: 5m
  ##           labels:
  ##             severity: warning
  ##           annotations:
  ##             summary: "Physical component too hot (instance {{ $labels.instance }})"
  ##             description: "Physical hardware component too hot\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"
  ##         - alert: NodeOvertemperatureAlarm
  ##           expr: node_hwmon_temp_alarm == 1
  ##           for: 5m
  ##           labels:
  ##             severity: critical
  ##           annotations:
  ##             summary: "Node overtemperature alarm (instance {{ $labels.instance }})"
  ##             description: "Physical node temperature alarm triggered\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"
  ##
  additionalPrometheusRules: []
  ## Note that the prometheus will fail to provision if the correct secret does not exist.
  ## @param prometheus.additionalScrapeConfigs.enabled Enable additional scrape configs
  ## @param prometheus.additionalScrapeConfigs.type Indicates if the cart should use external additional scrape configs or internal configs
  ## @param prometheus.additionalScrapeConfigs.external.name Name of the secret that Prometheus should use for the additional external scrape configuration
  ## @param prometheus.additionalScrapeConfigs.external.key Name of the key inside the secret to be used for the additional external scrape configuration
  ## @param prometheus.additionalScrapeConfigs.internal.jobList A list of Prometheus scrape jobs
  ##
  additionalScrapeConfigs:
    enabled: false
    type: external
    external:
      ## Name of the secret that Prometheus should use for the additional scrape configuration
      ##
      name: ""
      ## Name of the key inside the secret to be used for the additional scrape configuration.
      ##
      key: ""
    internal:
      jobList: []
  ## @param prometheus.additionalScrapeConfigsExternal.enabled Deprecated: Enable additional scrape configs that are managed externally to this chart
  ## @param prometheus.additionalScrapeConfigsExternal.name Deprecated: Name of the secret that Prometheus should use for the additional scrape configuration
  ## @param prometheus.additionalScrapeConfigsExternal.key Deprecated: Name of the key inside the secret to be used for the additional scrape configuration
  ##
  additionalScrapeConfigsExternal:
    enabled: false
    name:
    key:
  ## Enable additional Prometheus alert relabel configs that are managed externally to this chart
  ## Note that the prometheus will fail to provision if the correct secret does not exist.
  ## @param prometheus.additionalAlertRelabelConfigsExternal.enabled Enable additional Prometheus alert relabel configs that are managed externally to this chart
  ## @param prometheus.additionalAlertRelabelConfigsExternal.name Name of the secret that Prometheus should use for the additional Prometheus alert relabel configuration
  ## @param prometheus.additionalAlertRelabelConfigsExternal.key Name of the key inside the secret to be used for the additional Prometheus alert relabel configuration
  ##
  additionalAlertRelabelConfigsExternal:
    enabled: false
    name:
    key:
  ## Thanos sidecar container configuration
  ##
  thanos:
    ## @param prometheus.thanos.create Create a Thanos sidecar container
    ##
    create: false
    ## Bitnami Thanos image
    ## ref: https://hub.docker.com/r/bitnami/thanos/tags/
    ## @param prometheus.thanos.image.registry Thanos image registry
    ## @param prometheus.thanos.image.repository Thanos image name
    ## @param prometheus.thanos.image.tag Thanos image tag
    ## @param prometheus.thanos.image.pullPolicy Thanos image pull policy
    ## @param prometheus.thanos.image.pullSecrets Specify docker-registry secret names as an array
    ##
    image:
      registry: docker.io
      repository: bitnami/thanos
      tag: 0.21.1-scratch-r1
      ## Specify a imagePullPolicy. Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
      ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images
      ##
      pullPolicy: IfNotPresent
      ## Optionally specify an array of imagePullSecrets.
      ## Secrets must be manually created in the namespace.
      ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
      ## Example:
      ## pullSecrets:
      ##   - myRegistryKeySecretName
      ##
      pullSecrets: []
    ## Thanos Sidecar container's securityContext
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
    ## @param prometheus.thanos.containerSecurityContext.enabled Enable container security context
    ## @param prometheus.thanos.containerSecurityContext.readOnlyRootFilesystem mount / (root) as a readonly filesystem
    ## @param prometheus.thanos.containerSecurityContext.allowPrivilegeEscalation Switch privilegeEscalation possibility on or off
    ## @param prometheus.thanos.containerSecurityContext.runAsNonRoot Force the container to run as a non root user
    ## @param prometheus.thanos.containerSecurityContext.capabilities.drop [array] Linux Kernel capabilities which should be dropped
    ##
    containerSecurityContext:
      enabled: true
      readOnlyRootFilesystem: false
      allowPrivilegeEscalation: false
      runAsNonRoot: true
      capabilities:
        drop:
          - ALL
    ## @param prometheus.thanos.prometheusUrl Override default prometheus url "http://localhost:9090"
    ##
    prometheusUrl: ""
    ## @param prometheus.thanos.extraArgs Additional arguments passed to the thanos sidecar container
    ## extraArgs:
    ## - --log.level=debug
    ## - --tsdb.path=/data/
    ##
    extraArgs: []
    ## @param prometheus.thanos.objectStorageConfig Support mounting a Secret for the objectStorageConfig of the sideCar container.
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/thanos.md
    ## objectStorageConfig:
    ##    secretName: thanos-objstore-config
    ##    secretKey: thanos.yaml
    ##
    objectStorageConfig: {}
    ## Thanos sidecar container resource requests and limits.
    ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
    ## We usually recommend not to specify default resources and to leave this as a conscious
    ## choice for the user. This also increases chances charts run on environments with little
    ## resources, such as Minikube. If you do want to specify resources, uncomment the following
    ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    ## @param prometheus.thanos.resources.limits The resources limits for the Thanos sidecar container
    ## @param prometheus.thanos.resources.requests The resources requests for the Thanos sidecar container
    ##
    resources:
      ## Example:
      ## limits:
      ##    cpu: 100m
      ##    memory: 128Mi
      limits: {}
      ## Examples:
      ## requests:
      ##    cpu: 100m
      ##    memory: 128Mi
      requests: {}
    ## Configure extra options for liveness probe
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
    ## @param prometheus.thanos.livenessProbe.enabled Turn on and off liveness probe
    ## @param prometheus.thanos.livenessProbe.path Path of the HTTP service for checking the healthy state
    ## @param prometheus.thanos.livenessProbe.initialDelaySeconds Delay before liveness probe is initiated
    ## @param prometheus.thanos.livenessProbe.periodSeconds How often to perform the probe
    ## @param prometheus.thanos.livenessProbe.timeoutSeconds When the probe times out
    ## @param prometheus.thanos.livenessProbe.failureThreshold Minimum consecutive failures for the probe
    ## @param prometheus.thanos.livenessProbe.successThreshold Minimum consecutive successes for the probe
    ##
    livenessProbe:
      enabled: true
      path: /-/healthy
      initialDelaySeconds: 0
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 120
      successThreshold: 1
    ## Configure extra options for readiness probe
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
    ## @param prometheus.thanos.readinessProbe.enabled Turn on and off readiness probe
    ## @param prometheus.thanos.readinessProbe.path Path of the HTTP service for checking the ready state
    ## @param prometheus.thanos.readinessProbe.initialDelaySeconds Delay before readiness probe is initiated
    ## @param prometheus.thanos.readinessProbe.periodSeconds How often to perform the probe
    ## @param prometheus.thanos.readinessProbe.timeoutSeconds When the probe times out
    ## @param prometheus.thanos.readinessProbe.failureThreshold Minimum consecutive failures for the probe
    ## @param prometheus.thanos.readinessProbe.successThreshold Minimum consecutive successes for the probe
    ##
    readinessProbe:
      enabled: true
      path: /-/ready
      initialDelaySeconds: 0
      periodSeconds: 5
      timeoutSeconds: 3
      failureThreshold: 120
      successThreshold: 1
    ## Thanos Sidecar Service
    ##
    service:
      ## @param prometheus.thanos.service.type Kubernetes service type
      ##
      type: ClusterIP
      ## @param prometheus.thanos.service.port Thanos service port
      ##
      port: 10901
      ## @param prometheus.thanos.service.clusterIP Specific cluster IP when service type is cluster IP. Use `None` to create headless service by default.
      ## Use a "headless" service by default so it returns every pod's IP instead of loadbalancing requests.
      ##
      clusterIP: None
      ## @param prometheus.thanos.service.nodePort Specify the nodePort value for the LoadBalancer and NodePort service types.
      ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport
      ## e.g:
      ## nodePort: 30901
      ##
      nodePort:
      ## @param prometheus.thanos.service.loadBalancerIP `loadBalancerIP` if service type is `LoadBalancer`
      ## Set the LoadBalancer service type to internal only
      ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer
      ##
      loadBalancerIP:
      ## @param prometheus.thanos.service.loadBalancerSourceRanges Address that are allowed when svc is `LoadBalancer`
      ## https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
      ## e.g:
      ## loadBalancerSourceRanges:
      ## - 10.10.10.0/24
      ##
      loadBalancerSourceRanges:
      ## @param prometheus.thanos.service.annotations Additional annotations for Prometheus service
      ##
      annotations: {}
      ## @param prometheus.thanos.service.extraPorts Additional ports to expose from the Thanos sidecar container
      ## extraPorts:
      ##   - name: http
      ##     port: 10902
      ##     targetPort: http
      ##     protocol: TCP
      ##
      extraPorts: []
    ## Configure the ingress resource that allows you to access the
    ## Thanos Sidecar installation. Set up the URL
    ## ref: http://kubernetes.io/docs/user-guide/ingress/
    ##
    ingress:
      ## @param prometheus.thanos.ingress.enabled Enable ingress controller resource
      ##
      enabled: false
      ## @param prometheus.thanos.ingress.certManager Add annotations for cert-manager
      ##
      certManager: false
      ## @param prometheus.thanos.ingress.annotations Ingress annotations
      ## For a full list of possible ingress annotations, please see
      ## ref: https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/nginx-configuration/annotations.md
      ##
      ## If tls is set to true, annotation ingress.kubernetes.io/secure-backends: "true" will automatically be set
      ## If certManager is set to true, annotation kubernetes.io/tls-acme: "true" will automatically be set
      ## annotations:
      ##    kubernetes.io/ingress.class: nginx
      ##    nginx.ingress.kubernetes.io/backend-protocol: "GRPCS"
      ##
      annotations: {}
      ## @param prometheus.thanos.ingress.hosts [array] The list of hostnames to be covered with this ingress record.
      ## Most likely this will be just one host, but in the event more hosts are needed, this is an array
      ##
      hosts:
        - name: thanos.prometheus.local
          path: /
      ## @param prometheus.thanos.ingress.tls The tls configuration for the ingress
      ## see: https://kubernetes.io/docs/concepts/services-networking/ingress/#tls
      ## tls:
      ## - hosts:
      ##     - thanos.prometheus.local
      ##   secretName: thanos.prometheus.local-tls
      ##
      tls: {}
  ## @param prometheus.portName Port name used for the pods and governing service. This defaults to web
  ##
  portName: web

## @section Alertmanager Parameters

## Configuration for alertmanager
## ref: https://prometheus.io/docs/alerting/alertmanager/
##
alertmanager:
  ## @param alertmanager.enabled Deploy Alertmanager to the cluster
  ##
  enabled: true
  ## Bitnami Alertmanager image version
  ## ref: https://hub.docker.com/r/bitnami/prometheus-operator/tags/
  ## @param alertmanager.image.registry Prometheus image registry
  ## @param alertmanager.image.repository Prometheus Image repository
  ## @param alertmanager.image.tag Prometheus Image tag (immutable tags are recommended)
  ## @param alertmanager.image.pullSecrets Specify docker-registry secret names as an array
  ##
  image:
    registry: docker.io
    repository: bitnami/alertmanager
    tag: 0.22.2-debian-10-r27
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ## Example:
    ## pullSecrets:
    ##   - myRegistryKeySecretName
    ##
    pullSecrets: []
  ## Service account for Alertmanager to use.
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
  ##
  serviceAccount:
    ## @param alertmanager.serviceAccount.create Specify whether to create a ServiceAccount for Alertmanager
    ##
    create: true
    ## @param alertmanager.serviceAccount.name The name of the ServiceAccount to create
    ## If not set and create is true, a name is generated using the kube-prometheus.alertmanager.fullname template
    name:
  ## Prometheus Alertmanager pods' Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param alertmanager.podSecurityContext.enabled Enable security context
  ## @param alertmanager.podSecurityContext.runAsUser User ID for the container
  ## @param alertmanager.podSecurityContext.fsGroup Group ID for the container filesystem
  ##
  podSecurityContext:
    enabled: true
    runAsUser: 1001
    fsGroup: 1001
  ## Prometheus Alertmanager container's securityContext
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
  ## @param alertmanager.containerSecurityContext.enabled Enable container security context
  ## @param alertmanager.containerSecurityContext.readOnlyRootFilesystem mount / (root) as a readonly filesystem
  ## @param alertmanager.containerSecurityContext.allowPrivilegeEscalation Switch privilegeEscalation possibility on or off
  ## @param alertmanager.containerSecurityContext.runAsNonRoot Force the container to run as a non root user
  ## @param alertmanager.containerSecurityContext.capabilities.drop [array] Linux Kernel capabilities which should be dropped
  ##
  containerSecurityContext:
    enabled: true
    readOnlyRootFilesystem: false
    allowPrivilegeEscalation: false
    runAsNonRoot: true
    capabilities:
      drop:
        - ALL
  ## Configure pod disruption budgets for Alertmanager
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/#specifying-a-poddisruptionbudget
  ## @param alertmanager.podDisruptionBudget.enabled Create a pod disruption budget for Alertmanager
  ## @param alertmanager.podDisruptionBudget.minAvailable Minimum number / percentage of pods that should remain scheduled
  ## @param alertmanager.podDisruptionBudget.maxUnavailable Maximum number / percentage of pods that may be made unavailable
  ##
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
    maxUnavailable:
  ## Alertmanager Service
  ##
  service:
    ## @param alertmanager.service.type Kubernetes service type
    ##
    type: ClusterIP
    ## @param alertmanager.service.port Alertmanager service port
    ##
    port: 9093
    ## @param alertmanager.service.clusterIP Specific cluster IP when service type is cluster IP. Use `None` for headless service
    ## e.g:
    ## clusterIP: None
    ##
    clusterIP:
    ## @param alertmanager.service.nodePort Specify the nodePort value for the LoadBalancer and NodePort service types.
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport
    ## e.g:
    ## nodePort: 30903
    ##
    nodePort:
    ## @param alertmanager.service.loadBalancerIP `loadBalancerIP` if service type is `LoadBalancer`
    ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer
    ##
    loadBalancerIP:
    ## @param alertmanager.service.loadBalancerSourceRanges Address that are allowed when svc is `LoadBalancer`
    ## https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
    ## e.g:
    ## loadBalancerSourceRanges:
    ## - 10.10.10.0/24
    ##
    loadBalancerSourceRanges: []
    ## @param alertmanager.service.externalTrafficPolicy Enable client source IP preservation
    ## Denotes if this Service desires to route external traffic to node-local or cluster-wide endpoints
    ## There are two available options: Cluster (default) and Local.
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    externalTrafficPolicy: Cluster
    ## @param alertmanager.service.healthCheckNodePort Specifies the health check node port
    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip
    ##
    healthCheckNodePort:
    ## @param alertmanager.service.stickySessions Set stickySessions to `true` to enable Session Affinity
    ##
    stickySessions:
    ## @param alertmanager.service.annotations Additional annotations for Alertmanager service (this value is evaluated as a template)
    ##
    annotations: {}
  ## If true, create a serviceMonitor for alertmanager
  ##
  serviceMonitor:
    ## @param alertmanager.serviceMonitor.enabled Creates a ServiceMonitor to monitor Alertmanager
    ##
    enabled: true
    ## @param alertmanager.serviceMonitor.interval Scrape interval. If not set, the Prometheus default scrape interval is used.
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ##
    interval: ""
    ## @param alertmanager.serviceMonitor.metricRelabelings Metric relabeling
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
    ##
    metricRelabelings: []
    ## @param alertmanager.serviceMonitor.relabelings Relabel configs
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
    ##
    relabelings: []
  ## Configure the ingress resource that allows you to access the
  ## Alertmanager installation. Set up the URL
  ## ref: http://kubernetes.io/docs/user-guide/ingress/
  ##
  ingress:
    ## @param alertmanager.ingress.enabled Enable ingress controller resource
    ##
    enabled: false
    ## @param alertmanager.ingress.certManager Add annotations for cert-manager
    ##
    certManager: false
    ## @param alertmanager.ingress.pathType Ingress Path type
    ##
    pathType: ImplementationSpecific
    ## @param alertmanager.ingress.apiVersion Override API Version (automatically detected if not set)
    ##
    apiVersion:
    ## @param alertmanager.ingress.hostname Default host for the ingress resource
    ##
    hostname: alertmanager.local
    ## @param alertmanager.ingress.path The Path to Alert Manager. You may need to set this to '/*' in order to use this with ALB ingress controllers.
    ##
    path: /
    ## @param alertmanager.ingress.annotations Ingress annotations
    ## For a full list of possible ingress annotations, please see
    ## ref: https://github.com/kubernetes/ingress-nginx/blob/master/docs/user-guide/nginx-configuration/annotations.md
    ##
    ## If tls is set to true, annotation ingress.kubernetes.io/secure-backends: "true" will automatically be set
    ## If certManager is set to true, annotation kubernetes.io/tls-acme: "true" will automatically be set
    ## annotations:
    ##    kubernetes.io/ingress.class: nginx
    ##
    annotations: {}
    ## @param alertmanager.ingress.tls Enable TLS configuration for the hostname defined at alertmanager.ingress.hostname parameter
    ## TLS certificates will be retrieved from a TLS secret with name: {{- printf "%s-tls" .Values.alertmanager.ingress.hostname }}
    ## You can use the alertmanager.ingress.secrets parameter to create this TLS secret or relay on cert-manager to create it
    ##
    tls: false
    ## @param alertmanager.ingress.extraHosts The list of additional hostnames to be covered with this ingress record.
    ## Most likely the hostname above will be enough, but in the event more hosts are needed, this is an array
    ## extraHosts:
    ## - name: alertmanager.local
    ##   path: /
    ##
    extraHosts: []
    ## @param alertmanager.ingress.extraPaths Additional arbitrary path/backend objects
    ## For example: The ALB ingress controller requires a special rule for handling SSL redirection.
    ## extraPaths:
    ## - path: /*
    ##   backend:
    ##     serviceName: ssl-redirect
    ##     servicePort: use-annotation
    ##
    extraPaths: []
    ## @param alertmanager.ingress.extraTls The tls configuration for additional hostnames to be covered with this ingress record.
    ## see: https://kubernetes.io/docs/concepts/services-networking/ingress/#tls
    ## extraTls:
    ## - hosts:
    ##     - alertmanager.local
    ##   secretName: alertmanager.local-tls
    ##
    extraTls: []
    ## @param alertmanager.ingress.secrets If you're providing your own certificates, please use this to add the certificates as secrets
    ## key and certificate should start with -----BEGIN CERTIFICATE----- or
    ## -----BEGIN RSA PRIVATE KEY-----
    ##
    ## name should line up with a tlsSecret set further up
    ## If you're using cert-manager, this is unneeded, as it will create the secret for you if it is not set
    ##
    ## It is also possible to create and manage the certificates outside of this helm chart
    ## Please see README.md for more information
    ## secrets:
    ## - name: alertmanager.local-tls
    ##   key:
    ##   certificate:
    ##
    secrets: []
  ## @param alertmanager.externalUrl External URL used to access Alertmanager
  ## e.g:
  ## externalUrl: https://alertmanager.example.com
  ##
  externalUrl:
  ## @param alertmanager.resources CPU/Memory resource requests/limits for node
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  ##
  resources: {}
  ## @param alertmanager.podAffinityPreset Alertmanager Pod affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAffinityPreset: ""
  ## @param alertmanager.podAntiAffinityPreset Alertmanager Pod anti-affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAntiAffinityPreset: soft
  ## Node affinity preset
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ##
  nodeAffinityPreset:
    ## @param alertmanager.nodeAffinityPreset.type Alertmanager Node affinity preset type. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
    ##
    type: ""
    ## @param alertmanager.nodeAffinityPreset.key Alertmanager Node label key to match Ignored if `affinity` is set.
    ## E.g.
    ## key: "kubernetes.io/e2e-az-name"
    ##
    key: ""
    ## @param alertmanager.nodeAffinityPreset.values Alertmanager Node label values to match. Ignored if `affinity` is set.
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []
  ## @param alertmanager.affinity Alertmanager Affinity for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## Note: alertmanager.podAffinityPreset, alertmanager.podAntiAffinityPreset, and alertmanager.nodeAffinityPreset will be ignored when it's set
  ##
  affinity: {}
  ## @param alertmanager.nodeSelector Alertmanager Node labels for pod assignment
  ## ref: https://kubernetes.io/docs/user-guide/node-selection/
  ##
  nodeSelector: {}
  ## @param alertmanager.tolerations Alertmanager Tolerations for pod assignment
  ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  ## Alertmanager configuration
  ## ref: https://prometheus.io/docs/alerting/configuration/#configuration-file
  ## @param alertmanager.config [object] Alertmanager configuration directive
  ## @skip alertmanager.config.route.group_by
  ## @skip alertmanager.config.route.routes
  ## @skip alertmanager.config.receivers
  ##
  config:
    global:
      resolve_timeout: 5m
    route:
      group_by: ['job']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 12h
      receiver: 'null'
      routes:
        - match:
            alertname: Watchdog
          receiver: 'null'
    receivers:
      - name: 'null'
  ## @param alertmanager.externalConfig Alertmanager configuration is created externally. If true, `alertmanager.config` is ignored, and a secret will not be created.
  ## Alertmanager requires a secret named `alertmanager-{{ template "kube-prometheus.alertmanager.fullname" . }}`
  ## It must contain:
  ##     alertmanager.yaml: <config>
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/user-guides/alerting.md#alerting
  ##
  externalConfig: false
  ## @param alertmanager.replicaCount Number of Alertmanager replicas desired
  ##
  replicaCount: 1
  ## Configure extra options for liveness probe
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
  ## @param alertmanager.livenessProbe.enabled Turn on and off liveness probe
  ## @param alertmanager.livenessProbe.path Path of the HTTP service for checking the healthy state
  ## @param alertmanager.livenessProbe.initialDelaySeconds Delay before liveness probe is initiated
  ## @param alertmanager.livenessProbe.periodSeconds How often to perform the probe
  ## @param alertmanager.livenessProbe.timeoutSeconds When the probe times out
  ## @param alertmanager.livenessProbe.failureThreshold Minimum consecutive failures for the probe
  ## @param alertmanager.livenessProbe.successThreshold Minimum consecutive successes for the probe
  ##
  livenessProbe:
    enabled: true
    path: /-/healthy
    initialDelaySeconds: 0
    periodSeconds: 5
    timeoutSeconds: 3
    failureThreshold: 120
    successThreshold: 1
  ## Configure extra options for readiness probe
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#configure-probes
  ## @param alertmanager.readinessProbe.enabled Turn on and off readiness probe
  ## @param alertmanager.readinessProbe.path Path of the HTTP service for checking the ready state
  ## @param alertmanager.readinessProbe.initialDelaySeconds Delay before readiness probe is initiated
  ## @param alertmanager.readinessProbe.periodSeconds How often to perform the probe
  ## @param alertmanager.readinessProbe.timeoutSeconds When the probe times out
  ## @param alertmanager.readinessProbe.failureThreshold Minimum consecutive failures for the probe
  ## @param alertmanager.readinessProbe.successThreshold Minimum consecutive successes for the probe
  ##
  readinessProbe:
    enabled: true
    path: /-/ready
    initialDelaySeconds: 0
    periodSeconds: 5
    timeoutSeconds: 3
    failureThreshold: 120
    successThreshold: 1
  ## @param alertmanager.logLevel Log level for Alertmanager
  ##
  logLevel: info
  ## @param alertmanager.logFormat Log format for Alertmanager
  ##
  logFormat: logfmt
  ## @param alertmanager.podMetadata [object] Standard object's metadata.
  ## ref: https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#metadata
  ##
  podMetadata:
    labels: {}
    annotations: {}
  ## @param alertmanager.secrets Secrets that should be mounted into the Alertmanager Pods
  ##
  secrets: []
  ## @param alertmanager.configMaps ConfigMaps that should be mounted into the Alertmanager Pods
  ##
  configMaps: []
  ## @param alertmanager.retention Metrics retention days
  ##
  retention: 120h
  ## @param alertmanager.storageSpec Alertmanager StorageSpec for persistent data
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/user-guides/storage.md
  ##
  storageSpec: {}
  ## Alertmanager persistence parameters
  ##
  persistence:
    ## @param alertmanager.persistence.enabled Use PVCs to persist data. If the storageSpec is provided this will not take effect.
    ## If you want to use this configuration make sure the storageSpec is not provided.
    ##
    enabled: false
    ## @param alertmanager.persistence.storageClass Persistent Volume Storage Class
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ## set, choosing the default provisioner.
    ##
    storageClass:
    ## @param alertmanager.persistence.accessModes Persistent Volume Access Modes
    ##
    accessModes:
      - ReadWriteOnce
    ## @param alertmanager.persistence.size Persistent Volume Size
    ##
    size: 8Gi
  ## @param alertmanager.paused If true, the Operator won't process any Alertmanager configuration changes
  ##
  paused: false
  ## @param alertmanager.listenLocal ListenLocal makes the Alertmanager server listen on loopback
  ##
  listenLocal: false
  ## @param alertmanager.containers Containers allows injecting additional containers
  ##
  containers: []
  ## @param alertmanager.volumes Volumes allows configuration of additional volumes. Evaluated as a template
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#alertmanagerspec
  ##
  volumes: []
  ## @param alertmanager.volumeMounts VolumeMounts allows configuration of additional VolumeMounts. Evaluated as a template
  ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/pi.md#alertmanagerspec
  ##
  volumeMounts: []
  ## @param alertmanager.priorityClassName Priority class assigned to the Pods
  ##
  priorityClassName: ""
  ## @param alertmanager.additionalPeers AdditionalPeers allows injecting a set of additional Alertmanagers to peer with to form a highly available cluster
  ##
  additionalPeers: []
  ## @param alertmanager.routePrefix Prefix used to register routes, overriding externalUrl route
  ## Useful for proxies that rewrite URLs.
  ##
  routePrefix: /
  ## @param alertmanager.portName Port name used for the pods and governing service. This defaults to web
  ##
  portName: web
  ## @param alertmanager.configNamespaceSelector AlertmanagerConfigs to be selected for to merge and configure Alertmanager with. This defaults to {}
  ##
  configNamespaceSelector: {}
  ## @param alertmanager.configSelector Namespaces to be selected for AlertmanagerConfig discovery. If nil, only check own namespace. This defaults to {}
  ##
  configSelector: {}

## @section Exporters

## Exporters
##
exporters:
  node-exporter:
    ## @param exporters.node-exporter.enabled Enable node-exporter
    ##
    enabled: true
  kube-state-metrics:
    ## @param exporters.kube-state-metrics.enabled Enable kube-state-metrics
    ##
    enabled: true
## @param node-exporter [object] Node Exporter deployment configuration
##
node-exporter:
  service:
    labels:
      jobLabel: node-exporter
  serviceMonitor:
    enabled: true
    jobLabel: jobLabel
  extraArgs:
    collector.filesystem.ignored-mount-points: "^/(dev|proc|sys|var/lib/docker/.+)($|/)"
    collector.filesystem.ignored-fs-types: "^(autofs|binfmt_misc|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|sysfs|tracefs)$"
## @param kube-state-metrics [object] Node Exporter deployment configuration
##
kube-state-metrics:
  serviceMonitor:
    enabled: true
## Component scraping for kubelet and kubelet hosted cAdvisor
##
kubelet:
  ## @param kubelet.enabled Create a ServiceMonitor to scrape kubelet service
  ##
  enabled: true
  ## @param kubelet.namespace Namespace where kubelet service is deployed. Related configuration `operator.kubeletService.namespace`
  ##
  namespace: kube-system
  serviceMonitor:
    ## @param kubelet.serviceMonitor.https Enable scraping of the kubelet over HTTPS
    ##
    https: true
    ## @param kubelet.serviceMonitor.interval Scrape interval (use by default, falling back to Prometheus' default)
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ##
    interval: ""
    ## @param kubelet.serviceMonitor.metricRelabelings Metric relabeling
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
    ##
    metricRelabelings: []
    ## @param kubelet.serviceMonitor.relabelings Relabel configs
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
    ##
    relabelings: []
    ## @param kubelet.serviceMonitor.cAdvisorMetricRelabelings Metric relabeling for scraping cAdvisor
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
    ##
    cAdvisorMetricRelabelings: []
    ## @param kubelet.serviceMonitor.cAdvisorRelabelings Relabel configs for scraping cAdvisor
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
    ##
    cAdvisorRelabelings: []
## Component scraping the kube-apiserver
##
kubeApiServer:
  ## @param kubeApiServer.enabled Create a ServiceMonitor to scrape kube-apiserver service
  ##
  enabled: true
  serviceMonitor:
    ## @param kubeApiServer.serviceMonitor.interval Scrape interval. If not set, the Prometheus default scrape interval is used.
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ##
    interval: ""
    ## @param kubeApiServer.serviceMonitor.metricRelabelings Metric relabeling
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
    ##
    metricRelabelings: []
    ## @param kubeApiServer.serviceMonitor.relabelings Relabel configs
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
    ##
    relabelings: []
## Component scraping the kube-controller-manager
##
kubeControllerManager:
  ## @param kubeControllerManager.enabled Create a ServiceMonitor to scrape kube-controller-manager service
  ##
  enabled: true
  ## @param kubeControllerManager.endpoints If your kube controller manager is not deployed as a pod, specify IPs it can be found on
  ## endpoints:
  ##  - 10.141.4.22
  ##  - 10.141.4.23
  ##  - 10.141.4.24
  ##
  endpoints: []
  ## @param kubeControllerManager.namespace Namespace where kube-controller-manager service is deployed.
  ##
  namespace: kube-system
  ## Service ports and selector information
  ## @param kubeControllerManager.service.enabled Whether or not to create a Service object for kube-controller-manager
  ## @param kubeControllerManager.service.port Listening port of the kube-controller-manager Service object
  ## @param kubeControllerManager.service.targetPort Port to target on the kube-controller-manager Pods. This should be the port that kube-controller-manager is exposing metrics on
  ## @param kubeControllerManager.service.selector Optional PODs Label selector for the service
  ##
  service:
    enabled: true
    port: 10252
    targetPort: 10252
    ## selector:
    ##   component: kube-controller-manager
    ##
    selector:
  serviceMonitor:
    ## @param kubeControllerManager.serviceMonitor.interval Scrape interval (use by default, falling back to Prometheus' default)
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ##
    interval: ""
    ## @param kubeControllerManager.serviceMonitor.https Enable scraping kube-controller-manager over https
    ## Requires proper certs (not self-signed) and delegated authentication/authorization checks
    ##
    https: false
    ## @param kubeControllerManager.serviceMonitor.insecureSkipVerify Skip TLS certificate validation when scraping
    ##
    insecureSkipVerify: null
    ## @param kubeControllerManager.serviceMonitor.serverName Name of the server to use when validating TLS certificate
    serverName: null
    ## @param kubeControllerManager.serviceMonitor.metricRelabelings Metric relabeling
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
    ##
    metricRelabelings: []
    ## @param kubeControllerManager.serviceMonitor.relabelings Relabel configs
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
    ##
    relabelings: []
## Component scraping kube scheduler
##
kubeScheduler:
  ## @param kubeScheduler.enabled Create a ServiceMonitor to scrape kube-scheduler service
  ##
  enabled: true
  ## @param kubeScheduler.endpoints If your kube scheduler is not deployed as a pod, specify IPs it can be found on
  ## endpoints:
  ##  - 10.141.4.22
  ##  - 10.141.4.23
  ##  - 10.141.4.24
  ##
  endpoints: []
  ## @param kubeScheduler.namespace Namespace where kube-scheduler service is deployed.
  ##
  namespace: kube-system
  ## If using kubeScheduler.endpoints only the port and targetPort are used
  ## @param kubeScheduler.service.enabled Whether or not to create a Service object for kube-scheduler
  ## @param kubeScheduler.service.port Listening port of the kube scheduler Service object
  ## @param kubeScheduler.service.targetPort Port to target on the kube scheduler Pods. This should be the port that kube scheduler is exposing metrics on
  ## @param kubeScheduler.service.selector Optional PODs Label selector for the service
  ##
  service:
    enabled: true
    port: 10251
    targetPort: 10251
    ## selector:
    ##   component: kube-scheduler
    ##
    selector:
  serviceMonitor:
    ## @param kubeScheduler.serviceMonitor.interval Scrape interval (use by default, falling back to Prometheus' default)
    ##
    interval: ""
    ## @param kubeScheduler.serviceMonitor.https Enable scraping kube-scheduler over https
    ## Requires proper certs (not self-signed) and delegated authentication/authorization checks
    ##
    https: false
    ## @param kubeScheduler.serviceMonitor.insecureSkipVerify Skip TLS certificate validation when scraping
    ##
    insecureSkipVerify: null
    ## @param kubeScheduler.serviceMonitor.serverName Name of the server to use when validating TLS certificate
    ##
    serverName: null
    ## @param kubeScheduler.serviceMonitor.metricRelabelings Metric relabeling
    ## metricRelabelings:
    ##  - action: keep
    ##    regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'
    ##    sourceLabels: [__name__]
    ##
    metricRelabelings: []
    ## @param kubeScheduler.serviceMonitor.relabelings Relabel configs
    ## relabelings:
    ##  - sourceLabels: [__meta_kubernetes_pod_node_name]
    ##    separator: ;
    ##    regex: ^(.*)$
    ##    targetLabel: nodename
    ##    replacement: $1
    ##    action: replace
    ##
    relabelings: []
## Component scraping coreDns
##
coreDns:
  ## @param coreDns.enabled Create a ServiceMonitor to scrape coredns service
  ##
  enabled: true
  ## @param coreDns.namespace Namespace where core dns service is deployed.
  ##
  namespace: kube-system
  ## Create a ServiceMonitor to scrape coredns service
  ## @param coreDns.service.enabled Whether or not to create a Service object for coredns
  ## @param coreDns.service.port Listening port of the coredns Service object
  ## @param coreDns.service.targetPort Port to target on the coredns Pods. This should be the port that coredns is exposing metrics on
  ## @param coreDns.service.selector Optional PODs Label selector for the service
  ##
  service:
    enabled: true
    port: 9153
    targetPort: 9153
    ## selector:
    ##   component: kube-dns
    ##
    selector:
  serviceMonitor:
    ## @param coreDns.serviceMonitor.interval Scrape interval. If not set, the Prometheus default scrape interval is used.
    ##
    interval: ""
    ## @param coreDns.serviceMonitor.metricRelabelings Metric relabel configs to apply to samples before ingestion.
    ## metricRelabelings:
    ##  - action: keep
    ##    regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'
    ##    sourceLabels: [__name__]
    ##
    metricRelabelings: []
    ## @param coreDns.serviceMonitor.relabelings Relabel configs to apply to samples before ingestion.
    ## relabelings:
    ##  - sourceLabels: [__meta_kubernetes_pod_node_name]
    ##    separator: ;
    ##    regex: ^(.*)$
    ##    targetLabel: nodename
    ##    replacement: $1
    ##    action: replace
    ##
    relabelings: []
## Component scraping the kube-proxy
##
kubeProxy:
  ## @param kubeProxy.enabled Create a ServiceMonitor to scrape the kube-proxy Service
  ##
  enabled: true
  ## @param kubeProxy.endpoints If your kube-proxy is not deployed as a pod, specify IPs it can be found on
  ## endpoints:
  ##  - 10.141.4.22
  ##  - 10.141.4.23
  ##  - 10.141.4.24
  ##
  endpoints: []
  ## @param kubeProxy.namespace Namespace where cube-proxy service is deployed.
  ##
  namespace: kube-system
  ## @param kubeProxy.service [object] Service ports and selector information
  ## @param coreDns.service.enabled Whether or not to create a Service object for coredns
  ## @param coreDns.service.port Listening port of the coredns Service object
  ## @param coreDns.service.targetPort Port to target on the coredns Pods. This should be the port that coredns is exposing metrics on
  ## @param coreDns.service.selector Optional PODs Label selector for the service
  ##
  service:
    enabled: true
    port: 10249
    targetPort: 10249
    ## selector:
    ##   k8s-app: kube-proxy
    ##
    selector:
  serviceMonitor:
    ## @param kubeProxy.serviceMonitor.https Enable scraping kube-proxy over https.
    ## Requires proper certs (not self-signed) and delegated authentication/authorization checks
    ##
    https: false
    ## @param kubeProxy.serviceMonitor.interval Scrape interval (use by default, falling back to Prometheus' default)
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ##
    interval: ""
    ## @param kubeProxy.serviceMonitor.metricRelabelings Metric relabeling
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs
    ##
    metricRelabelings: []
    ## @param kubeProxy.serviceMonitor.relabelings Relabel configs
    ## ref: https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config
    ##
    relabelings: []

## @section RBAC parameters

## Role Based Access
## ref: https://kubernetes.io/docs/admin/authorization/rbac/
## @param rbac.create Whether to create and use RBAC resources or not
## @param rbac.apiVersion Version of the RBAC API
## @param rbac.pspEnabled PodSecurityPolicy
##
rbac:
  create: true
  apiVersion: v1beta1
  pspEnabled: true
